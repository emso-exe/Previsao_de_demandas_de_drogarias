{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem preditiva\n",
    "_Machine Learning_\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário\n",
    "\n",
    "1. **Importação de bibliotecas**\n",
    "2. **Carregamento das bases**\n",
    "3. **Análise dos dataframes**\n",
    "4. **Modelagem preditiva**\n",
    "    - 4.1. Preparação dos dados\n",
    "    - 4.2. Treinamento dos modelos com todo o histórico de dados\n",
    "    - 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014\n",
    "    - 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015\n",
    "    - 4.5. Comparativo dos resultados\n",
    "5. **Tunagem dos hiperparâmetros dos melhores algoritmos**\n",
    "    - 5.1. Tunagem do modelo LightGBM com Optuna\n",
    "    - 5.2. Tunagem do modelo XGBoost com Optuna\n",
    "6. **Salvando os modelos**\n",
    "    - 6.1. Salvando e testando o desempenho dos modelos\n",
    "    - 6.2. Comparativo dos resultados\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de pacotes e definição de parâmetros globais\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import optuna\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações para exibição de dados no Jupyter Notebook\n",
    "\n",
    "# Configurar opção para exibir todas as linhas do Dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Configurar para exibir o conteúdo completo das colunas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Configurar a supressão de mensagens de aviso durante a execução\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo dos gráficos do seaborn\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de objetos removidos da memória: 5\n"
     ]
    }
   ],
   "source": [
    "# Efetuando a limpeza da memória antes do carregamento dos dados\n",
    "\n",
    "print(f'\\nQuantidade de objetos removidos da memória: {gc.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATAFRAME: df_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>...</th>\n",
       "      <th>PromoRollingSum_21</th>\n",
       "      <th>PromoRollingSum_28</th>\n",
       "      <th>PromoRollingSum_30</th>\n",
       "      <th>PromoRollingSum_60</th>\n",
       "      <th>PromoRollingSum_90</th>\n",
       "      <th>PromoRollingSum_120</th>\n",
       "      <th>PromoRollingSum_150</th>\n",
       "      <th>PromoRollingSum_180</th>\n",
       "      <th>PromoRollingSum_360</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0      1          1  2015-06-30     1      1            0              0   \n",
       "1      2          1  2015-06-30     1      1            0              0   \n",
       "2      3          1  2015-06-30     1      1            0              1   \n",
       "3      4          1  2015-06-30     1      1            0              0   \n",
       "4      5          1  2015-06-30     1      1            0              0   \n",
       "\n",
       "  StoreType Assortment  CompetitionDistance  ...  PromoRollingSum_21  \\\n",
       "0         c          a               1270.0  ...                 9.0   \n",
       "1         a          a                570.0  ...                 9.0   \n",
       "2         a          a              14130.0  ...                 9.0   \n",
       "3         c          c                620.0  ...                 9.0   \n",
       "4         a          a              29910.0  ...                 9.0   \n",
       "\n",
       "   PromoRollingSum_28  PromoRollingSum_30  PromoRollingSum_60  \\\n",
       "0                10.0                12.0                 0.0   \n",
       "1                10.0                12.0                 0.0   \n",
       "2                10.0                12.0                 0.0   \n",
       "3                10.0                12.0                 0.0   \n",
       "4                10.0                12.0                 0.0   \n",
       "\n",
       "   PromoRollingSum_90 PromoRollingSum_120  PromoRollingSum_150  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                 0.0                 0.0                  0.0   \n",
       "2                 0.0                 0.0                  0.0   \n",
       "3                 0.0                 0.0                  0.0   \n",
       "4                 0.0                 0.0                  0.0   \n",
       "\n",
       "   PromoRollingSum_180  PromoRollingSum_360    Target  \n",
       "0                  0.0                  0.0  149389.0  \n",
       "1                  0.0                  0.0  170586.0  \n",
       "2                  0.0                  0.0  243725.0  \n",
       "3                  0.0                  0.0  334601.0  \n",
       "4                  0.0                  0.0  162182.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataframe a partir do arquivo train_001.csv\n",
    "\n",
    "df_train = pd.read_csv('dados/train_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_train')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATAFRAME: df_validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>...</th>\n",
       "      <th>PromoRollingSum_21</th>\n",
       "      <th>PromoRollingSum_28</th>\n",
       "      <th>PromoRollingSum_30</th>\n",
       "      <th>PromoRollingSum_60</th>\n",
       "      <th>PromoRollingSum_90</th>\n",
       "      <th>PromoRollingSum_120</th>\n",
       "      <th>PromoRollingSum_150</th>\n",
       "      <th>PromoRollingSum_180</th>\n",
       "      <th>PromoRollingSum_360</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162083.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo  StateHoliday  SchoolHoliday  \\\n",
       "0      1          4  2015-07-31     1      1             0              1   \n",
       "1      2          4  2015-07-31     1      1             0              1   \n",
       "2      3          4  2015-07-31     1      1             0              1   \n",
       "3      4          4  2015-07-31     1      1             0              1   \n",
       "4      5          4  2015-07-31     1      1             0              1   \n",
       "\n",
       "  StoreType Assortment  CompetitionDistance  ...  PromoRollingSum_21  \\\n",
       "0         c          a               1270.0  ...                 0.0   \n",
       "1         a          a                570.0  ...                 0.0   \n",
       "2         a          a              14130.0  ...                 0.0   \n",
       "3         c          c                620.0  ...                 0.0   \n",
       "4         a          a              29910.0  ...                 0.0   \n",
       "\n",
       "   PromoRollingSum_28  PromoRollingSum_30  PromoRollingSum_60  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   PromoRollingSum_90  PromoRollingSum_120  PromoRollingSum_150  \\\n",
       "0                 0.0                  0.0                  0.0   \n",
       "1                 0.0                  0.0                  0.0   \n",
       "2                 0.0                  0.0                  0.0   \n",
       "3                 0.0                  0.0                  0.0   \n",
       "4                 0.0                  0.0                  0.0   \n",
       "\n",
       "   PromoRollingSum_180  PromoRollingSum_360    Target  \n",
       "0                  0.0                  0.0  157057.0  \n",
       "1                  0.0                  0.0  176872.0  \n",
       "2                  0.0                  0.0  245876.0  \n",
       "3                  0.0                  0.0  355383.0  \n",
       "4                  0.0                  0.0  162083.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataframe a partir do arquivo validation_001.csv\n",
    "\n",
    "df_validation = pd.read_csv('dados/validation_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_validation')\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VOLUMETRIA\n",
      "\n",
      "df_train\n",
      "---------------------------------------------\n",
      "Quantidade de linhas (registros):  943795\n",
      "Quantidade de colunas (variáveis): 38\n",
      "\n",
      "df_validation\n",
      "---------------------------------------------\n",
      "Quantidade de linhas (registros):  34565\n",
      "Quantidade de colunas (variáveis): 38\n"
     ]
    }
   ],
   "source": [
    "# Exibindo a quantidade de linhas e colunas dos dataframes\n",
    "\n",
    "# Criação de um dicionário com os dataframes e seus respectivos nomes\n",
    "dfs = {\n",
    "    'df_train': df_train,\n",
    "    'df_validation': df_validation\n",
    "}\n",
    "\n",
    "# Iteração sobre o dicionário para exibir o nome e as dimensões dos dataframes\n",
    "print(f'\\nVOLUMETRIA')\n",
    "for nome, df in dfs.items():\n",
    "    print(f'\\n{nome}')\n",
    "    print(f'-'*45)\n",
    "    print(f'Quantidade de linhas (registros):  {df.shape[0]}')\n",
    "    print(f'Quantidade de colunas (variáveis): {df.shape[1]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de um dataframe de metadados\n",
    "\n",
    "def gerar_metadados(dataframe):\n",
    "    '''\n",
    "    Gera um dataframe contendo metadados das colunas do dataframe fornecido.\n",
    "\n",
    "    :param dataframe: Dataframe\n",
    "        DataFrame para o qual os metadados serão gerados.\n",
    "    :return: DataFrame\n",
    "        DataFrame contendo os metadados.\n",
    "    '''\n",
    "    metadados = pd.DataFrame({\n",
    "        'Variável': dataframe.columns,\n",
    "        'Tipo': dataframe.dtypes,\n",
    "        'Qtde de nulos': dataframe.isnull().sum(),\n",
    "        '% de nulos': round((dataframe.isnull().sum()/len(dataframe))*100, 2),\n",
    "        'Cardinalidade': dataframe.nunique(),\n",
    "    })\n",
    "    metadados = metadados.sort_values(by='Qtde de nulos', ascending=False)\n",
    "    metadados = metadados.reset_index(drop=True)\n",
    "    return metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variável</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Qtde de nulos</th>\n",
       "      <th>% de nulos</th>\n",
       "      <th>Cardinalidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PromoRollingSum_21</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DayOfYear</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthsSinceTheCompetitionOpened</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YearsSinceTheCompetitionOpened</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PromoRollingSum_3</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PromoRollingSum_5</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PromoRollingSum_7</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PromoRollingSum_14</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PromoRollingSum_28</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DayOfWeek</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PromoRollingSum_30</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PromoRollingSum_60</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PromoRollingSum_90</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PromoRollingSum_120</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PromoRollingSum_150</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PromoRollingSum_180</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PromoRollingSum_360</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IsWeekend</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Day</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Month</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Date</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Open</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Promo</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>StateHoliday</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SchoolHoliday</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>StoreType</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Assortment</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CompetitionDistance</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CompetitionOpenSinceMonth</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CompetitionOpenSinceYear</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Promo2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Promo2SinceWeek</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Promo2SinceYear</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PromoInterval</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Year</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Target</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Variável     Tipo  Qtde de nulos  % de nulos  \\\n",
       "0                             Store    int64              0         0.0   \n",
       "1                PromoRollingSum_21  float64              0         0.0   \n",
       "2                         DayOfYear    int64              0         0.0   \n",
       "3   MonthsSinceTheCompetitionOpened  float64              0         0.0   \n",
       "4    YearsSinceTheCompetitionOpened  float64              0         0.0   \n",
       "5                 PromoRollingSum_3  float64              0         0.0   \n",
       "6                 PromoRollingSum_5  float64              0         0.0   \n",
       "7                 PromoRollingSum_7  float64              0         0.0   \n",
       "8                PromoRollingSum_14  float64              0         0.0   \n",
       "9                PromoRollingSum_28  float64              0         0.0   \n",
       "10                        DayOfWeek    int64              0         0.0   \n",
       "11               PromoRollingSum_30  float64              0         0.0   \n",
       "12               PromoRollingSum_60  float64              0         0.0   \n",
       "13               PromoRollingSum_90  float64              0         0.0   \n",
       "14              PromoRollingSum_120  float64              0         0.0   \n",
       "15              PromoRollingSum_150  float64              0         0.0   \n",
       "16              PromoRollingSum_180  float64              0         0.0   \n",
       "17              PromoRollingSum_360  float64              0         0.0   \n",
       "18                        IsWeekend     bool              0         0.0   \n",
       "19                          Quarter    int64              0         0.0   \n",
       "20                              Day    int64              0         0.0   \n",
       "21                            Month    int64              0         0.0   \n",
       "22                             Date   object              0         0.0   \n",
       "23                             Open    int64              0         0.0   \n",
       "24                            Promo    int64              0         0.0   \n",
       "25                     StateHoliday   object              0         0.0   \n",
       "26                    SchoolHoliday    int64              0         0.0   \n",
       "27                        StoreType   object              0         0.0   \n",
       "28                       Assortment   object              0         0.0   \n",
       "29              CompetitionDistance  float64              0         0.0   \n",
       "30        CompetitionOpenSinceMonth  float64              0         0.0   \n",
       "31         CompetitionOpenSinceYear  float64              0         0.0   \n",
       "32                           Promo2    int64              0         0.0   \n",
       "33                  Promo2SinceWeek  float64              0         0.0   \n",
       "34                  Promo2SinceYear  float64              0         0.0   \n",
       "35                    PromoInterval   object              0         0.0   \n",
       "36                             Year    int64              0         0.0   \n",
       "37                           Target  float64              0         0.0   \n",
       "\n",
       "    Cardinalidade  \n",
       "0            1115  \n",
       "1               7  \n",
       "2             365  \n",
       "3             336  \n",
       "4             346  \n",
       "5               4  \n",
       "6               6  \n",
       "7               6  \n",
       "8              11  \n",
       "9              11  \n",
       "10              7  \n",
       "11             13  \n",
       "12             14  \n",
       "13             13  \n",
       "14             13  \n",
       "15             17  \n",
       "16             17  \n",
       "17             21  \n",
       "18              2  \n",
       "19              4  \n",
       "20             31  \n",
       "21             12  \n",
       "22            911  \n",
       "23              2  \n",
       "24              2  \n",
       "25              5  \n",
       "26              2  \n",
       "27              4  \n",
       "28              3  \n",
       "29            655  \n",
       "30             13  \n",
       "31             24  \n",
       "32              2  \n",
       "33             25  \n",
       "34              8  \n",
       "35              4  \n",
       "36              3  \n",
       "37         278695  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerar_metadados(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelagem preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditivas e a variável preditora (alvo)\n",
    "\n",
    "features = df_train.columns.drop('Target')\n",
    "target = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis numéricas e categóricas\n",
    "\n",
    "numerical_features = df_train[features].select_dtypes(exclude=object).columns\n",
    "categorical_features = df_train[features].select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter todas as colunas categóricas para string\n",
    "\n",
    "df_train[categorical_features] = df_train[categorical_features].astype(str)\n",
    "df_validation[categorical_features] = df_validation[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_validation[features]\n",
    "y_test = df_validation[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: X_train: (943795, 37), y_train: (943795,)\n",
      "Shape: X_test:  (34565, 37),  y_test: (34565,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os shapes\n",
    "\n",
    "print(f'Shape: X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'Shape: X_test:  {X_test.shape},  y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando transformação de dados\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X_train após transformação: (943795, 958)\n",
      "Shape de X_test após transformação:  (34565, 958)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os shapes após transformação\n",
    "\n",
    "print(f'Shape de X_train após transformação: {X_train_transformed.shape}')\n",
    "print(f'Shape de X_test após transformação:  {X_test_transformed.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Treinamento dos modelos com todo o histórico de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos a serem testados\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'CatBoost': cb.CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, loss_function='RMSE', verbose=0),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor):\n",
    "    '''\n",
    "    Avalia modelos de aprendizado de máquina, calculando métricas de desempenho \n",
    "    no conjunto de treino e teste.\n",
    "\n",
    "    :param models: dict\n",
    "        Dicionário contendo os modelos a serem avaliados.\n",
    "    :param X_train: DataFrame\n",
    "        Conjunto de dados de treino com as variáveis independentes.\n",
    "    :param y_train: Series\n",
    "        Variável dependente para o conjunto de treino.\n",
    "    :param X_test: DataFrame\n",
    "        Conjunto de dados de teste com as variáveis independentes.\n",
    "    :param y_test: Series\n",
    "        Variável dependente para o conjunto de teste.\n",
    "    :param preprocessor: ColumnTransformer\n",
    "        Objeto de pré-processamento que será aplicado aos dados antes do treinamento do modelo.\n",
    "\n",
    "    :return: list\n",
    "        Lista contendo os resultados de avaliação de cada modelo, RMSE e MAE para treino \n",
    "        e teste, além do tempo de execução.\n",
    "    '''\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "        # Registra o tempo de início\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Treina o modelo usando o pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Registra o tempo de término e calcula o tempo de execução\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de treino\n",
    "        train_predictions = pipeline.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "        train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de teste\n",
    "        test_predictions = pipeline.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "        test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "        # Adiciona os resultados à lista\n",
    "        results.append((\n",
    "            model_name, train_rmse, test_rmse, train_mae, test_mae, elapsed_time\n",
    "        ))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74600.379064</td>\n",
       "      <td>309293.409817</td>\n",
       "      <td>51738.388898</td>\n",
       "      <td>271276.664045</td>\n",
       "      <td>31.595168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>38586.776903</td>\n",
       "      <td>44161.800849</td>\n",
       "      <td>27936.856770</td>\n",
       "      <td>32487.902792</td>\n",
       "      <td>9.428456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56395.651572</td>\n",
       "      <td>62284.344024</td>\n",
       "      <td>39903.499101</td>\n",
       "      <td>44085.404224</td>\n",
       "      <td>15.095588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>65562.258359</td>\n",
       "      <td>70611.741017</td>\n",
       "      <td>45250.375402</td>\n",
       "      <td>48747.665342</td>\n",
       "      <td>334.461325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21462.326807</td>\n",
       "      <td>28607.617056</td>\n",
       "      <td>15610.326833</td>\n",
       "      <td>21221.732968</td>\n",
       "      <td>9.710920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74600.379064  309293.409817   51738.388898   \n",
       "1          LightGBM    38586.776903   44161.800849   27936.856770   \n",
       "2          CatBoost    56395.651572   62284.344024   39903.499101   \n",
       "3  GradientBoosting    65562.258359   70611.741017   45250.375402   \n",
       "4           XGBoost    21462.326807   28607.617056   15610.326833   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  271276.664045            31.595168  \n",
       "1   32487.902792             9.428456  \n",
       "2   44085.404224            15.095588  \n",
       "3   48747.665342           334.461325  \n",
       "4   21221.732968             9.710920  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74409.362859</td>\n",
       "      <td>276823.117601</td>\n",
       "      <td>51872.836322</td>\n",
       "      <td>240122.218335</td>\n",
       "      <td>17.609226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>37508.232887</td>\n",
       "      <td>42825.956651</td>\n",
       "      <td>27228.816279</td>\n",
       "      <td>31749.433281</td>\n",
       "      <td>4.844280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56252.880219</td>\n",
       "      <td>61747.624779</td>\n",
       "      <td>39709.751946</td>\n",
       "      <td>43654.323788</td>\n",
       "      <td>10.245021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>64445.219168</td>\n",
       "      <td>69331.655819</td>\n",
       "      <td>44933.129775</td>\n",
       "      <td>48135.930325</td>\n",
       "      <td>197.969966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>19679.021450</td>\n",
       "      <td>25890.517653</td>\n",
       "      <td>14269.371007</td>\n",
       "      <td>19121.840148</td>\n",
       "      <td>5.249812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74409.362859  276823.117601   51872.836322   \n",
       "1          LightGBM    37508.232887   42825.956651   27228.816279   \n",
       "2          CatBoost    56252.880219   61747.624779   39709.751946   \n",
       "3  GradientBoosting    64445.219168   69331.655819   44933.129775   \n",
       "4           XGBoost    19679.021450   25890.517653   14269.371007   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  240122.218335            17.609226  \n",
       "1   31749.433281             4.844280  \n",
       "2   43654.323788            10.245021  \n",
       "3   48135.930325           197.969966  \n",
       "4   19121.840148             5.249812  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando dados a partir de 01-01-2014\n",
    "df_train_00 = df_train[df_train['Date'] >= '2014-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_00[categorical_features] = df_train_00[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_00[features]\n",
    "y_train = df_train_00[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_00 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>73699.366946</td>\n",
       "      <td>86771.077084</td>\n",
       "      <td>51404.782369</td>\n",
       "      <td>60645.653521</td>\n",
       "      <td>2.180020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>35155.499255</td>\n",
       "      <td>40311.140946</td>\n",
       "      <td>25778.097047</td>\n",
       "      <td>29902.591028</td>\n",
       "      <td>1.834738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>54854.734524</td>\n",
       "      <td>62294.912910</td>\n",
       "      <td>38846.806357</td>\n",
       "      <td>43603.607236</td>\n",
       "      <td>2.678659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>63451.163306</td>\n",
       "      <td>69028.536458</td>\n",
       "      <td>44110.979695</td>\n",
       "      <td>47900.685039</td>\n",
       "      <td>55.165528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18390.785339</td>\n",
       "      <td>24604.677229</td>\n",
       "      <td>13493.532465</td>\n",
       "      <td>18316.927099</td>\n",
       "      <td>1.678125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    73699.366946   86771.077084   51404.782369   \n",
       "1          LightGBM    35155.499255   40311.140946   25778.097047   \n",
       "2          CatBoost    54854.734524   62294.912910   38846.806357   \n",
       "3  GradientBoosting    63451.163306   69028.536458   44110.979695   \n",
       "4           XGBoost    18390.785339   24604.677229   13493.532465   \n",
       "\n",
       "   MAE em teste  Tempo decorrido (s)  \n",
       "0  60645.653521             2.180020  \n",
       "1  29902.591028             1.834738  \n",
       "2  43603.607236             2.678659  \n",
       "3  47900.685039            55.165528  \n",
       "4  18316.927099             1.678125  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando dados a partir de 01-01-2015\n",
    "df_train_01 = df_train[df_train['Date'] >= '2015-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_01[categorical_features] = df_train_01[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_01[features]\n",
    "y_train = df_train_01[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_01 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Comparativo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74600.379064</td>\n",
       "      <td>309293.409817</td>\n",
       "      <td>51738.388898</td>\n",
       "      <td>271276.664045</td>\n",
       "      <td>31.595168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>38586.776903</td>\n",
       "      <td>44161.800849</td>\n",
       "      <td>27936.856770</td>\n",
       "      <td>32487.902792</td>\n",
       "      <td>9.428456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56395.651572</td>\n",
       "      <td>62284.344024</td>\n",
       "      <td>39903.499101</td>\n",
       "      <td>44085.404224</td>\n",
       "      <td>15.095588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>65562.258359</td>\n",
       "      <td>70611.741017</td>\n",
       "      <td>45250.375402</td>\n",
       "      <td>48747.665342</td>\n",
       "      <td>334.461325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21462.326807</td>\n",
       "      <td>28607.617056</td>\n",
       "      <td>15610.326833</td>\n",
       "      <td>21221.732968</td>\n",
       "      <td>9.710920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74600.379064  309293.409817   51738.388898   \n",
       "1          LightGBM    38586.776903   44161.800849   27936.856770   \n",
       "2          CatBoost    56395.651572   62284.344024   39903.499101   \n",
       "3  GradientBoosting    65562.258359   70611.741017   45250.375402   \n",
       "4           XGBoost    21462.326807   28607.617056   15610.326833   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  271276.664045            31.595168  \n",
       "1   32487.902792             9.428456  \n",
       "2   44085.404224            15.095588  \n",
       "3   48747.665342           334.461325  \n",
       "4   21221.732968             9.710920  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando todo o histórico de dados\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores elevados de **RMSE** e **MAE** podem ser atribuídos à grande variação na variável dependente _'Target'_, que inclui dias com vendas zero e dias com vendas muito elevadas. Esse cenário reflete a realidade de que drogarias podem estar fechadas ou operar em horários reduzidos, o que influencia os dados. O foco, no entanto, deve ser nas diferenças entre as métricas de treino e teste, o que indica a capacidade dos modelos em **generalizar**.\n",
    "\n",
    "Dentre os modelos analisados, o **LinearRegression** teve o pior desempenho com os maiores valores de erro. O **GradientBoosting** apresentou boas diferenças entre treino e teste, mas os erros ainda foram elevados, além de apresentar o pior tempo de execução. O **CatBoost** se destacou com métricas razoáveis, mas seu tempo de execução foi elevado em relação aos próximos modelos. O **XGBoost** obteve os menores valores de _RMSE_ e _MAE_ em comparação aos demais modelos, porém com uma diferença maior entre treino e teste, indicando possível overfitting. O **LightGBM**, com _RMSE_ e _MAE_ competitivos e o menor tempo de execução, mostrou-se o modelo mais equilibrado, oferecendo a melhor performance geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tunagem dos hiperparâmetros dos melhores algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Tunagem do modelo LightGBM com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lightgbm(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo LGBMRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''   \n",
    "    model = lgb.LGBMRegressor(\n",
    "        # Número de árvores (boosting rounds) no modelo, cada árvore corrige os erros da anterior\n",
    "        n_estimators = trial.suggest_int('n_estimators', 300, 450),\n",
    "        # Taxa de aprendizado para ajustar o impacto de cada árvore\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        # Limita a profundidade máxima de cada árvore, controlando o crescimento da árvore e prevenindo overfitting\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 5),\n",
    "        # Número máximo de folhas em cada árvore. Controla a complexidade do modelo\n",
    "        num_leaves = trial.suggest_int('num_leaves', 20, 99),\n",
    "        # Proporção de amostras usadas para treinar cada árvore, útil para prevenir overfitting\n",
    "        subsample = trial.suggest_float('subsample', 0.4, 0.7),\n",
    "        # Proporção de colunas (features) usadas para construir cada árvore, ajuda a reduzir correlação entre árvores e evitar overfitting\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        # Regularização L1 (Lasso), adiciona penalidade proporcional ao valor absoluto dos coeficientes, ajudando a reduzir o overfitting\n",
    "        reg_alpha = trial.suggest_float('reg_alpha', 1, 10, log=True),\n",
    "        # Regularização L2 (Ridge), adiciona penalidade proporcional ao quadrado dos coeficientes, ajudando a reduzir o overfitting\n",
    "        reg_lambda = trial.suggest_float('reg_lambda', 1, 10, log=True),\n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados     \n",
    "        random_state=42,\n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbose=-1,         \n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Previsões e cálculo das métricas no conjunto de teste\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-10 00:00:51,834] A new study created in memory with name: no-name-f7ea192f-07ab-4d5c-921b-104cdd9783fe\n",
      "[I 2024-11-10 00:00:56,063] Trial 0 finished with value: 34636.81886732525 and parameters: {'n_estimators': 356, 'learning_rate': 0.044635901521768134, 'max_depth': 5, 'num_leaves': 67, 'subsample': 0.44680559213273097, 'colsample_bytree': 0.7467983561008608, 'reg_alpha': 1.1430983876313219, 'reg_lambda': 7.348118405270449}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:00:59,011] Trial 1 finished with value: 48634.26465549473 and parameters: {'n_estimators': 390, 'learning_rate': 0.025529516046973785, 'max_depth': 3, 'num_leaves': 97, 'subsample': 0.6497327922401265, 'colsample_bytree': 0.7637017332034828, 'reg_alpha': 1.5199348301309807, 'reg_lambda': 1.5254729458052607}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:03,229] Trial 2 finished with value: 47874.91299773548 and parameters: {'n_estimators': 345, 'learning_rate': 0.016738881542579662, 'max_depth': 4, 'num_leaves': 43, 'subsample': 0.5835558684167138, 'colsample_bytree': 0.7418481581956126, 'reg_alpha': 1.9594972058679163, 'reg_lambda': 2.324672848950434}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:06,742] Trial 3 finished with value: 48201.41001035422 and parameters: {'n_estimators': 368, 'learning_rate': 0.030489195547657565, 'max_depth': 3, 'num_leaves': 61, 'subsample': 0.5777243706586127, 'colsample_bytree': 0.7139351238159993, 'reg_alpha': 4.050837781329674, 'reg_lambda': 1.4808945119975185}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:09,800] Trial 4 finished with value: 36982.19631031517 and parameters: {'n_estimators': 309, 'learning_rate': 0.044448339535094646, 'max_depth': 5, 'num_leaves': 84, 'subsample': 0.4913841307520112, 'colsample_bytree': 0.7293016342019151, 'reg_alpha': 4.833180632488465, 'reg_lambda': 2.7551959649510764}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:13,030] Trial 5 finished with value: 50839.161968209 and parameters: {'n_estimators': 318, 'learning_rate': 0.015636765183901856, 'max_depth': 3, 'num_leaves': 92, 'subsample': 0.4776339944800051, 'colsample_bytree': 0.8987566853061946, 'reg_alpha': 2.0497980520950176, 'reg_lambda': 3.3118298880723813}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:17,248] Trial 6 finished with value: 49143.0392236237 and parameters: {'n_estimators': 382, 'learning_rate': 0.007652872182750091, 'max_depth': 5, 'num_leaves': 82, 'subsample': 0.6818496824692567, 'colsample_bytree': 0.9684482051282947, 'reg_alpha': 3.961867790406583, 'reg_lambda': 8.353610755311761}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:19,615] Trial 7 finished with value: 53875.3466082151 and parameters: {'n_estimators': 313, 'learning_rate': 0.007851504189403358, 'max_depth': 3, 'num_leaves': 46, 'subsample': 0.5166031869068446, 'colsample_bytree': 0.7814047095321688, 'reg_alpha': 6.741204610702761, 'reg_lambda': 2.273805573563182}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:22,893] Trial 8 finished with value: 50295.987179510026 and parameters: {'n_estimators': 342, 'learning_rate': 0.017444803725696106, 'max_depth': 3, 'num_leaves': 84, 'subsample': 0.4223651931039313, 'colsample_bytree': 0.9960660809801551, 'reg_alpha': 5.918951335463645, 'reg_lambda': 1.580213186410388}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:26,484] Trial 9 finished with value: 40509.173711945165 and parameters: {'n_estimators': 300, 'learning_rate': 0.03269124292259021, 'max_depth': 5, 'num_leaves': 78, 'subsample': 0.6313811040057837, 'colsample_bytree': 0.7222133955202271, 'reg_alpha': 2.2827887759905128, 'reg_lambda': 1.305777134899723}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:30,232] Trial 10 finished with value: 53300.60666061224 and parameters: {'n_estimators': 435, 'learning_rate': 0.0050695240451904405, 'max_depth': 4, 'num_leaves': 21, 'subsample': 0.4046103211984313, 'colsample_bytree': 0.831424278238549, 'reg_alpha': 1.035486013330949, 'reg_lambda': 9.46542023098865}. Best is trial 0 with value: 34636.81886732525.\n",
      "[I 2024-11-10 00:01:34,184] Trial 11 finished with value: 30991.665863550053 and parameters: {'n_estimators': 418, 'learning_rate': 0.049518201141865524, 'max_depth': 5, 'num_leaves': 67, 'subsample': 0.4700341430619077, 'colsample_bytree': 0.8185202661129731, 'reg_alpha': 8.89078944228278, 'reg_lambda': 5.277513379254598}. Best is trial 11 with value: 30991.665863550053.\n",
      "[I 2024-11-10 00:01:37,790] Trial 12 finished with value: 30990.549871957748 and parameters: {'n_estimators': 426, 'learning_rate': 0.04988585630056919, 'max_depth': 5, 'num_leaves': 64, 'subsample': 0.4519007388862893, 'colsample_bytree': 0.8093326909715368, 'reg_alpha': 9.879203603425442, 'reg_lambda': 5.3863470853067685}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:01:41,742] Trial 13 finished with value: 37900.56546603296 and parameters: {'n_estimators': 431, 'learning_rate': 0.049423555541083, 'max_depth': 4, 'num_leaves': 49, 'subsample': 0.5230161991843356, 'colsample_bytree': 0.8369630069952889, 'reg_alpha': 9.985330377627196, 'reg_lambda': 5.1119269985759335}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:01:45,835] Trial 14 finished with value: 40894.17544257046 and parameters: {'n_estimators': 410, 'learning_rate': 0.02303437500361535, 'max_depth': 5, 'num_leaves': 70, 'subsample': 0.4572227953605157, 'colsample_bytree': 0.8768075437408684, 'reg_alpha': 9.888163174719505, 'reg_lambda': 5.208333066451084}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:01:50,179] Trial 15 finished with value: 34876.10447435845 and parameters: {'n_estimators': 450, 'learning_rate': 0.03533580864333844, 'max_depth': 5, 'num_leaves': 57, 'subsample': 0.5416965885001604, 'colsample_bytree': 0.8138387267681632, 'reg_alpha': 7.45040168854269, 'reg_lambda': 4.632760409271543}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:01:53,602] Trial 16 finished with value: 48825.01499087384 and parameters: {'n_estimators': 410, 'learning_rate': 0.011232894046987978, 'max_depth': 4, 'num_leaves': 57, 'subsample': 0.4424752724957054, 'colsample_bytree': 0.9097593135009883, 'reg_alpha': 8.060630434380782, 'reg_lambda': 6.492435668624714}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:01:57,455] Trial 17 finished with value: 35178.79611547361 and parameters: {'n_estimators': 406, 'learning_rate': 0.03750708566708119, 'max_depth': 5, 'num_leaves': 33, 'subsample': 0.49288166861967214, 'colsample_bytree': 0.794824239795712, 'reg_alpha': 5.389808390823125, 'reg_lambda': 3.696259715560619}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:01,511] Trial 18 finished with value: 44429.295530302785 and parameters: {'n_estimators': 427, 'learning_rate': 0.024101711355929086, 'max_depth': 4, 'num_leaves': 71, 'subsample': 0.5620285060340782, 'colsample_bytree': 0.8638038249098459, 'reg_alpha': 3.5580648620971487, 'reg_lambda': 6.258621517840355}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:08,519] Trial 19 finished with value: 32359.428604340213 and parameters: {'n_estimators': 450, 'learning_rate': 0.04147087158403985, 'max_depth': 5, 'num_leaves': 39, 'subsample': 0.4034019784250794, 'colsample_bytree': 0.9238414929418803, 'reg_alpha': 8.449731903136302, 'reg_lambda': 4.126029527363758}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:14,821] Trial 20 finished with value: 38353.88746759788 and parameters: {'n_estimators': 399, 'learning_rate': 0.029029791605418145, 'max_depth': 5, 'num_leaves': 53, 'subsample': 0.46547981148922096, 'colsample_bytree': 0.8156812524479168, 'reg_alpha': 2.794615145845252, 'reg_lambda': 6.162924772504557}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:20,754] Trial 21 finished with value: 32428.223982555428 and parameters: {'n_estimators': 450, 'learning_rate': 0.039940222672378185, 'max_depth': 5, 'num_leaves': 37, 'subsample': 0.4046877793323705, 'colsample_bytree': 0.9364881302341647, 'reg_alpha': 8.238783750576555, 'reg_lambda': 3.9203867850885996}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:25,160] Trial 22 finished with value: 31633.0987355522 and parameters: {'n_estimators': 421, 'learning_rate': 0.04835435986521565, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.4279155128533614, 'colsample_bytree': 0.9378984398607915, 'reg_alpha': 6.418506160352657, 'reg_lambda': 4.301878352540108}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:29,661] Trial 23 finished with value: 38004.98301038387 and parameters: {'n_estimators': 422, 'learning_rate': 0.04919839159503352, 'max_depth': 4, 'num_leaves': 21, 'subsample': 0.4319812762969611, 'colsample_bytree': 0.8741387088982457, 'reg_alpha': 6.05951891883103, 'reg_lambda': 3.01565824254704}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:34,171] Trial 24 finished with value: 41970.76054674265 and parameters: {'n_estimators': 416, 'learning_rate': 0.020624746418930095, 'max_depth': 5, 'num_leaves': 62, 'subsample': 0.5081933572384011, 'colsample_bytree': 0.7844659489730096, 'reg_alpha': 4.713869182385392, 'reg_lambda': 5.227493595343038}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:38,629] Trial 25 finished with value: 35834.66650241279 and parameters: {'n_estimators': 393, 'learning_rate': 0.03478796217420472, 'max_depth': 5, 'num_leaves': 31, 'subsample': 0.47512824494776307, 'colsample_bytree': 0.9578413080061283, 'reg_alpha': 6.856675713159553, 'reg_lambda': 4.467869593642925}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:44,126] Trial 26 finished with value: 37846.93703822598 and parameters: {'n_estimators': 436, 'learning_rate': 0.04904197044379594, 'max_depth': 4, 'num_leaves': 77, 'subsample': 0.42616816511146705, 'colsample_bytree': 0.846181975051035, 'reg_alpha': 9.64294690729266, 'reg_lambda': 7.5654245252794965}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:47,894] Trial 27 finished with value: 39404.7173180601 and parameters: {'n_estimators': 379, 'learning_rate': 0.027664924951990254, 'max_depth': 5, 'num_leaves': 66, 'subsample': 0.4933138495997036, 'colsample_bytree': 0.8150124216127118, 'reg_alpha': 7.536555790206149, 'reg_lambda': 2.4538737873879555}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:52,215] Trial 28 finished with value: 44790.24748413467 and parameters: {'n_estimators': 421, 'learning_rate': 0.01352691293703268, 'max_depth': 5, 'num_leaves': 51, 'subsample': 0.4536438538837987, 'colsample_bytree': 0.8894814678579671, 'reg_alpha': 6.3991532507783075, 'reg_lambda': 3.5909488409855164}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:02:58,472] Trial 29 finished with value: 33295.36591961058 and parameters: {'n_estimators': 440, 'learning_rate': 0.04117429757967301, 'max_depth': 5, 'num_leaves': 67, 'subsample': 0.4403324545594951, 'colsample_bytree': 0.7581716712215739, 'reg_alpha': 5.1626294245872275, 'reg_lambda': 5.819760192987131}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:03,179] Trial 30 finished with value: 46193.441684623416 and parameters: {'n_estimators': 367, 'learning_rate': 0.020345270788817107, 'max_depth': 4, 'num_leaves': 28, 'subsample': 0.5472512594918983, 'colsample_bytree': 0.8561093827931214, 'reg_alpha': 8.72269728646084, 'reg_lambda': 7.138968357967436}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:09,862] Trial 31 finished with value: 31977.46073393674 and parameters: {'n_estimators': 446, 'learning_rate': 0.0417780172626041, 'max_depth': 5, 'num_leaves': 38, 'subsample': 0.40187450088102616, 'colsample_bytree': 0.9296235458740868, 'reg_alpha': 8.422608375069169, 'reg_lambda': 4.760509592978086}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:14,473] Trial 32 finished with value: 31880.54699670847 and parameters: {'n_estimators': 439, 'learning_rate': 0.04286076037736361, 'max_depth': 5, 'num_leaves': 26, 'subsample': 0.42153468932546634, 'colsample_bytree': 0.9575745848742371, 'reg_alpha': 8.602408477125705, 'reg_lambda': 4.598734853858154}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:19,454] Trial 33 finished with value: 35946.034915513956 and parameters: {'n_estimators': 403, 'learning_rate': 0.0346244365757289, 'max_depth': 5, 'num_leaves': 27, 'subsample': 0.4209958546716471, 'colsample_bytree': 0.9980152716176639, 'reg_alpha': 7.218861071784591, 'reg_lambda': 5.50203897531677}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:24,830] Trial 34 finished with value: 32056.83933665583 and parameters: {'n_estimators': 417, 'learning_rate': 0.045381512285055846, 'max_depth': 5, 'num_leaves': 25, 'subsample': 0.44925164624041936, 'colsample_bytree': 0.9566380302764843, 'reg_alpha': 1.4223876635047692, 'reg_lambda': 4.128412668018949}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:31,053] Trial 35 finished with value: 38348.00140694396 and parameters: {'n_estimators': 428, 'learning_rate': 0.02911893886338756, 'max_depth': 5, 'num_leaves': 74, 'subsample': 0.6166883721480609, 'colsample_bytree': 0.7016375726131938, 'reg_alpha': 9.183982797255819, 'reg_lambda': 7.299337994289701}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:36,306] Trial 36 finished with value: 31391.561534608754 and parameters: {'n_estimators': 441, 'learning_rate': 0.04397083047846013, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.4666841179031296, 'colsample_bytree': 0.9838502003028885, 'reg_alpha': 5.739635826066391, 'reg_lambda': 3.19562241233332}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:40,818] Trial 37 finished with value: 34980.28382751215 and parameters: {'n_estimators': 391, 'learning_rate': 0.03749020658565422, 'max_depth': 5, 'num_leaves': 43, 'subsample': 0.47361911368668685, 'colsample_bytree': 0.979673804440411, 'reg_alpha': 4.246271245681416, 'reg_lambda': 3.048384202579579}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:45,558] Trial 38 finished with value: 36054.7600161801 and parameters: {'n_estimators': 425, 'learning_rate': 0.03175462487122365, 'max_depth': 5, 'num_leaves': 61, 'subsample': 0.5326641761238363, 'colsample_bytree': 0.9757204318702486, 'reg_alpha': 3.10558941974784, 'reg_lambda': 2.0907207296908914}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:49,129] Trial 39 finished with value: 41253.63457792373 and parameters: {'n_estimators': 349, 'learning_rate': 0.04622272967688654, 'max_depth': 4, 'num_leaves': 96, 'subsample': 0.5058989372169275, 'colsample_bytree': 0.7939414348319062, 'reg_alpha': 5.581277430682548, 'reg_lambda': 2.638299929500163}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:53,959] Trial 40 finished with value: 35319.7675117473 and parameters: {'n_estimators': 399, 'learning_rate': 0.03880703373527135, 'max_depth': 5, 'num_leaves': 55, 'subsample': 0.486709521944186, 'colsample_bytree': 0.7419061164056844, 'reg_alpha': 6.379236954801586, 'reg_lambda': 1.0140922009126376}. Best is trial 12 with value: 30990.549871957748.\n",
      "[I 2024-11-10 00:03:58,500] Trial 41 finished with value: 29450.865364457753 and parameters: {'n_estimators': 439, 'learning_rate': 0.04953025180937145, 'max_depth': 5, 'num_leaves': 31, 'subsample': 0.41788333799448124, 'colsample_bytree': 0.9474560494265953, 'reg_alpha': 7.375758431006774, 'reg_lambda': 3.2918367656411776}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:06,424] Trial 42 finished with value: 30729.697973422797 and parameters: {'n_estimators': 442, 'learning_rate': 0.04548952958806829, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.4647475186245299, 'colsample_bytree': 0.9457820926651923, 'reg_alpha': 7.354887633556252, 'reg_lambda': 3.3998709608419846}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:12,037] Trial 43 finished with value: 31185.474825367623 and parameters: {'n_estimators': 442, 'learning_rate': 0.04317092111536514, 'max_depth': 5, 'num_leaves': 47, 'subsample': 0.45969182625741783, 'colsample_bytree': 0.9154411223074026, 'reg_alpha': 7.459936054124061, 'reg_lambda': 1.8679359669746864}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:16,815] Trial 44 finished with value: 34001.035724228066 and parameters: {'n_estimators': 331, 'learning_rate': 0.04986999630756933, 'max_depth': 5, 'num_leaves': 65, 'subsample': 0.4546580700466917, 'colsample_bytree': 0.9038426028600859, 'reg_alpha': 7.373428129627013, 'reg_lambda': 1.9804919975369049}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:20,790] Trial 45 finished with value: 47209.74819358902 and parameters: {'n_estimators': 432, 'learning_rate': 0.009086477746265843, 'max_depth': 5, 'num_leaves': 34, 'subsample': 0.48382577661020887, 'colsample_bytree': 0.9158429133725967, 'reg_alpha': 7.824117277825475, 'reg_lambda': 1.7901108144085973}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:25,976] Trial 46 finished with value: 35408.42032938365 and parameters: {'n_estimators': 443, 'learning_rate': 0.03263157693045795, 'max_depth': 5, 'num_leaves': 49, 'subsample': 0.5866188812941073, 'colsample_bytree': 0.9475367905077756, 'reg_alpha': 4.4685189993486985, 'reg_lambda': 2.760178007679326}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:29,412] Trial 47 finished with value: 46377.481277783576 and parameters: {'n_estimators': 433, 'learning_rate': 0.03687548730019077, 'max_depth': 3, 'num_leaves': 48, 'subsample': 0.6740795547982223, 'colsample_bytree': 0.8929856567697559, 'reg_alpha': 9.10273302222484, 'reg_lambda': 3.51367813524687}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:34,272] Trial 48 finished with value: 39435.39961593779 and parameters: {'n_estimators': 411, 'learning_rate': 0.026077927482733312, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.43914034638950017, 'colsample_bytree': 0.8290812448051849, 'reg_alpha': 6.8826566588768365, 'reg_lambda': 9.994282241594961}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:37,949] Trial 49 finished with value: 51178.81362861863 and parameters: {'n_estimators': 370, 'learning_rate': 0.0062639590466356445, 'max_depth': 5, 'num_leaves': 63, 'subsample': 0.5010948295290321, 'colsample_bytree': 0.7591444051926686, 'reg_alpha': 9.991020699233504, 'reg_lambda': 1.3049128321879688}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:42,547] Trial 50 finished with value: 38949.651148285644 and parameters: {'n_estimators': 444, 'learning_rate': 0.04450735740489385, 'max_depth': 4, 'num_leaves': 57, 'subsample': 0.46430113370161713, 'colsample_bytree': 0.7990586174272495, 'reg_alpha': 3.808080399364687, 'reg_lambda': 2.334767054832162}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:46,684] Trial 51 finished with value: 31002.889151815518 and parameters: {'n_estimators': 438, 'learning_rate': 0.04495190907375624, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.4654792506672382, 'colsample_bytree': 0.9707255993447753, 'reg_alpha': 5.929287005032651, 'reg_lambda': 3.416609989324792}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:51,051] Trial 52 finished with value: 32981.70823499265 and parameters: {'n_estimators': 435, 'learning_rate': 0.039703192215385145, 'max_depth': 5, 'num_leaves': 42, 'subsample': 0.4140746037851659, 'colsample_bytree': 0.9695332698505185, 'reg_alpha': 7.847727867594464, 'reg_lambda': 2.705636983824432}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:54,794] Trial 53 finished with value: 31805.882202584708 and parameters: {'n_estimators': 428, 'learning_rate': 0.044360226008266515, 'max_depth': 5, 'num_leaves': 70, 'subsample': 0.4396814157078502, 'colsample_bytree': 0.9469333360025273, 'reg_alpha': 5.248597679412498, 'reg_lambda': 3.3464784836945882}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:04:59,027] Trial 54 finished with value: 34901.01670067907 and parameters: {'n_estimators': 417, 'learning_rate': 0.03485324178474651, 'max_depth': 5, 'num_leaves': 46, 'subsample': 0.5231868604653, 'colsample_bytree': 0.9906046095400048, 'reg_alpha': 9.066339613658208, 'reg_lambda': 3.9830223245506646}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:05,082] Trial 55 finished with value: 29895.625439764804 and parameters: {'n_estimators': 447, 'learning_rate': 0.049870546914608335, 'max_depth': 5, 'num_leaves': 53, 'subsample': 0.4628059437063767, 'colsample_bytree': 0.9199217424475155, 'reg_alpha': 7.087777209890798, 'reg_lambda': 8.653602618846794}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:12,153] Trial 56 finished with value: 29489.7704769272 and parameters: {'n_estimators': 450, 'learning_rate': 0.049760537473641245, 'max_depth': 5, 'num_leaves': 52, 'subsample': 0.4811806828024105, 'colsample_bytree': 0.9657948815399104, 'reg_alpha': 6.830917485357184, 'reg_lambda': 8.844273006906334}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:17,181] Trial 57 finished with value: 29909.52573434263 and parameters: {'n_estimators': 448, 'learning_rate': 0.049906514427728206, 'max_depth': 5, 'num_leaves': 53, 'subsample': 0.478224142671516, 'colsample_bytree': 0.838309180687714, 'reg_alpha': 6.908479831987604, 'reg_lambda': 8.640269887276197}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:22,160] Trial 58 finished with value: 46139.32634671244 and parameters: {'n_estimators': 447, 'learning_rate': 0.03906653435222838, 'max_depth': 3, 'num_leaves': 54, 'subsample': 0.481718329459891, 'colsample_bytree': 0.8783315838331214, 'reg_alpha': 2.207564807085514, 'reg_lambda': 8.779724770051226}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:28,065] Trial 59 finished with value: 30632.58873899933 and parameters: {'n_estimators': 450, 'learning_rate': 0.04680571377132332, 'max_depth': 5, 'num_leaves': 52, 'subsample': 0.5601560698589458, 'colsample_bytree': 0.8399466011934738, 'reg_alpha': 6.767643360079605, 'reg_lambda': 8.261781452635116}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:32,101] Trial 60 finished with value: 43927.69421860089 and parameters: {'n_estimators': 450, 'learning_rate': 0.014596176929873916, 'max_depth': 5, 'num_leaves': 51, 'subsample': 0.5637922388944465, 'colsample_bytree': 0.8619871907809191, 'reg_alpha': 4.773603957007478, 'reg_lambda': 8.634442350803901}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:36,843] Trial 61 finished with value: 30760.441277410897 and parameters: {'n_estimators': 445, 'learning_rate': 0.04955503894772113, 'max_depth': 5, 'num_leaves': 57, 'subsample': 0.5888793713344298, 'colsample_bytree': 0.8437804157858512, 'reg_alpha': 6.932546367750474, 'reg_lambda': 7.957705771434225}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:40,778] Trial 62 finished with value: 31145.182269715035 and parameters: {'n_estimators': 445, 'learning_rate': 0.046356867954660735, 'max_depth': 5, 'num_leaves': 57, 'subsample': 0.5980061633235503, 'colsample_bytree': 0.8404626598712235, 'reg_alpha': 6.781259728228364, 'reg_lambda': 7.995492824529659}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:46,134] Trial 63 finished with value: 31187.202102383155 and parameters: {'n_estimators': 437, 'learning_rate': 0.0473751452768575, 'max_depth': 5, 'num_leaves': 59, 'subsample': 0.5631213121069998, 'colsample_bytree': 0.8272056796263448, 'reg_alpha': 6.273504307935436, 'reg_lambda': 9.240626647176956}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:05:56,207] Trial 64 finished with value: 32068.337017702226 and parameters: {'n_estimators': 450, 'learning_rate': 0.04119764806614587, 'max_depth': 5, 'num_leaves': 51, 'subsample': 0.6078784749956541, 'colsample_bytree': 0.8480986075807435, 'reg_alpha': 6.9679833062364125, 'reg_lambda': 8.074080995363676}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:01,284] Trial 65 finished with value: 34444.04353138027 and parameters: {'n_estimators': 444, 'learning_rate': 0.03578842486219281, 'max_depth': 5, 'num_leaves': 53, 'subsample': 0.5915936551619992, 'colsample_bytree': 0.8704945788571347, 'reg_alpha': 4.951173661327594, 'reg_lambda': 6.674292143136208}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:07,405] Trial 66 finished with value: 29957.90740513287 and parameters: {'n_estimators': 432, 'learning_rate': 0.04968162296611603, 'max_depth': 5, 'num_leaves': 35, 'subsample': 0.574331735407188, 'colsample_bytree': 0.945439913832857, 'reg_alpha': 5.924386319842063, 'reg_lambda': 9.875565026968369}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:13,729] Trial 67 finished with value: 32696.591138025407 and parameters: {'n_estimators': 432, 'learning_rate': 0.041187769896293115, 'max_depth': 5, 'num_leaves': 35, 'subsample': 0.573351887193199, 'colsample_bytree': 0.9395127834181662, 'reg_alpha': 5.744619022286654, 'reg_lambda': 9.799278050688324}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:19,191] Trial 68 finished with value: 30515.076189440293 and parameters: {'n_estimators': 439, 'learning_rate': 0.04629378155564937, 'max_depth': 5, 'num_leaves': 36, 'subsample': 0.5374145145292224, 'colsample_bytree': 0.9596326432028716, 'reg_alpha': 8.030840292353087, 'reg_lambda': 9.107485868006178}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:23,068] Trial 69 finished with value: 35543.404800330434 and parameters: {'n_estimators': 430, 'learning_rate': 0.03268523477034671, 'max_depth': 5, 'num_leaves': 30, 'subsample': 0.5366524434595084, 'colsample_bytree': 0.9266737289399511, 'reg_alpha': 7.939533557797638, 'reg_lambda': 9.06930947726482}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:29,873] Trial 70 finished with value: 33593.67510203406 and parameters: {'n_estimators': 424, 'learning_rate': 0.038750590362114846, 'max_depth': 5, 'num_leaves': 32, 'subsample': 0.5787289433926509, 'colsample_bytree': 0.9539422372684129, 'reg_alpha': 1.7566228404171411, 'reg_lambda': 7.542295276355349}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:35,601] Trial 71 finished with value: 30873.709887999732 and parameters: {'n_estimators': 438, 'learning_rate': 0.04691809849420173, 'max_depth': 5, 'num_leaves': 37, 'subsample': 0.5573978062009144, 'colsample_bytree': 0.9656864625727776, 'reg_alpha': 6.5113134016235525, 'reg_lambda': 6.852831003030423}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:39,830] Trial 72 finished with value: 29689.037159004158 and parameters: {'n_estimators': 450, 'learning_rate': 0.04978096476376932, 'max_depth': 5, 'num_leaves': 41, 'subsample': 0.516733077837915, 'colsample_bytree': 0.9382340996786463, 'reg_alpha': 6.069297741044844, 'reg_lambda': 8.481151851094173}. Best is trial 41 with value: 29450.865364457753.\n",
      "[I 2024-11-10 00:06:43,805] Trial 73 finished with value: 29409.322681368 and parameters: {'n_estimators': 450, 'learning_rate': 0.049822113148944844, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.51956090741459, 'colsample_bytree': 0.9341156853653367, 'reg_alpha': 6.056451913926463, 'reg_lambda': 8.530066377434268}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:06:49,445] Trial 74 finished with value: 29917.799154354856 and parameters: {'n_estimators': 435, 'learning_rate': 0.04985748310810603, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.5174625962422914, 'colsample_bytree': 0.9333201336489426, 'reg_alpha': 6.001201292926153, 'reg_lambda': 8.819521456427431}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:06:55,239] Trial 75 finished with value: 31483.2570371813 and parameters: {'n_estimators': 447, 'learning_rate': 0.043177224094074505, 'max_depth': 5, 'num_leaves': 29, 'subsample': 0.5182385713551217, 'colsample_bytree': 0.9319288232878558, 'reg_alpha': 5.4049092961338285, 'reg_lambda': 6.040777714981273}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:06:59,806] Trial 76 finished with value: 30145.889487712724 and parameters: {'n_estimators': 436, 'learning_rate': 0.049194950198834055, 'max_depth': 5, 'num_leaves': 41, 'subsample': 0.49636776044058356, 'colsample_bytree': 0.9236134435524564, 'reg_alpha': 6.121285459165151, 'reg_lambda': 9.687027937222856}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:04,435] Trial 77 finished with value: 32510.846070852098 and parameters: {'n_estimators': 432, 'learning_rate': 0.041393392008835045, 'max_depth': 5, 'num_leaves': 38, 'subsample': 0.5161141186867045, 'colsample_bytree': 0.9217218940963036, 'reg_alpha': 5.0103722273267195, 'reg_lambda': 6.932269979147623}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:10,019] Trial 78 finished with value: 45663.19950455923 and parameters: {'n_estimators': 441, 'learning_rate': 0.011005380625899645, 'max_depth': 5, 'num_leaves': 33, 'subsample': 0.528606763652676, 'colsample_bytree': 0.9390326494403624, 'reg_alpha': 4.489001872357183, 'reg_lambda': 7.651538757859407}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:15,543] Trial 79 finished with value: 30951.565780041157 and parameters: {'n_estimators': 446, 'learning_rate': 0.049726497988392494, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.5461207856660051, 'colsample_bytree': 0.906874741238552, 'reg_alpha': 5.998271325689037, 'reg_lambda': 8.543273916096389}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:20,202] Trial 80 finished with value: 40500.98179450473 and parameters: {'n_estimators': 426, 'learning_rate': 0.037388762804438376, 'max_depth': 4, 'num_leaves': 46, 'subsample': 0.5102116157738402, 'colsample_bytree': 0.9879746282422531, 'reg_alpha': 2.5741311565086007, 'reg_lambda': 6.409571746314857}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:26,235] Trial 81 finished with value: 31987.656225953197 and parameters: {'n_estimators': 435, 'learning_rate': 0.04304649427147847, 'max_depth': 5, 'num_leaves': 41, 'subsample': 0.497623682917117, 'colsample_bytree': 0.9178693472498614, 'reg_alpha': 6.091897698399723, 'reg_lambda': 9.437408710593843}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:31,305] Trial 82 finished with value: 31029.45679680235 and parameters: {'n_estimators': 436, 'learning_rate': 0.04770403093545751, 'max_depth': 5, 'num_leaves': 39, 'subsample': 0.4921781601145314, 'colsample_bytree': 0.8957262614044946, 'reg_alpha': 5.414383152655259, 'reg_lambda': 9.99706451888998}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:36,361] Trial 83 finished with value: 29819.824210226132 and parameters: {'n_estimators': 447, 'learning_rate': 0.04930775076500344, 'max_depth': 5, 'num_leaves': 41, 'subsample': 0.4765469815918156, 'colsample_bytree': 0.9328292463749808, 'reg_alpha': 5.7066362509354835, 'reg_lambda': 8.84482470387865}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:40,240] Trial 84 finished with value: 31762.120470448506 and parameters: {'n_estimators': 447, 'learning_rate': 0.043310080262890134, 'max_depth': 5, 'num_leaves': 49, 'subsample': 0.47746367386561395, 'colsample_bytree': 0.9492568912672754, 'reg_alpha': 5.583285948480712, 'reg_lambda': 8.646185778399936}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:44,125] Trial 85 finished with value: 32923.01319183086 and parameters: {'n_estimators': 440, 'learning_rate': 0.039746403982706305, 'max_depth': 5, 'num_leaves': 36, 'subsample': 0.5064819388398383, 'colsample_bytree': 0.933636271728444, 'reg_alpha': 6.586066165056818, 'reg_lambda': 7.256940416591758}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:48,311] Trial 86 finished with value: 32419.434363818 and parameters: {'n_estimators': 384, 'learning_rate': 0.046114153682566106, 'max_depth': 5, 'num_leaves': 43, 'subsample': 0.48708336860695234, 'colsample_bytree': 0.9633598582783822, 'reg_alpha': 7.0924612344750475, 'reg_lambda': 7.762822547431131}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:53,331] Trial 87 finished with value: 42541.00227351389 and parameters: {'n_estimators': 450, 'learning_rate': 0.016904271463588146, 'max_depth': 5, 'num_leaves': 60, 'subsample': 0.47219302908366245, 'colsample_bytree': 0.911397025411807, 'reg_alpha': 5.700157143408025, 'reg_lambda': 8.3683636068363}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:07:56,825] Trial 88 finished with value: 32737.680550107165 and parameters: {'n_estimators': 359, 'learning_rate': 0.04981079216144317, 'max_depth': 5, 'num_leaves': 30, 'subsample': 0.4486396184596483, 'colsample_bytree': 0.8819163457665149, 'reg_alpha': 3.4349079571569416, 'reg_lambda': 9.088273844426574}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:01,791] Trial 89 finished with value: 40921.37530562589 and parameters: {'n_estimators': 442, 'learning_rate': 0.020414016644065936, 'max_depth': 5, 'num_leaves': 46, 'subsample': 0.524630943295158, 'colsample_bytree': 0.9435698167786496, 'reg_alpha': 4.560257960306451, 'reg_lambda': 7.180385171350783}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:07,330] Trial 90 finished with value: 32751.04229387136 and parameters: {'n_estimators': 421, 'learning_rate': 0.042502128018161466, 'max_depth': 5, 'num_leaves': 33, 'subsample': 0.5522789115021554, 'colsample_bytree': 0.9015423770090609, 'reg_alpha': 4.115139005133705, 'reg_lambda': 5.749803277043089}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:13,871] Trial 91 finished with value: 30494.083384634036 and parameters: {'n_estimators': 429, 'learning_rate': 0.049711868254902404, 'max_depth': 5, 'num_leaves': 39, 'subsample': 0.49765158967720596, 'colsample_bytree': 0.9300604619042286, 'reg_alpha': 6.269230897105308, 'reg_lambda': 9.62741263926798}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:19,258] Trial 92 finished with value: 29753.31041531514 and parameters: {'n_estimators': 447, 'learning_rate': 0.0475001282943574, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.4821417034206217, 'colsample_bytree': 0.9217695547658687, 'reg_alpha': 5.10036360792866, 'reg_lambda': 9.307309266481724}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:25,152] Trial 93 finished with value: 30857.553010719166 and parameters: {'n_estimators': 447, 'learning_rate': 0.0448642136414184, 'max_depth': 5, 'num_leaves': 35, 'subsample': 0.5135019488166469, 'colsample_bytree': 0.9744652896759609, 'reg_alpha': 5.111759932047522, 'reg_lambda': 8.910940581920581}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:30,486] Trial 94 finished with value: 30752.62942941384 and parameters: {'n_estimators': 442, 'learning_rate': 0.047203734300872935, 'max_depth': 5, 'num_leaves': 42, 'subsample': 0.4134862090555855, 'colsample_bytree': 0.95232764835358, 'reg_alpha': 7.602397441636752, 'reg_lambda': 8.24593866208192}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:35,033] Trial 95 finished with value: 31225.13885933351 and parameters: {'n_estimators': 446, 'learning_rate': 0.0447528310692506, 'max_depth': 5, 'num_leaves': 55, 'subsample': 0.48126741434666803, 'colsample_bytree': 0.9405757978842884, 'reg_alpha': 5.864235460783625, 'reg_lambda': 7.692575077480496}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:38,855] Trial 96 finished with value: 32930.17593251396 and parameters: {'n_estimators': 434, 'learning_rate': 0.04039937469458954, 'max_depth': 5, 'num_leaves': 45, 'subsample': 0.4602730759349308, 'colsample_bytree': 0.8882386421217401, 'reg_alpha': 7.228444034049159, 'reg_lambda': 9.396305743381408}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:44,597] Trial 97 finished with value: 34004.98095349866 and parameters: {'n_estimators': 324, 'learning_rate': 0.04723787085288091, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.4328840826892173, 'colsample_bytree': 0.9340963787334086, 'reg_alpha': 6.60915498392688, 'reg_lambda': 8.561765231422763}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:48,576] Trial 98 finished with value: 33575.24372453078 and parameters: {'n_estimators': 440, 'learning_rate': 0.0381367285900405, 'max_depth': 5, 'num_leaves': 49, 'subsample': 0.5017497519949704, 'colsample_bytree': 0.9211865383256687, 'reg_alpha': 1.211237209982207, 'reg_lambda': 8.079920103339148}. Best is trial 73 with value: 29409.322681368.\n",
      "[I 2024-11-10 00:08:51,505] Trial 99 finished with value: 36859.15813820043 and parameters: {'n_estimators': 304, 'learning_rate': 0.04238684103862892, 'max_depth': 5, 'num_leaves': 37, 'subsample': 0.48926586730213867, 'colsample_bytree': 0.9604665889591132, 'reg_alpha': 5.413293368370741, 'reg_lambda': 8.889583966943942}. Best is trial 73 with value: 29409.322681368.\n"
     ]
    }
   ],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "\n",
    "# Otimiza o modelo com a função objetivo\n",
    "study.optimize(objective_lightgbm, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_estimators': 450, 'learning_rate': 0.049822113148944844, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.51956090741459, 'colsample_bytree': 0.9341156853653367, 'reg_alpha': 6.056451913926463, 'reg_lambda': 8.530066377434268}\n",
      "\n",
      "Melhor MAE: 29409.3227\n"
     ]
    }
   ],
   "source": [
    "# Acessa o melhor MAE e os melhores parâmetros após a otimização\n",
    "mae_lightgbm = study.best_value\n",
    "params_lightgbm = study.best_params\n",
    "\n",
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Tunagem do modelo XGBoost com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgboost(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo XGBRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''   \n",
    "    model = XGBRegressor(\n",
    "        # Número de árvores (boosting rounds) no modelo, cada árvore corrige os erros da anterior\n",
    "        n_estimators=trial.suggest_int('n_estimators', 300, 450),        \n",
    "        # Taxa de aprendizado para ajustar o impacto de cada árvore\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.005, 0.05, log=True),        \n",
    "        # Limita a profundidade máxima de cada árvore, controlando o crescimento da árvore e prevenindo overfitting\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 5),        \n",
    "        # Número máximo de folhas em cada árvore. Controla a complexidade do modelo\n",
    "        max_leaves=trial.suggest_int('max_leaves', 20, 99),        \n",
    "        # Proporção de amostras usadas para treinar cada árvore, útil para prevenir overfitting\n",
    "        subsample=trial.suggest_float('subsample', 0.4, 0.7),        \n",
    "        # Proporção de colunas (features) usadas para construir cada árvore, ajuda a reduzir correlação entre árvores e evitar overfitting\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.7, 1.0),        \n",
    "        # Regularização L1 (Lasso), adiciona penalidade proporcional ao valor absoluto dos coeficientes, ajudando a reduzir o overfitting\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 1, 10, log=True),\n",
    "        # Regularização L2 (Ridge), adiciona penalidade proporcional ao quadrado dos coeficientes, ajudando a reduzir o overfitting\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 1, 10, log=True),\n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados\n",
    "        random_state=42,\n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Faz previsões no conjunto de teste e calcula as métricas\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-10 00:08:51,535] A new study created in memory with name: no-name-5144df34-71ca-4b81-8f39-d67fb79fa294\n",
      "[I 2024-11-10 00:08:55,927] Trial 0 finished with value: 35203.41371763931 and parameters: {'n_estimators': 356, 'learning_rate': 0.044635901521768134, 'max_depth': 5, 'max_leaves': 67, 'subsample': 0.44680559213273097, 'colsample_bytree': 0.7467983561008608, 'reg_alpha': 1.1430983876313219, 'reg_lambda': 7.348118405270449}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:00,072] Trial 1 finished with value: 48485.85009266873 and parameters: {'n_estimators': 390, 'learning_rate': 0.025529516046973785, 'max_depth': 3, 'max_leaves': 97, 'subsample': 0.6497327922401265, 'colsample_bytree': 0.7637017332034828, 'reg_alpha': 1.5199348301309807, 'reg_lambda': 1.5254729458052607}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:05,645] Trial 2 finished with value: 47823.71964918297 and parameters: {'n_estimators': 345, 'learning_rate': 0.016738881542579662, 'max_depth': 4, 'max_leaves': 43, 'subsample': 0.5835558684167138, 'colsample_bytree': 0.7418481581956126, 'reg_alpha': 1.9594972058679163, 'reg_lambda': 2.324672848950434}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:11,105] Trial 3 finished with value: 48007.74013238259 and parameters: {'n_estimators': 368, 'learning_rate': 0.030489195547657565, 'max_depth': 3, 'max_leaves': 61, 'subsample': 0.5777243706586127, 'colsample_bytree': 0.7139351238159993, 'reg_alpha': 4.050837781329674, 'reg_lambda': 1.4808945119975185}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:16,104] Trial 4 finished with value: 36756.99750394679 and parameters: {'n_estimators': 309, 'learning_rate': 0.044448339535094646, 'max_depth': 5, 'max_leaves': 84, 'subsample': 0.4913841307520112, 'colsample_bytree': 0.7293016342019151, 'reg_alpha': 4.833180632488465, 'reg_lambda': 2.7551959649510764}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:20,345] Trial 5 finished with value: 50661.20657396707 and parameters: {'n_estimators': 318, 'learning_rate': 0.015636765183901856, 'max_depth': 3, 'max_leaves': 92, 'subsample': 0.4776339944800051, 'colsample_bytree': 0.8987566853061946, 'reg_alpha': 2.0497980520950176, 'reg_lambda': 3.3118298880723813}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:28,870] Trial 6 finished with value: 49071.92753957105 and parameters: {'n_estimators': 382, 'learning_rate': 0.007652872182750091, 'max_depth': 5, 'max_leaves': 82, 'subsample': 0.6818496824692567, 'colsample_bytree': 0.9684482051282947, 'reg_alpha': 3.961867790406583, 'reg_lambda': 8.353610755311761}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:32,814] Trial 7 finished with value: 53926.31974450311 and parameters: {'n_estimators': 313, 'learning_rate': 0.007851504189403358, 'max_depth': 3, 'max_leaves': 46, 'subsample': 0.5166031869068446, 'colsample_bytree': 0.7814047095321688, 'reg_alpha': 6.741204610702761, 'reg_lambda': 2.273805573563182}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:37,707] Trial 8 finished with value: 50106.04340795017 and parameters: {'n_estimators': 342, 'learning_rate': 0.017444803725696106, 'max_depth': 3, 'max_leaves': 84, 'subsample': 0.4223651931039313, 'colsample_bytree': 0.9960660809801551, 'reg_alpha': 5.918951335463645, 'reg_lambda': 1.580213186410388}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:42,356] Trial 9 finished with value: 40572.03570611314 and parameters: {'n_estimators': 300, 'learning_rate': 0.03269124292259021, 'max_depth': 5, 'max_leaves': 78, 'subsample': 0.6313811040057837, 'colsample_bytree': 0.7222133955202271, 'reg_alpha': 2.2827887759905128, 'reg_lambda': 1.305777134899723}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:47,977] Trial 10 finished with value: 53431.71025513525 and parameters: {'n_estimators': 435, 'learning_rate': 0.0050695240451904405, 'max_depth': 4, 'max_leaves': 21, 'subsample': 0.4046103211984313, 'colsample_bytree': 0.831424278238549, 'reg_alpha': 1.035486013330949, 'reg_lambda': 9.46542023098865}. Best is trial 0 with value: 35203.41371763931.\n",
      "[I 2024-11-10 00:09:53,728] Trial 11 finished with value: 31540.797566923564 and parameters: {'n_estimators': 418, 'learning_rate': 0.049518201141865524, 'max_depth': 5, 'max_leaves': 67, 'subsample': 0.4700341430619077, 'colsample_bytree': 0.8185202661129731, 'reg_alpha': 8.89078944228278, 'reg_lambda': 5.277513379254598}. Best is trial 11 with value: 31540.797566923564.\n",
      "[I 2024-11-10 00:10:00,049] Trial 12 finished with value: 30909.99320288037 and parameters: {'n_estimators': 426, 'learning_rate': 0.04988585630056919, 'max_depth': 5, 'max_leaves': 64, 'subsample': 0.4519007388862893, 'colsample_bytree': 0.8093326909715368, 'reg_alpha': 9.879203603425442, 'reg_lambda': 5.3863470853067685}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:06,795] Trial 13 finished with value: 37861.322906735695 and parameters: {'n_estimators': 431, 'learning_rate': 0.049423555541083, 'max_depth': 4, 'max_leaves': 49, 'subsample': 0.5230161991843356, 'colsample_bytree': 0.8369630069952889, 'reg_alpha': 9.985330377627196, 'reg_lambda': 5.1119269985759335}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:13,423] Trial 14 finished with value: 40002.97889938166 and parameters: {'n_estimators': 410, 'learning_rate': 0.02303437500361535, 'max_depth': 5, 'max_leaves': 70, 'subsample': 0.4572227953605157, 'colsample_bytree': 0.8768075437408684, 'reg_alpha': 9.888163174719505, 'reg_lambda': 5.208333066451084}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:21,491] Trial 15 finished with value: 34462.7513974353 and parameters: {'n_estimators': 450, 'learning_rate': 0.03533580864333844, 'max_depth': 5, 'max_leaves': 57, 'subsample': 0.5416965885001604, 'colsample_bytree': 0.8138387267681632, 'reg_alpha': 7.45040168854269, 'reg_lambda': 4.632760409271543}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:26,845] Trial 16 finished with value: 48654.67803054361 and parameters: {'n_estimators': 410, 'learning_rate': 0.011232894046987978, 'max_depth': 4, 'max_leaves': 57, 'subsample': 0.4424752724957054, 'colsample_bytree': 0.9097593135009883, 'reg_alpha': 8.060630434380782, 'reg_lambda': 6.492435668624714}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:33,624] Trial 17 finished with value: 35434.17774636903 and parameters: {'n_estimators': 406, 'learning_rate': 0.03750708566708119, 'max_depth': 5, 'max_leaves': 33, 'subsample': 0.49288166861967214, 'colsample_bytree': 0.794824239795712, 'reg_alpha': 5.389808390823125, 'reg_lambda': 3.696259715560619}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:38,867] Trial 18 finished with value: 44242.410632183564 and parameters: {'n_estimators': 427, 'learning_rate': 0.024101711355929086, 'max_depth': 4, 'max_leaves': 71, 'subsample': 0.5620285060340782, 'colsample_bytree': 0.8638038249098459, 'reg_alpha': 3.5580648620971487, 'reg_lambda': 6.258621517840355}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:45,007] Trial 19 finished with value: 32196.443758184025 and parameters: {'n_estimators': 450, 'learning_rate': 0.04147087158403985, 'max_depth': 5, 'max_leaves': 39, 'subsample': 0.4034019784250794, 'colsample_bytree': 0.9238414929418803, 'reg_alpha': 8.449731903136302, 'reg_lambda': 4.126029527363758}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:50,169] Trial 20 finished with value: 38239.55769240408 and parameters: {'n_estimators': 399, 'learning_rate': 0.029029791605418145, 'max_depth': 5, 'max_leaves': 53, 'subsample': 0.46547981148922096, 'colsample_bytree': 0.8156812524479168, 'reg_alpha': 2.794615145845252, 'reg_lambda': 6.162924772504557}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:10:55,677] Trial 21 finished with value: 32147.152502522662 and parameters: {'n_estimators': 450, 'learning_rate': 0.039940222672378185, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.4046877793323705, 'colsample_bytree': 0.9364881302341647, 'reg_alpha': 8.238783750576555, 'reg_lambda': 3.9203867850885996}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:00,539] Trial 22 finished with value: 31769.646276974825 and parameters: {'n_estimators': 421, 'learning_rate': 0.048345279089377614, 'max_depth': 5, 'max_leaves': 29, 'subsample': 0.4279155128533614, 'colsample_bytree': 0.9432936457127994, 'reg_alpha': 6.542829100532306, 'reg_lambda': 2.825133366496708}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:05,914] Trial 23 finished with value: 37954.15507017565 and parameters: {'n_estimators': 422, 'learning_rate': 0.04919839159503352, 'max_depth': 4, 'max_leaves': 21, 'subsample': 0.4319812762969611, 'colsample_bytree': 0.8570947908951391, 'reg_alpha': 6.05951891883103, 'reg_lambda': 2.789252182427791}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:12,326] Trial 24 finished with value: 40958.2223699908 and parameters: {'n_estimators': 416, 'learning_rate': 0.02062561754817034, 'max_depth': 5, 'max_leaves': 62, 'subsample': 0.5081933572384011, 'colsample_bytree': 0.8835937762587203, 'reg_alpha': 4.707323463483243, 'reg_lambda': 1.8774668555345246}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:20,867] Trial 25 finished with value: 35936.9884665377 and parameters: {'n_estimators': 393, 'learning_rate': 0.03478796217420472, 'max_depth': 5, 'max_leaves': 31, 'subsample': 0.47512824494776307, 'colsample_bytree': 0.9578413080061283, 'reg_alpha': 6.856675713159553, 'reg_lambda': 1.0459598991413275}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:28,705] Trial 26 finished with value: 38190.110184696285 and parameters: {'n_estimators': 436, 'learning_rate': 0.04904197596235994, 'max_depth': 4, 'max_leaves': 77, 'subsample': 0.42616816511146705, 'colsample_bytree': 0.7845428953591125, 'reg_alpha': 9.64294690729266, 'reg_lambda': 3.032560127023098}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:35,320] Trial 27 finished with value: 39170.57744299195 and parameters: {'n_estimators': 379, 'learning_rate': 0.027664924951990254, 'max_depth': 5, 'max_leaves': 66, 'subsample': 0.4933138495997036, 'colsample_bytree': 0.8150124216127118, 'reg_alpha': 7.536555790206149, 'reg_lambda': 4.702586828823185}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:41,737] Trial 28 finished with value: 44422.67091252236 and parameters: {'n_estimators': 421, 'learning_rate': 0.01352691293703268, 'max_depth': 5, 'max_leaves': 52, 'subsample': 0.4536438538837987, 'colsample_bytree': 0.8358810558063016, 'reg_alpha': 6.3991532507783075, 'reg_lambda': 2.255129164787948}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:47,598] Trial 29 finished with value: 33780.98976910823 and parameters: {'n_estimators': 440, 'learning_rate': 0.04117429757967301, 'max_depth': 5, 'max_leaves': 67, 'subsample': 0.4403324545594951, 'colsample_bytree': 0.7581716712215739, 'reg_alpha': 5.161560009259255, 'reg_lambda': 7.819992933324456}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:52,251] Trial 30 finished with value: 45909.30772445681 and parameters: {'n_estimators': 367, 'learning_rate': 0.020345270788817107, 'max_depth': 4, 'max_leaves': 28, 'subsample': 0.5472512594918983, 'colsample_bytree': 0.9839625847733349, 'reg_alpha': 8.738998334918978, 'reg_lambda': 5.8781907128362825}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:11:58,188] Trial 31 finished with value: 32632.71943637876 and parameters: {'n_estimators': 446, 'learning_rate': 0.0392536511742704, 'max_depth': 5, 'max_leaves': 38, 'subsample': 0.40191386806498436, 'colsample_bytree': 0.9412011605099682, 'reg_alpha': 8.422608375069169, 'reg_lambda': 3.7656182327369847}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:04,066] Trial 32 finished with value: 33106.15247809351 and parameters: {'n_estimators': 439, 'learning_rate': 0.04257286806880175, 'max_depth': 5, 'max_leaves': 28, 'subsample': 0.42153468932546634, 'colsample_bytree': 0.9347398194069853, 'reg_alpha': 7.466152771133849, 'reg_lambda': 4.206816622276199}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:11,592] Trial 33 finished with value: 31479.53466695181 and parameters: {'n_estimators': 399, 'learning_rate': 0.04965058205247995, 'max_depth': 5, 'max_leaves': 40, 'subsample': 0.4498448481380984, 'colsample_bytree': 0.9564777266183477, 'reg_alpha': 8.967757963267264, 'reg_lambda': 3.408674464046907}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:17,250] Trial 34 finished with value: 36492.73160331276 and parameters: {'n_estimators': 395, 'learning_rate': 0.03247817024403815, 'max_depth': 5, 'max_leaves': 63, 'subsample': 0.45905161233431496, 'colsample_bytree': 0.9560068493142956, 'reg_alpha': 1.4223876635047692, 'reg_lambda': 3.4383860282242527}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:24,082] Trial 35 finished with value: 32732.438704546534 and parameters: {'n_estimators': 402, 'learning_rate': 0.04920201381102927, 'max_depth': 5, 'max_leaves': 44, 'subsample': 0.6166883721480609, 'colsample_bytree': 0.7016375726131938, 'reg_alpha': 9.24992002933704, 'reg_lambda': 2.678910383874584}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:31,056] Trial 36 finished with value: 34211.37511263411 and parameters: {'n_estimators': 417, 'learning_rate': 0.045458683676425436, 'max_depth': 5, 'max_leaves': 26, 'subsample': 0.48050420021797385, 'colsample_bytree': 0.9062152245477457, 'reg_alpha': 4.395649965031417, 'reg_lambda': 7.183833527030535}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:37,410] Trial 37 finished with value: 36660.061224904384 and parameters: {'n_estimators': 388, 'learning_rate': 0.03594645313196364, 'max_depth': 5, 'max_leaves': 95, 'subsample': 0.4374560763381275, 'colsample_bytree': 0.7716856410177003, 'reg_alpha': 5.6609223328805856, 'reg_lambda': 5.378544533441021}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:44,966] Trial 38 finished with value: 37306.99719544685 and parameters: {'n_estimators': 428, 'learning_rate': 0.027566216465068467, 'max_depth': 5, 'max_leaves': 74, 'subsample': 0.508659893647467, 'colsample_bytree': 0.9757204318702486, 'reg_alpha': 6.92035282452562, 'reg_lambda': 3.162953887341045}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:50,972] Trial 39 finished with value: 40619.88158007467 and parameters: {'n_estimators': 364, 'learning_rate': 0.043285964920839616, 'max_depth': 4, 'max_leaves': 88, 'subsample': 0.5307151868993226, 'colsample_bytree': 0.8882147815607762, 'reg_alpha': 3.1446565092677, 'reg_lambda': 1.938449371042694}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:12:57,757] Trial 40 finished with value: 37424.48505195605 and parameters: {'n_estimators': 410, 'learning_rate': 0.030953239159716806, 'max_depth': 5, 'max_leaves': 57, 'subsample': 0.4737145646709499, 'colsample_bytree': 0.7419061164056844, 'reg_alpha': 8.950612089344618, 'reg_lambda': 2.589793692372855}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:04,446] Trial 41 finished with value: 33912.25941956364 and parameters: {'n_estimators': 424, 'learning_rate': 0.03879328105340593, 'max_depth': 5, 'max_leaves': 39, 'subsample': 0.4161542103959312, 'colsample_bytree': 0.9242789695512352, 'reg_alpha': 7.846128247523165, 'reg_lambda': 4.213910425896942}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:13,007] Trial 42 finished with value: 31705.681945702945 and parameters: {'n_estimators': 442, 'learning_rate': 0.04431095315975764, 'max_depth': 5, 'max_leaves': 35, 'subsample': 0.44469421695166617, 'colsample_bytree': 0.946689689170191, 'reg_alpha': 6.598694877601177, 'reg_lambda': 3.714421395636134}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:19,722] Trial 43 finished with value: 31186.65448347765 and parameters: {'n_estimators': 441, 'learning_rate': 0.04518778014531143, 'max_depth': 5, 'max_leaves': 34, 'subsample': 0.446517560798164, 'colsample_bytree': 0.9996271720049044, 'reg_alpha': 6.4103923128636415, 'reg_lambda': 4.648925073163158}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:28,247] Trial 44 finished with value: 31524.248263512116 and parameters: {'n_estimators': 432, 'learning_rate': 0.04425542045682447, 'max_depth': 5, 'max_leaves': 34, 'subsample': 0.4504712920148808, 'colsample_bytree': 0.9923966841884021, 'reg_alpha': 7.169333812158292, 'reg_lambda': 4.777738633543555}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:35,060] Trial 45 finished with value: 34606.88531579964 and parameters: {'n_estimators': 431, 'learning_rate': 0.03389309775773265, 'max_depth': 5, 'max_leaves': 43, 'subsample': 0.4865325829664751, 'colsample_bytree': 0.9994072099221158, 'reg_alpha': 9.143076111549616, 'reg_lambda': 4.708487225763249}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:38,677] Trial 46 finished with value: 52446.25088284753 and parameters: {'n_estimators': 347, 'learning_rate': 0.008662663173557142, 'max_depth': 3, 'max_leaves': 49, 'subsample': 0.46918436759478965, 'colsample_bytree': 0.9859984198374818, 'reg_alpha': 7.408543677576698, 'reg_lambda': 7.003381570642921}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:43,351] Trial 47 finished with value: 32611.2576521947 and parameters: {'n_estimators': 415, 'learning_rate': 0.044609486334648445, 'max_depth': 5, 'max_leaves': 46, 'subsample': 0.4524502428300758, 'colsample_bytree': 0.9614262826804442, 'reg_alpha': 9.904625861468665, 'reg_lambda': 9.02173702244117}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:47,006] Trial 48 finished with value: 42233.75401645 and parameters: {'n_estimators': 329, 'learning_rate': 0.037573596726647035, 'max_depth': 4, 'max_leaves': 24, 'subsample': 0.45874524986764587, 'colsample_bytree': 0.9754486001118226, 'reg_alpha': 6.073818331727505, 'reg_lambda': 5.569197100026852}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:13:53,089] Trial 49 finished with value: 50013.733269660646 and parameters: {'n_estimators': 432, 'learning_rate': 0.0062639590466356445, 'max_depth': 5, 'max_leaves': 33, 'subsample': 0.5009651537032953, 'colsample_bytree': 0.7927220197364135, 'reg_alpha': 3.977469078969849, 'reg_lambda': 4.879222635380706}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:02,002] Trial 50 finished with value: 36711.855098093394 and parameters: {'n_estimators': 405, 'learning_rate': 0.030804953853672393, 'max_depth': 5, 'max_leaves': 42, 'subsample': 0.6814380479649939, 'colsample_bytree': 0.9889650990515579, 'reg_alpha': 5.227573555110292, 'reg_lambda': 6.685413997565711}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:10,352] Trial 51 finished with value: 31479.40820012478 and parameters: {'n_estimators': 444, 'learning_rate': 0.04495190907375624, 'max_depth': 5, 'max_leaves': 34, 'subsample': 0.4455392282079868, 'colsample_bytree': 0.9739443602315382, 'reg_alpha': 6.907949728185973, 'reg_lambda': 3.5788352232800027}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:17,886] Trial 52 finished with value: 31477.59543245421 and parameters: {'n_estimators': 441, 'learning_rate': 0.04560866829964182, 'max_depth': 5, 'max_leaves': 35, 'subsample': 0.4140746037851659, 'colsample_bytree': 0.9702761394439829, 'reg_alpha': 8.25377371398372, 'reg_lambda': 4.40431081982991}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:25,679] Trial 53 finished with value: 31088.54103159287 and parameters: {'n_estimators': 444, 'learning_rate': 0.0455651885451128, 'max_depth': 5, 'max_leaves': 35, 'subsample': 0.4169270155998279, 'colsample_bytree': 0.9715640929916771, 'reg_alpha': 7.2640612702751515, 'reg_lambda': 4.404713129369994}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:32,453] Trial 54 finished with value: 33257.798804153164 and parameters: {'n_estimators': 442, 'learning_rate': 0.038188782177417904, 'max_depth': 5, 'max_leaves': 41, 'subsample': 0.41457550520820907, 'colsample_bytree': 0.9701216341495538, 'reg_alpha': 8.29338908021088, 'reg_lambda': 3.5307486097412317}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:38,580] Trial 55 finished with value: 33004.7777157947 and parameters: {'n_estimators': 445, 'learning_rate': 0.045919741381079016, 'max_depth': 5, 'max_leaves': 25, 'subsample': 0.4127953279715559, 'colsample_bytree': 0.9657120748577219, 'reg_alpha': 5.693902011797129, 'reg_lambda': 4.194219237040201}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:44,864] Trial 56 finished with value: 34224.99966580457 and parameters: {'n_estimators': 437, 'learning_rate': 0.03522890620734062, 'max_depth': 5, 'max_leaves': 32, 'subsample': 0.43335674965649484, 'colsample_bytree': 0.9779560708088508, 'reg_alpha': 7.985412140549429, 'reg_lambda': 4.474592938721351}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:51,302] Trial 57 finished with value: 32030.699160436423 and parameters: {'n_estimators': 446, 'learning_rate': 0.04105041926437639, 'max_depth': 5, 'max_leaves': 35, 'subsample': 0.44167062204226193, 'colsample_bytree': 0.9999044083184544, 'reg_alpha': 4.735130000958406, 'reg_lambda': 3.131085526388514}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:14:56,244] Trial 58 finished with value: 50773.3321534203 and parameters: {'n_estimators': 436, 'learning_rate': 0.011158453583883367, 'max_depth': 3, 'max_leaves': 48, 'subsample': 0.42608651739721787, 'colsample_bytree': 0.951842799156475, 'reg_alpha': 2.207564807085514, 'reg_lambda': 5.789810484365566}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:15:02,808] Trial 59 finished with value: 31937.36794609711 and parameters: {'n_estimators': 426, 'learning_rate': 0.046043037802151965, 'max_depth': 5, 'max_leaves': 30, 'subsample': 0.6063767086022466, 'colsample_bytree': 0.9249301051605391, 'reg_alpha': 6.946343685564327, 'reg_lambda': 3.4202604849974128}. Best is trial 12 with value: 30909.99320288037.\n",
      "[I 2024-11-10 00:15:09,896] Trial 60 finished with value: 29898.70660474665 and parameters: {'n_estimators': 450, 'learning_rate': 0.04991816070960025, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.4127560059076609, 'colsample_bytree': 0.9624760048803387, 'reg_alpha': 1.668200985120503, 'reg_lambda': 5.196909694919349}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:16,736] Trial 61 finished with value: 30034.83052510069 and parameters: {'n_estimators': 445, 'learning_rate': 0.049558354660087824, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.4166276946358337, 'colsample_bytree': 0.965309616162559, 'reg_alpha': 1.6598221086874305, 'reg_lambda': 3.980061816335203}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:22,862] Trial 62 finished with value: 31969.724576986715 and parameters: {'n_estimators': 449, 'learning_rate': 0.041157796371717445, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.41080913881533676, 'colsample_bytree': 0.9826714731137688, 'reg_alpha': 1.835450680955713, 'reg_lambda': 5.131535723041324}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:30,781] Trial 63 finished with value: 31382.374066180844 and parameters: {'n_estimators': 445, 'learning_rate': 0.04660463974711837, 'max_depth': 5, 'max_leaves': 36, 'subsample': 0.420731823601619, 'colsample_bytree': 0.8459277751427629, 'reg_alpha': 1.4850439373539317, 'reg_lambda': 3.948760158970517}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:38,076] Trial 64 finished with value: 33577.169006575416 and parameters: {'n_estimators': 450, 'learning_rate': 0.037439216777861974, 'max_depth': 5, 'max_leaves': 53, 'subsample': 0.42067420128071004, 'colsample_bytree': 0.8445701251958976, 'reg_alpha': 1.320198246736673, 'reg_lambda': 4.421607220753172}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:43,256] Trial 65 finished with value: 31431.011553381137 and parameters: {'n_estimators': 439, 'learning_rate': 0.04717215808091727, 'max_depth': 5, 'max_leaves': 45, 'subsample': 0.40129318107670603, 'colsample_bytree': 0.8582526346413301, 'reg_alpha': 1.720047050351023, 'reg_lambda': 3.8864603321726707}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:48,211] Trial 66 finished with value: 31049.87738939923 and parameters: {'n_estimators': 434, 'learning_rate': 0.04968859065570325, 'max_depth': 5, 'max_leaves': 47, 'subsample': 0.4017739417030179, 'colsample_bytree': 0.8266154703313175, 'reg_alpha': 1.705112169342085, 'reg_lambda': 3.820035204213378}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:53,196] Trial 67 finished with value: 31449.816396856342 and parameters: {'n_estimators': 433, 'learning_rate': 0.0497491876155121, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.43143607850572196, 'colsample_bytree': 0.825870487249788, 'reg_alpha': 1.1758322929329836, 'reg_lambda': 4.005798200719511}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:15:58,201] Trial 68 finished with value: 33522.61563251258 and parameters: {'n_estimators': 428, 'learning_rate': 0.0414654875113432, 'max_depth': 5, 'max_leaves': 59, 'subsample': 0.4062026545199413, 'colsample_bytree': 0.801763261063877, 'reg_alpha': 1.7609124411558859, 'reg_lambda': 5.108637006008193}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:03,446] Trial 69 finished with value: 35530.14492077076 and parameters: {'n_estimators': 446, 'learning_rate': 0.0328306681661535, 'max_depth': 5, 'max_leaves': 49, 'subsample': 0.4322249469445622, 'colsample_bytree': 0.8066200992278528, 'reg_alpha': 1.5504148782652285, 'reg_lambda': 6.024107181263595}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:09,758] Trial 70 finished with value: 35390.600189858334 and parameters: {'n_estimators': 436, 'learning_rate': 0.042667074612775656, 'max_depth': 5, 'max_leaves': 23, 'subsample': 0.5682644445949946, 'colsample_bytree': 0.8659872008392463, 'reg_alpha': 2.711810330695183, 'reg_lambda': 4.93716160464691}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:16,336] Trial 71 finished with value: 31086.61432420763 and parameters: {'n_estimators': 441, 'learning_rate': 0.04739164638306395, 'max_depth': 5, 'max_leaves': 46, 'subsample': 0.4013491218258844, 'colsample_bytree': 0.8478928263634461, 'reg_alpha': 1.5785042572647172, 'reg_lambda': 3.961762525123528}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:22,247] Trial 72 finished with value: 31016.96214853836 and parameters: {'n_estimators': 442, 'learning_rate': 0.04977724180599821, 'max_depth': 5, 'max_leaves': 41, 'subsample': 0.4200393703412659, 'colsample_bytree': 0.8469607119477247, 'reg_alpha': 1.6230896195854099, 'reg_lambda': 5.532247777338939}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:28,714] Trial 73 finished with value: 31044.02105123707 and parameters: {'n_estimators': 428, 'learning_rate': 0.04982225577542532, 'max_depth': 5, 'max_leaves': 46, 'subsample': 0.4109045905658725, 'colsample_bytree': 0.8251218410071354, 'reg_alpha': 2.035021824152052, 'reg_lambda': 5.460447704370876}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:33,755] Trial 74 finished with value: 31310.397056537764 and parameters: {'n_estimators': 426, 'learning_rate': 0.049853978960074374, 'max_depth': 5, 'max_leaves': 55, 'subsample': 0.40220384910382545, 'colsample_bytree': 0.8301386259296661, 'reg_alpha': 1.6201658507285637, 'reg_lambda': 5.556959309980526}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:40,059] Trial 75 finished with value: 33892.21188836409 and parameters: {'n_estimators': 420, 'learning_rate': 0.040050030502190075, 'max_depth': 5, 'max_leaves': 64, 'subsample': 0.4238805861400927, 'colsample_bytree': 0.8198237719837903, 'reg_alpha': 2.031409766957656, 'reg_lambda': 7.8321251976705835}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:45,457] Trial 76 finished with value: 32674.693076220723 and parameters: {'n_estimators': 430, 'learning_rate': 0.042292684801163404, 'max_depth': 5, 'max_leaves': 47, 'subsample': 0.41119736043441996, 'colsample_bytree': 0.8722833924289378, 'reg_alpha': 1.3501388276718553, 'reg_lambda': 5.307145607371195}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:50,261] Trial 77 finished with value: 43306.70685643114 and parameters: {'n_estimators': 413, 'learning_rate': 0.015828936188404103, 'max_depth': 5, 'max_leaves': 51, 'subsample': 0.40692290167881195, 'colsample_bytree': 0.8390279389269051, 'reg_alpha': 2.4272929242416574, 'reg_lambda': 6.663333438785495}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:16:55,839] Trial 78 finished with value: 31744.283014665518 and parameters: {'n_estimators': 435, 'learning_rate': 0.04746243672797703, 'max_depth': 5, 'max_leaves': 41, 'subsample': 0.4165451048159343, 'colsample_bytree': 0.8091735478745798, 'reg_alpha': 1.2298241791499083, 'reg_lambda': 5.86400665959505}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:00,370] Trial 79 finished with value: 40947.92506918022 and parameters: {'n_estimators': 424, 'learning_rate': 0.03652046613629693, 'max_depth': 4, 'max_leaves': 44, 'subsample': 0.43883581773491037, 'colsample_bytree': 0.8553891625088854, 'reg_alpha': 1.9151081175841633, 'reg_lambda': 6.313698712862715}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:05,263] Trial 80 finished with value: 41296.70459198386 and parameters: {'n_estimators': 439, 'learning_rate': 0.018719101305645174, 'max_depth': 5, 'max_leaves': 70, 'subsample': 0.42819544457110464, 'colsample_bytree': 0.8283756571108973, 'reg_alpha': 1.0286380060878983, 'reg_lambda': 2.946740972816514}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:12,209] Trial 81 finished with value: 31343.21590254243 and parameters: {'n_estimators': 450, 'learning_rate': 0.04671698553334947, 'max_depth': 5, 'max_leaves': 40, 'subsample': 0.4633176989071903, 'colsample_bytree': 0.8519221859059412, 'reg_alpha': 1.655228605947757, 'reg_lambda': 4.569233646120296}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:18,795] Trial 82 finished with value: 33426.12283686402 and parameters: {'n_estimators': 441, 'learning_rate': 0.03925751243736683, 'max_depth': 5, 'max_leaves': 31, 'subsample': 0.4210022852788673, 'colsample_bytree': 0.8380250457461365, 'reg_alpha': 2.24622318154463, 'reg_lambda': 4.302037134197931}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:27,026] Trial 83 finished with value: 32270.7162565248 and parameters: {'n_estimators': 434, 'learning_rate': 0.044284602129675645, 'max_depth': 5, 'max_leaves': 51, 'subsample': 0.40869435161497364, 'colsample_bytree': 0.8232415216179391, 'reg_alpha': 1.4452371529332242, 'reg_lambda': 4.896135517388809}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:35,032] Trial 84 finished with value: 30883.28594643576 and parameters: {'n_estimators': 443, 'learning_rate': 0.047314392563907307, 'max_depth': 5, 'max_leaves': 43, 'subsample': 0.4377143975932164, 'colsample_bytree': 0.8689992302758686, 'reg_alpha': 1.8753763275131685, 'reg_lambda': 5.5854625121539145}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:41,272] Trial 85 finished with value: 30823.395670312755 and parameters: {'n_estimators': 446, 'learning_rate': 0.04788006840864847, 'max_depth': 5, 'max_leaves': 43, 'subsample': 0.4372228146032649, 'colsample_bytree': 0.894969814788577, 'reg_alpha': 2.1162425425387332, 'reg_lambda': 5.481921895405149}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:45,623] Trial 86 finished with value: 35293.619288747934 and parameters: {'n_estimators': 300, 'learning_rate': 0.048273807186866635, 'max_depth': 5, 'max_leaves': 43, 'subsample': 0.40010570140573093, 'colsample_bytree': 0.8813039334800394, 'reg_alpha': 2.0786114384428664, 'reg_lambda': 5.67327661294802}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:51,298] Trial 87 finished with value: 33305.898275183776 and parameters: {'n_estimators': 437, 'learning_rate': 0.04272227248800798, 'max_depth': 5, 'max_leaves': 46, 'subsample': 0.4321971714131011, 'colsample_bytree': 0.7961718844279078, 'reg_alpha': 1.834593723867005, 'reg_lambda': 7.640282042307227}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:17:57,026] Trial 88 finished with value: 30216.442591152194 and parameters: {'n_estimators': 447, 'learning_rate': 0.04977135268190944, 'max_depth': 5, 'max_leaves': 60, 'subsample': 0.43821898316541613, 'colsample_bytree': 0.8964198905392511, 'reg_alpha': 1.5649540741821613, 'reg_lambda': 5.385279983279971}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:02,828] Trial 89 finished with value: 30217.0962506948 and parameters: {'n_estimators': 448, 'learning_rate': 0.04951269653115521, 'max_depth': 5, 'max_leaves': 60, 'subsample': 0.43699443743389993, 'colsample_bytree': 0.8976979848900158, 'reg_alpha': 1.6931711745341063, 'reg_lambda': 6.94761935678103}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:09,320] Trial 90 finished with value: 33070.52759967828 and parameters: {'n_estimators': 447, 'learning_rate': 0.03960061606790371, 'max_depth': 5, 'max_leaves': 66, 'subsample': 0.4616343861650218, 'colsample_bytree': 0.8956822492989875, 'reg_alpha': 2.457029602120638, 'reg_lambda': 8.660780180138728}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:16,401] Trial 91 finished with value: 30440.667316010215 and parameters: {'n_estimators': 450, 'learning_rate': 0.049706642451971275, 'max_depth': 5, 'max_leaves': 60, 'subsample': 0.4423746657056238, 'colsample_bytree': 0.9161543549750307, 'reg_alpha': 1.9330207686260252, 'reg_lambda': 6.9285938154761695}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:23,721] Trial 92 finished with value: 32252.81692226227 and parameters: {'n_estimators': 448, 'learning_rate': 0.04309909008703671, 'max_depth': 5, 'max_leaves': 60, 'subsample': 0.46846597539603474, 'colsample_bytree': 0.9116940949934936, 'reg_alpha': 2.126451259591238, 'reg_lambda': 7.041193424176715}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:30,801] Trial 93 finished with value: 30825.655579150032 and parameters: {'n_estimators': 444, 'learning_rate': 0.04775646704067311, 'max_depth': 5, 'max_leaves': 57, 'subsample': 0.43915070632116776, 'colsample_bytree': 0.8918334410734248, 'reg_alpha': 1.9321748855870442, 'reg_lambda': 6.324783684627137}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:37,911] Trial 94 finished with value: 32247.374790396098 and parameters: {'n_estimators': 444, 'learning_rate': 0.043479822739149784, 'max_depth': 5, 'max_leaves': 62, 'subsample': 0.43685175556563693, 'colsample_bytree': 0.8924313340087026, 'reg_alpha': 1.8193420376342702, 'reg_lambda': 6.301369853656891}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:43,680] Trial 95 finished with value: 44166.14563015206 and parameters: {'n_estimators': 448, 'learning_rate': 0.012977236870369325, 'max_depth': 5, 'max_leaves': 58, 'subsample': 0.45308874436032015, 'colsample_bytree': 0.9031611080087266, 'reg_alpha': 1.930809030363555, 'reg_lambda': 6.714974396706431}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:49,265] Trial 96 finished with value: 33009.36699694592 and parameters: {'n_estimators': 444, 'learning_rate': 0.04041893341999361, 'max_depth': 5, 'max_leaves': 55, 'subsample': 0.4451356598125356, 'colsample_bytree': 0.8770346118410546, 'reg_alpha': 1.4006741282453274, 'reg_lambda': 8.262638428362786}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:54,243] Trial 97 finished with value: 31115.72725436369 and parameters: {'n_estimators': 450, 'learning_rate': 0.04719893085233279, 'max_depth': 5, 'max_leaves': 65, 'subsample': 0.4402016342495915, 'colsample_bytree': 0.9320722431084374, 'reg_alpha': 1.516263413375081, 'reg_lambda': 9.563294071860433}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:18:59,190] Trial 98 finished with value: 38832.39048165723 and parameters: {'n_estimators': 438, 'learning_rate': 0.024340597078261535, 'max_depth': 5, 'max_leaves': 69, 'subsample': 0.45488109521159187, 'colsample_bytree': 0.9150167895424766, 'reg_alpha': 2.409169613228285, 'reg_lambda': 7.331052446129564}. Best is trial 60 with value: 29898.70660474665.\n",
      "[I 2024-11-10 00:19:04,013] Trial 99 finished with value: 31597.92193024088 and parameters: {'n_estimators': 443, 'learning_rate': 0.04443878106054573, 'max_depth': 5, 'max_leaves': 74, 'subsample': 0.4275324519196728, 'colsample_bytree': 0.8868457233833849, 'reg_alpha': 3.382591675154747, 'reg_lambda': 6.185166473690491}. Best is trial 60 with value: 29898.70660474665.\n"
     ]
    }
   ],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "\n",
    "# Otimiza o modelo com a função objetivo\n",
    "study.optimize(objective_xgboost, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_estimators': 450, 'learning_rate': 0.04991816070960025, 'max_depth': 5, 'max_leaves': 37, 'subsample': 0.4127560059076609, 'colsample_bytree': 0.9624760048803387, 'reg_alpha': 1.668200985120503, 'reg_lambda': 5.196909694919349}\n",
      "\n",
      "Melhor MAE: 29898.7066\n"
     ]
    }
   ],
   "source": [
    "# Acessa o melhor MAE e os melhores parâmetros após a otimização\n",
    "mae_xgboost = study.best_value\n",
    "params_xgboost = study.best_params\n",
    "\n",
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvando os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Salvando e testando o desempenho dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(best_model, file_name, model_name):\n",
    "    '''\n",
    "    Treina um modelo com os melhores hiperparâmetros, salva o pipeline treinado \n",
    "    em um arquivo e avalia o desempenho no conjunto de teste.\n",
    "\n",
    "    :param best_model: Estimator object\n",
    "        O modelo otimizado com os melhores hiperparâmetros a ser treinado.\n",
    "    :param file_name: str\n",
    "        Nome do arquivo para salvar o pipeline treinado (formato .pkl).\n",
    "    :param model_name: str\n",
    "        Nome do modelo para identificação nos resultados.\n",
    "\n",
    "    :return: list\n",
    "        Lista contendo o nome do modelo, o RMSE e o MAE calculados no conjunto \n",
    "        de teste, para avaliação do desempenho.\n",
    "    '''\n",
    "    results = []\n",
    "    \n",
    "    # Recriando o pipeline com os melhores hiperpârametros\n",
    "    pipeline_best_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                          ('model', best_model)])\n",
    "    \n",
    "    # Treinando o pipeline final no conjunto de treinamento\n",
    "    pipeline_best_model.fit(X_train, y_train)\n",
    "    \n",
    "    try:\n",
    "        # Salvando o pipeline em um arquivo .pkl\n",
    "        joblib.dump(pipeline_best_model, f'modelos/{file_name}.pkl')\n",
    "        print(f'Arquivo {file_name}.pkl gerado com sucesso!')\n",
    "    except Exception as e:\n",
    "        print(f'Erro ao salvar o pipeline: {e}')\n",
    "        \n",
    "    # Previsões e cálculo das métricas no conjunto de treino\n",
    "    train_predictions = pipeline_best_model.predict(X_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "    train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "    \n",
    "    # Previsões e cálculo das métricas no conjunto de teste\n",
    "    test_predictions = pipeline_best_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    # Adiciona previsões em teste a lista\n",
    "    results.append((\n",
    "        model_name, train_rmse, test_rmse, train_mae, test_mae\n",
    "    ))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo pipeline_best_model_lightgbm.pkl gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros otimizados para o LightGBM\n",
    "best_params = params_lightgbm\n",
    "\n",
    "# Cria o modelo com os melhores hiperparâmetros\n",
    "best_model = lgb.LGBMRegressor(**best_params, verbose=-1)\n",
    "\n",
    "# Treina o modelo e salva o pipeline treinado em um arquivo .pkl\n",
    "results_lightgbm = train_and_save_model(best_model, 'pipeline_best_model_lightgbm', 'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo pipeline_best_model_xgboost.pkl gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros otimizados para o XGBoost\n",
    "best_params = params_xgboost\n",
    "\n",
    "# Cria o modelo com os melhores hiperparâmetros\n",
    "best_model = XGBRegressor(**best_params, verbosity=0)\n",
    "\n",
    "# Treina o modelo e salva o pipeline treinado em um arquivo .pkl\n",
    "results_xgboost = train_and_save_model(best_model, 'pipeline_best_model_xgboost', 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Comparativo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas para o DataFrame\n",
    "columns = ['Modelo', 'RMSE em treino', 'RMSE em teste', 'MAE em treino', 'MAE em teste']\n",
    "\n",
    "# Criando DataFrames com os resultados dos modelos LightGBM e XGBoost\n",
    "df_results_lightgbm = pd.DataFrame(results_lightgbm, columns=columns)\n",
    "df_results_xgboost = pd.DataFrame(results_xgboost, columns=columns)\n",
    "\n",
    "# Concatenando os resultados dos dois modelos em um único DataFrame\n",
    "df_results = pd.concat([df_results_lightgbm, df_results_xgboost], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado dos modelos SEM a tunagem de hiperparâmetros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>38586.776903</td>\n",
       "      <td>44161.800849</td>\n",
       "      <td>27936.856770</td>\n",
       "      <td>32487.902792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21462.326807</td>\n",
       "      <td>28607.617056</td>\n",
       "      <td>15610.326833</td>\n",
       "      <td>21221.732968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  RMSE em treino  RMSE em teste  MAE em treino  MAE em teste\n",
       "1  LightGBM    38586.776903   44161.800849   27936.856770  32487.902792\n",
       "4   XGBoost    21462.326807   28607.617056   15610.326833  21221.732968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nResultado dos modelos SEM a tunagem de hiperparâmetros')\n",
    "results_df.iloc[[1, 4], 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado dos modelos COM a tunagem de hiperparâmetros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>36887.215123</td>\n",
       "      <td>41674.877522</td>\n",
       "      <td>26525.398543</td>\n",
       "      <td>30222.956458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>35901.282846</td>\n",
       "      <td>40779.170533</td>\n",
       "      <td>26049.486890</td>\n",
       "      <td>29729.058447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  RMSE em treino  RMSE em teste  MAE em treino  MAE em teste\n",
       "0  LightGBM    36887.215123   41674.877522   26525.398543  30222.956458\n",
       "1   XGBoost    35901.282846   40779.170533   26049.486890  29729.058447"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nResultado dos modelos COM a tunagem de hiperparâmetros')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tunagem de hiperparâmetros trouxe uma melhoria na redução da diferença entre os valores das métricas **RMSE** e **MAE** nos conjuntos de dados de **treino** e **teste**, o que indica que os ajustes de hiperparâmetros ajudaram os modelos a capturar melhor os padrões dos dados. No entanto, ao analisar os erros, observou-se um comportamento distinto entre os modelos **LightGBM** e **XGBoost**.\n",
    "\n",
    "O modelo **XGBoost** apresentou um aumento nas métricas de erro **RMSE** e **MAE**, o que sugere que os ajustes de hiperparâmetros aumentaram a complexidade do modelo. Apesar disso, o **XGBoost** ainda demonstrou uma boa redução nas diferenças entre as métricas dos dados de treino e teste. Isso indica que mais ajustes ou outras abordagens seriam necessárias para melhorar os valores das métricas e reduzir as diferenças entre treino e teste.\n",
    "\n",
    "Por outro lado, o modelo **LightGBM** apresentou uma leve melhoria nas métricas de erro **RMSE** e **MAE** após a tunagem, indicando que o modelo agora está prevendo com erros menores e com uma melhor capacidade de **generalização**. Houve uma redução tanto nos valores das métricas quanto nas diferenças entre os resultados de treino e teste. O **LightGBM** continua se destacando como o modelo mais equilibrado, com redução das métricas de **RMSE** e **MAE**, aliado à melhor capacidade de generalização."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
