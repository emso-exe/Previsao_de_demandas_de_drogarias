{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem preditiva\n",
    "_Machine Learning_\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário\n",
    "\n",
    "1. **Importação de bibliotecas**\n",
    "2. **Carregamento das bases**\n",
    "3. **Análise dos dataframes**\n",
    "4. **Modelagem preditiva**\n",
    "    - 4.1. Preparação dos dados\n",
    "    - 4.2. Treinamento dos modelos com todo o histórico de dados\n",
    "    - 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014\n",
    "    - 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015\n",
    "    - 4.5. Comparativo dos resultados\n",
    "5. **Tunagem dos hiperparâmetros dos melhores algoritmos**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de pacotes e definição de parâmetros globais\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import optuna\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações para exibição de dados no Jupyter Notebook\n",
    "\n",
    "# Configurar opção para exibir todas as linhas do Dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Configurar para exibir o conteúdo completo das colunas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Configurar a supressão de mensagens de aviso durante a execução\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo dos gráficos do seaborn\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efetuando a limpeza da memória antes do carregamento dos dados\n",
    "\n",
    "print(f'\\nQuantidade de objetos removidos da memória: {gc.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir do arquivo train_001.csv\n",
    "\n",
    "df_train = pd.read_csv('dados/train_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_train')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir do arquivo validation_001.csv\n",
    "\n",
    "df_validation = pd.read_csv('dados/validation_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_validation')\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo a quantidade de linhas e colunas dos dataframes\n",
    "\n",
    "# Criação de um dicionário com os dataframes e seus respectivos nomes\n",
    "dfs = {\n",
    "    'df_train': df_train,\n",
    "    'df_validation': df_validation\n",
    "}\n",
    "\n",
    "# Iteração sobre o dicionário para exibir o nome e as dimensões dos dataframes\n",
    "print(f'\\nVOLUMETRIA')\n",
    "for nome, df in dfs.items():\n",
    "    print(f'\\n{nome}')\n",
    "    print(f'-'*45)\n",
    "    print(f'Quantidade de linhas (registros):  {df.shape[0]}')\n",
    "    print(f'Quantidade de colunas (variáveis): {df.shape[1]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de um dataframe de metadados\n",
    "\n",
    "def gerar_metadados(dataframe):\n",
    "    '''\n",
    "    Gera um dataframe contendo metadados das colunas do dataframe fornecido.\n",
    "\n",
    "    :param dataframe: Dataframe\n",
    "        DataFrame para o qual os metadados serão gerados.\n",
    "    :return: DataFrame\n",
    "        DataFrame contendo os metadados.\n",
    "    '''\n",
    "    metadados = pd.DataFrame({\n",
    "        'Variável': dataframe.columns,\n",
    "        'Tipo': dataframe.dtypes,\n",
    "        'Qtde de nulos': dataframe.isnull().sum(),\n",
    "        '% de nulos': round((dataframe.isnull().sum()/len(dataframe))*100, 2),\n",
    "        'Cardinalidade': dataframe.nunique(),\n",
    "    })\n",
    "    metadados = metadados.sort_values(by='Qtde de nulos', ascending=False)\n",
    "    metadados = metadados.reset_index(drop=True)\n",
    "    return metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerar_metadados(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelagem preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditivas e a variável preditora (alvo)\n",
    "\n",
    "features = df_train.columns.drop('Target')\n",
    "target = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis numéricas e categóricas\n",
    "\n",
    "numerical_features = df_train[features].select_dtypes(exclude=object).columns\n",
    "categorical_features = df_train[features].select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter todas as colunas categóricas para string\n",
    "\n",
    "df_train[categorical_features] = df_train[categorical_features].astype(str)\n",
    "df_validation[categorical_features] = df_validation[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_validation[features]\n",
    "y_test = df_validation[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os shapes\n",
    "\n",
    "print(f'Shape: X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'Shape: X_test:  {X_test.shape},  y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando transformação de dados\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os shapes após transformação\n",
    "\n",
    "print(f'Shape de X_train após transformação: {X_train_transformed.shape}')\n",
    "print(f'Shape de X_test após transformação:  {X_test_transformed.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Treinamento dos modelos com todo o histórico de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos a serem testados\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'CatBoost': cb.CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, loss_function='RMSE', verbose=0),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor):\n",
    "    '''\n",
    "    Avalia modelos de aprendizado de máquina, calculando métricas de desempenho \n",
    "    no conjunto de treino e teste.\n",
    "\n",
    "    :param models: dict\n",
    "        Dicionário contendo os modelos a serem avaliados.\n",
    "    :param X_train: DataFrame\n",
    "        Conjunto de dados de treino com as variáveis independentes.\n",
    "    :param y_train: Series\n",
    "        Variável dependente para o conjunto de treino.\n",
    "    :param X_test: DataFrame\n",
    "        Conjunto de dados de teste com as variáveis independentes.\n",
    "    :param y_test: Series\n",
    "        Variável dependente para o conjunto de teste.\n",
    "    :param preprocessor: ColumnTransformer\n",
    "        Objeto de pré-processamento que será aplicado aos dados antes do treinamento do modelo.\n",
    "\n",
    "    :return: list\n",
    "        Lista contendo os resultados de avaliação de cada modelo, RMSE e MAE para treino \n",
    "        e teste, além do tempo de execução.\n",
    "    '''\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "        # Registra o tempo de início\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Treina o modelo usando o pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Registra o tempo de término e calcula o tempo de execução\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de treino\n",
    "        train_predictions = pipeline.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "        train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de teste\n",
    "        test_predictions = pipeline.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "        test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "        # Adiciona os resultados à lista\n",
    "        results.append((\n",
    "            model_name, train_rmse, test_rmse, train_mae, test_mae, elapsed_time\n",
    "        ))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando dados a partir de 01-01-2014\n",
    "df_train_00 = df_train[df_train['Date'] >= '2014-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_00[categorical_features] = df_train_00[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_00[features]\n",
    "y_train = df_train_00[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_00 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando dados a partir de 01-01-2015\n",
    "df_train_01 = df_train[df_train['Date'] >= '2015-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_01[categorical_features] = df_train_01[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_01[features]\n",
    "y_train = df_train_01[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_01 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Comparativo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando todo o histórico de dados\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando histórico de dados a partir de 01-01-2014\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando histórico de dados a partir de 01-01-2015\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores elevados de **RMSE** e **MAE** podem ser atribuídos à grande variação na variável dependente _'Target'_, que inclui dias com vendas zero e dias com vendas muito elevadas. Esse cenário reflete a realidade de que drogarias podem estar fechadas ou operar em horários reduzidos, o que influencia os dados. O foco, no entanto, deve ser nas diferenças entre as métricas de treino e teste, o que indica a capacidade dos modelos em generalizar.\n",
    "\n",
    "Dentre os modelos analisados, o **LinearRegression** teve o pior desempenho com os maiores valores de erro. O **GradientBoosting** apresentou boas diferenças entre treino e teste, mas os erros ainda foram elevados. O **CatBoost** se destacou com métricas razoáveis, mas seu tempo de execução foi mais alto. O **XGBoost** obteve os menores valores de _RMSE_ e _MAE_, porém com uma diferença maior entre treino e teste, indicando possível overfitting. O **LightGBM**, com _RMSE_ e _MAE_ competitivos e o menor tempo de execução, mostrou-se o modelo mais equilibrado, oferecendo a melhor performance geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tunagem dos hiperparâmetros dos melhores algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Tunagem do modelo LightGBM com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo LGBMRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''\n",
    "    model = lgb.LGBMRegressor(\n",
    "        # Número de árvores no modelo, cada árvore corrige a anterior\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \n",
    "        # Tamanho dos passos que o modelo dá ao ajustar os pesos para minimizar o erro\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        \n",
    "        # Número máximo de folhas (ou nós terminais) em cada árvore\n",
    "        num_leaves= trial.suggest_int('num_leaves', 5, 500),\n",
    "        \n",
    "        # Limita a profundidade máxima de cada árvore\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 20),\n",
    "        \n",
    "        # Controla a fração de dados usados para treinar cada árvore\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1),\n",
    "        \n",
    "        # Define a fração de colunas (features) usadas para construir cada árvore\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        \n",
    "        # Define o número mínimo de amostras necessárias para formar uma folha\n",
    "        min_data_in_leaf=trial.suggest_int('min_data_in_leaf', 1, 300),\n",
    "        \n",
    "        # Regularização L1 (Lasso)- penalidade proporcional ao valor absoluto dos coeficientes\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Regularização L2 (Ridge) - penalidade proporcional ao quadrado dos coeficientes\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados     \n",
    "        random_state=42,\n",
    "        \n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbose=-1,         \n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Previsões e cálculo das métricas no conjunto de teste\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_params_00 = pd.DataFrame([study.best_params])\n",
    "df_best_params_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Tunagem do modelo XGBoost com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo XGBRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''\n",
    "    model = XGBRegressor(\n",
    "        # Número de árvores (boosting rounds)\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \n",
    "        # Taxa de aprendizado\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        \n",
    "        # Número máximo de folhas por árvore\n",
    "        max_leaves=trial.suggest_int('max_leaves', 5, 500),\n",
    "        \n",
    "        # Limita a profundidade máxima de cada árvore\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 20),\n",
    "        \n",
    "        # Proporção de amostras usadas para treinar cada árvore (controle de overfitting)\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1),\n",
    "        \n",
    "        # Proporção de colunas (features) usadas para construir cada árvore\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        \n",
    "        # Proporção de colunas usadas por cada nó para divisão (split)\n",
    "        colsample_bylevel=trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        \n",
    "        # Regularização L1 (Lasso) - penalidade no valor absoluto dos coeficientes\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Regularização L2 (Ridge) - penalidade no valor quadrático dos coeficientes\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Peso mínimo necessário para formar uma folha\n",
    "        min_child_weight=trial.suggest_int('min_child_weight', 1, 300),\n",
    "        \n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados\n",
    "        random_state=42,\n",
    "        \n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Faz previsões no conjunto de teste e calcula as métricas\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_params_01 = pd.DataFrame([study.best_params])\n",
    "df_best_params_01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
