{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem preditiva\n",
    "_Machine Learning_\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário\n",
    "\n",
    "1. **Importação de bibliotecas**\n",
    "2. **Carregamento das bases**\n",
    "3. **Análise dos dataframes**\n",
    "4. **Modelagem preditiva**\n",
    "    - 4.1. Preparação dos dados\n",
    "    - 4.2. Treinamento dos modelos com todo o histórico de dados\n",
    "    - 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014\n",
    "    - 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015\n",
    "    - 4.5. Comparativo dos resultados\n",
    "5. **Tunagem dos hiperparâmetros dos melhores algoritmos**\n",
    "    - 5.1. Tunagem do modelo LightGBM com Optuna\n",
    "    - 5.2. Tunagem do modelo XGBoost com Optuna\n",
    "6. **Salvando os modelos**\n",
    "    - 6.1. LightGBM: salvando e testando o desempenho\n",
    "    - 6.2. XGBoost: salvando e testando o desempenho\n",
    "    - 6.3. Comparativo dos resultados\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de pacotes e definição de parâmetros globais\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import optuna\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações para exibição de dados no Jupyter Notebook\n",
    "\n",
    "# Configurar opção para exibir todas as linhas do Dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Configurar para exibir o conteúdo completo das colunas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Configurar a supressão de mensagens de aviso durante a execução\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo dos gráficos do seaborn\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de objetos removidos da memória: 3723\n"
     ]
    }
   ],
   "source": [
    "# Efetuando a limpeza da memória antes do carregamento dos dados\n",
    "\n",
    "print(f'\\nQuantidade de objetos removidos da memória: {gc.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATAFRAME: df_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>...</th>\n",
       "      <th>PromoRollingSum_21</th>\n",
       "      <th>PromoRollingSum_28</th>\n",
       "      <th>PromoRollingSum_30</th>\n",
       "      <th>PromoRollingSum_60</th>\n",
       "      <th>PromoRollingSum_90</th>\n",
       "      <th>PromoRollingSum_120</th>\n",
       "      <th>PromoRollingSum_150</th>\n",
       "      <th>PromoRollingSum_180</th>\n",
       "      <th>PromoRollingSum_360</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0      1          1  2015-06-30     1      1            0              0   \n",
       "1      2          1  2015-06-30     1      1            0              0   \n",
       "2      3          1  2015-06-30     1      1            0              1   \n",
       "3      4          1  2015-06-30     1      1            0              0   \n",
       "4      5          1  2015-06-30     1      1            0              0   \n",
       "\n",
       "  StoreType Assortment  CompetitionDistance  ...  PromoRollingSum_21  \\\n",
       "0         c          a               1270.0  ...                 9.0   \n",
       "1         a          a                570.0  ...                 9.0   \n",
       "2         a          a              14130.0  ...                 9.0   \n",
       "3         c          c                620.0  ...                 9.0   \n",
       "4         a          a              29910.0  ...                 9.0   \n",
       "\n",
       "   PromoRollingSum_28  PromoRollingSum_30  PromoRollingSum_60  \\\n",
       "0                10.0                12.0                 0.0   \n",
       "1                10.0                12.0                 0.0   \n",
       "2                10.0                12.0                 0.0   \n",
       "3                10.0                12.0                 0.0   \n",
       "4                10.0                12.0                 0.0   \n",
       "\n",
       "   PromoRollingSum_90 PromoRollingSum_120  PromoRollingSum_150  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                 0.0                 0.0                  0.0   \n",
       "2                 0.0                 0.0                  0.0   \n",
       "3                 0.0                 0.0                  0.0   \n",
       "4                 0.0                 0.0                  0.0   \n",
       "\n",
       "   PromoRollingSum_180  PromoRollingSum_360    Target  \n",
       "0                  0.0                  0.0  149389.0  \n",
       "1                  0.0                  0.0  170586.0  \n",
       "2                  0.0                  0.0  243725.0  \n",
       "3                  0.0                  0.0  334601.0  \n",
       "4                  0.0                  0.0  162182.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataframe a partir do arquivo train_001.csv\n",
    "\n",
    "df_train = pd.read_csv('dados/train_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_train')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATAFRAME: df_validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>...</th>\n",
       "      <th>PromoRollingSum_21</th>\n",
       "      <th>PromoRollingSum_28</th>\n",
       "      <th>PromoRollingSum_30</th>\n",
       "      <th>PromoRollingSum_60</th>\n",
       "      <th>PromoRollingSum_90</th>\n",
       "      <th>PromoRollingSum_120</th>\n",
       "      <th>PromoRollingSum_150</th>\n",
       "      <th>PromoRollingSum_180</th>\n",
       "      <th>PromoRollingSum_360</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162083.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo  StateHoliday  SchoolHoliday  \\\n",
       "0      1          4  2015-07-31     1      1             0              1   \n",
       "1      2          4  2015-07-31     1      1             0              1   \n",
       "2      3          4  2015-07-31     1      1             0              1   \n",
       "3      4          4  2015-07-31     1      1             0              1   \n",
       "4      5          4  2015-07-31     1      1             0              1   \n",
       "\n",
       "  StoreType Assortment  CompetitionDistance  ...  PromoRollingSum_21  \\\n",
       "0         c          a               1270.0  ...                 0.0   \n",
       "1         a          a                570.0  ...                 0.0   \n",
       "2         a          a              14130.0  ...                 0.0   \n",
       "3         c          c                620.0  ...                 0.0   \n",
       "4         a          a              29910.0  ...                 0.0   \n",
       "\n",
       "   PromoRollingSum_28  PromoRollingSum_30  PromoRollingSum_60  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   PromoRollingSum_90  PromoRollingSum_120  PromoRollingSum_150  \\\n",
       "0                 0.0                  0.0                  0.0   \n",
       "1                 0.0                  0.0                  0.0   \n",
       "2                 0.0                  0.0                  0.0   \n",
       "3                 0.0                  0.0                  0.0   \n",
       "4                 0.0                  0.0                  0.0   \n",
       "\n",
       "   PromoRollingSum_180  PromoRollingSum_360    Target  \n",
       "0                  0.0                  0.0  157057.0  \n",
       "1                  0.0                  0.0  176872.0  \n",
       "2                  0.0                  0.0  245876.0  \n",
       "3                  0.0                  0.0  355383.0  \n",
       "4                  0.0                  0.0  162083.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataframe a partir do arquivo validation_001.csv\n",
    "\n",
    "df_validation = pd.read_csv('dados/validation_001.csv', sep=',')\n",
    "print('\\nDATAFRAME: df_validation')\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VOLUMETRIA\n",
      "\n",
      "df_train\n",
      "---------------------------------------------\n",
      "Quantidade de linhas (registros):  943795\n",
      "Quantidade de colunas (variáveis): 38\n",
      "\n",
      "df_validation\n",
      "---------------------------------------------\n",
      "Quantidade de linhas (registros):  34565\n",
      "Quantidade de colunas (variáveis): 38\n"
     ]
    }
   ],
   "source": [
    "# Exibindo a quantidade de linhas e colunas dos dataframes\n",
    "\n",
    "# Criação de um dicionário com os dataframes e seus respectivos nomes\n",
    "dfs = {\n",
    "    'df_train': df_train,\n",
    "    'df_validation': df_validation\n",
    "}\n",
    "\n",
    "# Iteração sobre o dicionário para exibir o nome e as dimensões dos dataframes\n",
    "print(f'\\nVOLUMETRIA')\n",
    "for nome, df in dfs.items():\n",
    "    print(f'\\n{nome}')\n",
    "    print(f'-'*45)\n",
    "    print(f'Quantidade de linhas (registros):  {df.shape[0]}')\n",
    "    print(f'Quantidade de colunas (variáveis): {df.shape[1]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de um dataframe de metadados\n",
    "\n",
    "def gerar_metadados(dataframe):\n",
    "    '''\n",
    "    Gera um dataframe contendo metadados das colunas do dataframe fornecido.\n",
    "\n",
    "    :param dataframe: Dataframe\n",
    "        DataFrame para o qual os metadados serão gerados.\n",
    "    :return: DataFrame\n",
    "        DataFrame contendo os metadados.\n",
    "    '''\n",
    "    metadados = pd.DataFrame({\n",
    "        'Variável': dataframe.columns,\n",
    "        'Tipo': dataframe.dtypes,\n",
    "        'Qtde de nulos': dataframe.isnull().sum(),\n",
    "        '% de nulos': round((dataframe.isnull().sum()/len(dataframe))*100, 2),\n",
    "        'Cardinalidade': dataframe.nunique(),\n",
    "    })\n",
    "    metadados = metadados.sort_values(by='Qtde de nulos', ascending=False)\n",
    "    metadados = metadados.reset_index(drop=True)\n",
    "    return metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variável</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Qtde de nulos</th>\n",
       "      <th>% de nulos</th>\n",
       "      <th>Cardinalidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PromoRollingSum_21</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DayOfYear</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthsSinceTheCompetitionOpened</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YearsSinceTheCompetitionOpened</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PromoRollingSum_3</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PromoRollingSum_5</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PromoRollingSum_7</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PromoRollingSum_14</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PromoRollingSum_28</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DayOfWeek</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PromoRollingSum_30</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PromoRollingSum_60</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PromoRollingSum_90</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PromoRollingSum_120</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PromoRollingSum_150</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PromoRollingSum_180</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PromoRollingSum_360</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IsWeekend</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Day</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Month</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Date</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Open</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Promo</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>StateHoliday</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SchoolHoliday</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>StoreType</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Assortment</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CompetitionDistance</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CompetitionOpenSinceMonth</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CompetitionOpenSinceYear</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Promo2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Promo2SinceWeek</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Promo2SinceYear</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PromoInterval</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Year</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Target</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Variável     Tipo  Qtde de nulos  % de nulos  \\\n",
       "0                             Store    int64              0         0.0   \n",
       "1                PromoRollingSum_21  float64              0         0.0   \n",
       "2                         DayOfYear    int64              0         0.0   \n",
       "3   MonthsSinceTheCompetitionOpened  float64              0         0.0   \n",
       "4    YearsSinceTheCompetitionOpened  float64              0         0.0   \n",
       "5                 PromoRollingSum_3  float64              0         0.0   \n",
       "6                 PromoRollingSum_5  float64              0         0.0   \n",
       "7                 PromoRollingSum_7  float64              0         0.0   \n",
       "8                PromoRollingSum_14  float64              0         0.0   \n",
       "9                PromoRollingSum_28  float64              0         0.0   \n",
       "10                        DayOfWeek    int64              0         0.0   \n",
       "11               PromoRollingSum_30  float64              0         0.0   \n",
       "12               PromoRollingSum_60  float64              0         0.0   \n",
       "13               PromoRollingSum_90  float64              0         0.0   \n",
       "14              PromoRollingSum_120  float64              0         0.0   \n",
       "15              PromoRollingSum_150  float64              0         0.0   \n",
       "16              PromoRollingSum_180  float64              0         0.0   \n",
       "17              PromoRollingSum_360  float64              0         0.0   \n",
       "18                        IsWeekend     bool              0         0.0   \n",
       "19                          Quarter    int64              0         0.0   \n",
       "20                              Day    int64              0         0.0   \n",
       "21                            Month    int64              0         0.0   \n",
       "22                             Date   object              0         0.0   \n",
       "23                             Open    int64              0         0.0   \n",
       "24                            Promo    int64              0         0.0   \n",
       "25                     StateHoliday   object              0         0.0   \n",
       "26                    SchoolHoliday    int64              0         0.0   \n",
       "27                        StoreType   object              0         0.0   \n",
       "28                       Assortment   object              0         0.0   \n",
       "29              CompetitionDistance  float64              0         0.0   \n",
       "30        CompetitionOpenSinceMonth  float64              0         0.0   \n",
       "31         CompetitionOpenSinceYear  float64              0         0.0   \n",
       "32                           Promo2    int64              0         0.0   \n",
       "33                  Promo2SinceWeek  float64              0         0.0   \n",
       "34                  Promo2SinceYear  float64              0         0.0   \n",
       "35                    PromoInterval   object              0         0.0   \n",
       "36                             Year    int64              0         0.0   \n",
       "37                           Target  float64              0         0.0   \n",
       "\n",
       "    Cardinalidade  \n",
       "0            1115  \n",
       "1               7  \n",
       "2             365  \n",
       "3             336  \n",
       "4             346  \n",
       "5               4  \n",
       "6               6  \n",
       "7               6  \n",
       "8              11  \n",
       "9              11  \n",
       "10              7  \n",
       "11             13  \n",
       "12             14  \n",
       "13             13  \n",
       "14             13  \n",
       "15             17  \n",
       "16             17  \n",
       "17             21  \n",
       "18              2  \n",
       "19              4  \n",
       "20             31  \n",
       "21             12  \n",
       "22            911  \n",
       "23              2  \n",
       "24              2  \n",
       "25              5  \n",
       "26              2  \n",
       "27              4  \n",
       "28              3  \n",
       "29            655  \n",
       "30             13  \n",
       "31             24  \n",
       "32              2  \n",
       "33             25  \n",
       "34              8  \n",
       "35              4  \n",
       "36              3  \n",
       "37         278695  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerar_metadados(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelagem preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditivas e a variável preditora (alvo)\n",
    "\n",
    "features = df_train.columns.drop('Target')\n",
    "target = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis numéricas e categóricas\n",
    "\n",
    "numerical_features = df_train[features].select_dtypes(exclude=object).columns\n",
    "categorical_features = df_train[features].select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter todas as colunas categóricas para string\n",
    "\n",
    "df_train[categorical_features] = df_train[categorical_features].astype(str)\n",
    "df_validation[categorical_features] = df_validation[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_validation[features]\n",
    "y_test = df_validation[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: X_train: (943795, 37), y_train: (943795,)\n",
      "Shape: X_test:  (34565, 37),  y_test: (34565,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os shapes\n",
    "\n",
    "print(f'Shape: X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'Shape: X_test:  {X_test.shape},  y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando transformação de dados\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X_train após transformação: (943795, 958)\n",
      "Shape de X_test após transformação:  (34565, 958)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os shapes após transformação\n",
    "\n",
    "print(f'Shape de X_train após transformação: {X_train_transformed.shape}')\n",
    "print(f'Shape de X_test após transformação:  {X_test_transformed.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Treinamento dos modelos com todo o histórico de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos a serem testados\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'CatBoost': cb.CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, loss_function='RMSE', verbose=0),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor):\n",
    "    '''\n",
    "    Avalia modelos de aprendizado de máquina, calculando métricas de desempenho \n",
    "    no conjunto de treino e teste.\n",
    "\n",
    "    :param models: dict\n",
    "        Dicionário contendo os modelos a serem avaliados.\n",
    "    :param X_train: DataFrame\n",
    "        Conjunto de dados de treino com as variáveis independentes.\n",
    "    :param y_train: Series\n",
    "        Variável dependente para o conjunto de treino.\n",
    "    :param X_test: DataFrame\n",
    "        Conjunto de dados de teste com as variáveis independentes.\n",
    "    :param y_test: Series\n",
    "        Variável dependente para o conjunto de teste.\n",
    "    :param preprocessor: ColumnTransformer\n",
    "        Objeto de pré-processamento que será aplicado aos dados antes do treinamento do modelo.\n",
    "\n",
    "    :return: list\n",
    "        Lista contendo os resultados de avaliação de cada modelo, RMSE e MAE para treino \n",
    "        e teste, além do tempo de execução.\n",
    "    '''\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "        # Registra o tempo de início\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Treina o modelo usando o pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Registra o tempo de término e calcula o tempo de execução\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de treino\n",
    "        train_predictions = pipeline.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "        train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "\n",
    "        # Previsões e cálculo das métricas no conjunto de teste\n",
    "        test_predictions = pipeline.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "        test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "        # Adiciona os resultados à lista\n",
    "        results.append((\n",
    "            model_name, train_rmse, test_rmse, train_mae, test_mae, elapsed_time\n",
    "        ))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74600.379064</td>\n",
       "      <td>309293.409817</td>\n",
       "      <td>51738.388898</td>\n",
       "      <td>271276.664045</td>\n",
       "      <td>28.949886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>38586.776903</td>\n",
       "      <td>44161.800849</td>\n",
       "      <td>27936.856770</td>\n",
       "      <td>32487.902792</td>\n",
       "      <td>7.407274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56395.651572</td>\n",
       "      <td>62284.344024</td>\n",
       "      <td>39903.499101</td>\n",
       "      <td>44085.404224</td>\n",
       "      <td>13.985719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>65562.258359</td>\n",
       "      <td>70611.741017</td>\n",
       "      <td>45250.375402</td>\n",
       "      <td>48747.665342</td>\n",
       "      <td>313.110708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21462.326807</td>\n",
       "      <td>28607.617056</td>\n",
       "      <td>15610.326833</td>\n",
       "      <td>21221.732968</td>\n",
       "      <td>8.739798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74600.379064  309293.409817   51738.388898   \n",
       "1          LightGBM    38586.776903   44161.800849   27936.856770   \n",
       "2          CatBoost    56395.651572   62284.344024   39903.499101   \n",
       "3  GradientBoosting    65562.258359   70611.741017   45250.375402   \n",
       "4           XGBoost    21462.326807   28607.617056   15610.326833   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  271276.664045            28.949886  \n",
       "1   32487.902792             7.407274  \n",
       "2   44085.404224            13.985719  \n",
       "3   48747.665342           313.110708  \n",
       "4   21221.732968             8.739798  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Treinamento dos modelos com histórico de dados a partir de 01-01-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74409.362859</td>\n",
       "      <td>276823.117601</td>\n",
       "      <td>51872.836322</td>\n",
       "      <td>240122.218335</td>\n",
       "      <td>17.079044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>37508.232887</td>\n",
       "      <td>42825.956651</td>\n",
       "      <td>27228.816279</td>\n",
       "      <td>31749.433281</td>\n",
       "      <td>6.093874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56252.880219</td>\n",
       "      <td>61747.624779</td>\n",
       "      <td>39709.751946</td>\n",
       "      <td>43654.323788</td>\n",
       "      <td>8.306505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>64445.219168</td>\n",
       "      <td>69331.655819</td>\n",
       "      <td>44933.129775</td>\n",
       "      <td>48135.930325</td>\n",
       "      <td>194.281831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>19679.021450</td>\n",
       "      <td>25890.517653</td>\n",
       "      <td>14269.371007</td>\n",
       "      <td>19121.840148</td>\n",
       "      <td>5.263091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74409.362859  276823.117601   51872.836322   \n",
       "1          LightGBM    37508.232887   42825.956651   27228.816279   \n",
       "2          CatBoost    56252.880219   61747.624779   39709.751946   \n",
       "3  GradientBoosting    64445.219168   69331.655819   44933.129775   \n",
       "4           XGBoost    19679.021450   25890.517653   14269.371007   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  240122.218335            17.079044  \n",
       "1   31749.433281             6.093874  \n",
       "2   43654.323788             8.306505  \n",
       "3   48135.930325           194.281831  \n",
       "4   19121.840148             5.263091  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando dados a partir de 01-01-2014\n",
    "df_train_00 = df_train[df_train['Date'] >= '2014-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_00[categorical_features] = df_train_00[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_00[features]\n",
    "y_train = df_train_00[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_00 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Treinamento dos modelos com histórico de dados a partir de 01-01-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>73699.366946</td>\n",
       "      <td>86771.077084</td>\n",
       "      <td>51404.782369</td>\n",
       "      <td>60645.653521</td>\n",
       "      <td>2.080378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>35155.499255</td>\n",
       "      <td>40311.140946</td>\n",
       "      <td>25778.097047</td>\n",
       "      <td>29902.591028</td>\n",
       "      <td>1.794418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>54854.734524</td>\n",
       "      <td>62294.912910</td>\n",
       "      <td>38846.806357</td>\n",
       "      <td>43603.607236</td>\n",
       "      <td>3.069998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>63451.163306</td>\n",
       "      <td>69028.536458</td>\n",
       "      <td>44110.979695</td>\n",
       "      <td>47900.685039</td>\n",
       "      <td>55.179872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18390.785339</td>\n",
       "      <td>24604.677229</td>\n",
       "      <td>13493.532465</td>\n",
       "      <td>18316.927099</td>\n",
       "      <td>1.735763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    73699.366946   86771.077084   51404.782369   \n",
       "1          LightGBM    35155.499255   40311.140946   25778.097047   \n",
       "2          CatBoost    54854.734524   62294.912910   38846.806357   \n",
       "3  GradientBoosting    63451.163306   69028.536458   44110.979695   \n",
       "4           XGBoost    18390.785339   24604.677229   13493.532465   \n",
       "\n",
       "   MAE em teste  Tempo decorrido (s)  \n",
       "0  60645.653521             2.080378  \n",
       "1  29902.591028             1.794418  \n",
       "2  43603.607236             3.069998  \n",
       "3  47900.685039            55.179872  \n",
       "4  18316.927099             1.735763  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando dados a partir de 01-01-2015\n",
    "df_train_01 = df_train[df_train['Date'] >= '2015-01-01'].copy()\n",
    "\n",
    "# Converter todas as colunas categóricas para string\n",
    "df_train_01[categorical_features] = df_train_01[categorical_features].astype(str)\n",
    "\n",
    "# Separando os dataframes com as variáveis preditivas e a variável preditora\n",
    "X_train = df_train_01[features]\n",
    "y_train = df_train_01[target]\n",
    "\n",
    "# Pré-processamento, transformação das features numéricas e categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numerical_features),\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Avaliando os modelos\n",
    "results = models_evaluation(models, X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "# Criando DataFrame de resultados\n",
    "results_df_01 = pd.DataFrame(results, columns=[\n",
    "                            'Modelo', 'RMSE em treino', 'RMSE em teste', \n",
    "                            'MAE em treino', 'MAE em teste', 'Tempo decorrido (s)'])\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Comparativo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74600.379064</td>\n",
       "      <td>309293.409817</td>\n",
       "      <td>51738.388898</td>\n",
       "      <td>271276.664045</td>\n",
       "      <td>28.949886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>38586.776903</td>\n",
       "      <td>44161.800849</td>\n",
       "      <td>27936.856770</td>\n",
       "      <td>32487.902792</td>\n",
       "      <td>7.407274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56395.651572</td>\n",
       "      <td>62284.344024</td>\n",
       "      <td>39903.499101</td>\n",
       "      <td>44085.404224</td>\n",
       "      <td>13.985719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>65562.258359</td>\n",
       "      <td>70611.741017</td>\n",
       "      <td>45250.375402</td>\n",
       "      <td>48747.665342</td>\n",
       "      <td>313.110708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21462.326807</td>\n",
       "      <td>28607.617056</td>\n",
       "      <td>15610.326833</td>\n",
       "      <td>21221.732968</td>\n",
       "      <td>8.739798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74600.379064  309293.409817   51738.388898   \n",
       "1          LightGBM    38586.776903   44161.800849   27936.856770   \n",
       "2          CatBoost    56395.651572   62284.344024   39903.499101   \n",
       "3  GradientBoosting    65562.258359   70611.741017   45250.375402   \n",
       "4           XGBoost    21462.326807   28607.617056   15610.326833   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  271276.664045            28.949886  \n",
       "1   32487.902792             7.407274  \n",
       "2   44085.404224            13.985719  \n",
       "3   48747.665342           313.110708  \n",
       "4   21221.732968             8.739798  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando todo o histórico de dados\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>74409.362859</td>\n",
       "      <td>276823.117601</td>\n",
       "      <td>51872.836322</td>\n",
       "      <td>240122.218335</td>\n",
       "      <td>17.079044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>37508.232887</td>\n",
       "      <td>42825.956651</td>\n",
       "      <td>27228.816279</td>\n",
       "      <td>31749.433281</td>\n",
       "      <td>6.093874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>56252.880219</td>\n",
       "      <td>61747.624779</td>\n",
       "      <td>39709.751946</td>\n",
       "      <td>43654.323788</td>\n",
       "      <td>8.306505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>64445.219168</td>\n",
       "      <td>69331.655819</td>\n",
       "      <td>44933.129775</td>\n",
       "      <td>48135.930325</td>\n",
       "      <td>194.281831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>19679.021450</td>\n",
       "      <td>25890.517653</td>\n",
       "      <td>14269.371007</td>\n",
       "      <td>19121.840148</td>\n",
       "      <td>5.263091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    74409.362859  276823.117601   51872.836322   \n",
       "1          LightGBM    37508.232887   42825.956651   27228.816279   \n",
       "2          CatBoost    56252.880219   61747.624779   39709.751946   \n",
       "3  GradientBoosting    64445.219168   69331.655819   44933.129775   \n",
       "4           XGBoost    19679.021450   25890.517653   14269.371007   \n",
       "\n",
       "    MAE em teste  Tempo decorrido (s)  \n",
       "0  240122.218335            17.079044  \n",
       "1   31749.433281             6.093874  \n",
       "2   43654.323788             8.306505  \n",
       "3   48135.930325           194.281831  \n",
       "4   19121.840148             5.263091  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando histórico de dados a partir de 01-01-2014\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "      <th>Tempo decorrido (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>73699.366946</td>\n",
       "      <td>86771.077084</td>\n",
       "      <td>51404.782369</td>\n",
       "      <td>60645.653521</td>\n",
       "      <td>2.080378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>35155.499255</td>\n",
       "      <td>40311.140946</td>\n",
       "      <td>25778.097047</td>\n",
       "      <td>29902.591028</td>\n",
       "      <td>1.794418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>54854.734524</td>\n",
       "      <td>62294.912910</td>\n",
       "      <td>38846.806357</td>\n",
       "      <td>43603.607236</td>\n",
       "      <td>3.069998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>63451.163306</td>\n",
       "      <td>69028.536458</td>\n",
       "      <td>44110.979695</td>\n",
       "      <td>47900.685039</td>\n",
       "      <td>55.179872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18390.785339</td>\n",
       "      <td>24604.677229</td>\n",
       "      <td>13493.532465</td>\n",
       "      <td>18316.927099</td>\n",
       "      <td>1.735763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  RMSE em treino  RMSE em teste  MAE em treino  \\\n",
       "0  LinearRegression    73699.366946   86771.077084   51404.782369   \n",
       "1          LightGBM    35155.499255   40311.140946   25778.097047   \n",
       "2          CatBoost    54854.734524   62294.912910   38846.806357   \n",
       "3  GradientBoosting    63451.163306   69028.536458   44110.979695   \n",
       "4           XGBoost    18390.785339   24604.677229   13493.532465   \n",
       "\n",
       "   MAE em teste  Tempo decorrido (s)  \n",
       "0  60645.653521             2.080378  \n",
       "1  29902.591028             1.794418  \n",
       "2  43603.607236             3.069998  \n",
       "3  47900.685039            55.179872  \n",
       "4  18316.927099             1.735763  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando histórico de dados a partir de 01-01-2015\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_df_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores elevados de **RMSE** e **MAE** podem ser atribuídos à grande variação na variável dependente _'Target'_, que inclui dias com vendas zero e dias com vendas muito elevadas. Esse cenário reflete a realidade de que drogarias podem estar fechadas ou operar em horários reduzidos, o que influencia os dados. O foco, no entanto, deve ser nas diferenças entre as métricas de treino e teste, o que indica a capacidade dos modelos em generalizar.\n",
    "\n",
    "Dentre os modelos analisados, o **LinearRegression** teve o pior desempenho com os maiores valores de erro. O **GradientBoosting** apresentou boas diferenças entre treino e teste, mas os erros ainda foram elevados, além de apresentar o pior tempo de execução. O **CatBoost** se destacou com métricas razoáveis, mas seu tempo de execução foi elevado em relação aos próximos modelos. O **XGBoost** obteve os menores valores de _RMSE_ e _MAE_, porém com uma diferença maior entre treino e teste, indicando possível overfitting. O **LightGBM**, com _RMSE_ e _MAE_ competitivos e o menor tempo de execução, mostrou-se o modelo mais equilibrado, oferecendo a melhor performance geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tunagem dos hiperparâmetros dos melhores algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Tunagem do modelo LightGBM com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo LGBMRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''\n",
    "    model = lgb.LGBMRegressor(\n",
    "        # Número de árvores no modelo, cada árvore corrige a anterior\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \n",
    "        # Tamanho dos passos que o modelo dá ao ajustar os pesos para minimizar o erro\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        \n",
    "        # Número máximo de folhas (ou nós terminais) em cada árvore\n",
    "        num_leaves= trial.suggest_int('num_leaves', 5, 500),\n",
    "        \n",
    "        # Limita a profundidade máxima de cada árvore\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 20),\n",
    "        \n",
    "        # Controla a fração de dados usados para treinar cada árvore\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1),\n",
    "        \n",
    "        # Define a fração de colunas (features) usadas para construir cada árvore\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        \n",
    "        # Define o número mínimo de amostras necessárias para formar uma folha\n",
    "        min_data_in_leaf=trial.suggest_int('min_data_in_leaf', 1, 300),\n",
    "        \n",
    "        # Regularização L1 (Lasso)- penalidade proporcional ao valor absoluto dos coeficientes\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Regularização L2 (Ridge) - penalidade proporcional ao quadrado dos coeficientes\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados     \n",
    "        random_state=42,\n",
    "        \n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbose=-1,         \n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Previsões e cálculo das métricas no conjunto de teste\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 20:54:24,563] A new study created in memory with name: no-name-8a589974-2549-4654-8747-a2fdef55ef5d\n",
      "[I 2024-11-06 20:54:34,092] Trial 0 finished with value: 12996.574064743065 and parameters: {'n_estimators': 437, 'learning_rate': 0.07969454818643935, 'num_leaves': 368, 'max_depth': 13, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'min_data_in_leaf': 18, 'reg_alpha': 0.08499808989182997, 'reg_lambda': 0.0006440507553993703}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:54:57,647] Trial 1 finished with value: 50677.464957775526 and parameters: {'n_estimators': 737, 'learning_rate': 0.0010994335574766201, 'num_leaves': 486, 'max_depth': 17, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503, 'min_data_in_leaf': 56, 'reg_alpha': 2.716051144654844e-06, 'reg_lambda': 0.00015777981883364995}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:02,826] Trial 2 finished with value: 53820.45052792358 and parameters: {'n_estimators': 489, 'learning_rate': 0.0038234752246751854, 'num_leaves': 308, 'max_depth': 5, 'subsample': 0.6460723242676091, 'colsample_bytree': 0.6831809216468459, 'min_data_in_leaf': 137, 'reg_alpha': 0.019116469627784252, 'reg_lambda': 3.9572205641009174e-07}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:08,433] Trial 3 finished with value: 37613.03533032932 and parameters: {'n_estimators': 563, 'learning_rate': 0.015304852121831466, 'num_leaves': 28, 'max_depth': 13, 'subsample': 0.5852620618436457, 'colsample_bytree': 0.5325257964926398, 'min_data_in_leaf': 285, 'reg_alpha': 0.530953226900921, 'reg_lambda': 0.02932100047183291}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:16,328] Trial 4 finished with value: 62475.636120080984 and parameters: {'n_estimators': 374, 'learning_rate': 0.0015679933916723015, 'num_leaves': 344, 'max_depth': 10, 'subsample': 0.5610191174223894, 'colsample_bytree': 0.7475884550556351, 'min_data_in_leaf': 11, 'reg_alpha': 0.1881755597772026, 'reg_lambda': 1.1755466083160747e-06}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:29,698] Trial 5 finished with value: 28248.840729216663 and parameters: {'n_estimators': 696, 'learning_rate': 0.004201672054372531, 'num_leaves': 262, 'max_depth': 12, 'subsample': 0.5924272277627636, 'colsample_bytree': 0.9847923138822793, 'min_data_in_leaf': 233, 'reg_alpha': 0.32808889626606236, 'reg_lambda': 0.14408501080722544}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:37,264] Trial 6 finished with value: 19248.568999339735 and parameters: {'n_estimators': 638, 'learning_rate': 0.06978281265126034, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.522613644455269, 'colsample_bytree': 0.6626651653816322, 'min_data_in_leaf': 117, 'reg_alpha': 1.481809088646707e-06, 'reg_lambda': 0.04264813784432918}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:43,067] Trial 7 finished with value: 57267.715147950075 and parameters: {'n_estimators': 421, 'learning_rate': 0.0036464395589807202, 'num_leaves': 274, 'max_depth': 5, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'min_data_in_leaf': 297, 'reg_alpha': 0.015064619068942013, 'reg_lambda': 3.8879928024075543e-07}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:47,179] Trial 8 finished with value: 21863.55610952761 and parameters: {'n_estimators': 104, 'learning_rate': 0.04274869455295218, 'num_leaves': 355, 'max_depth': 16, 'subsample': 0.8856351733429728, 'colsample_bytree': 0.5370223258670452, 'min_data_in_leaf': 108, 'reg_alpha': 8.451863533931625e-08, 'reg_lambda': 0.08032068562667222}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:55:59,332] Trial 9 finished with value: 42501.48459028032 and parameters: {'n_estimators': 661, 'learning_rate': 0.004589824181495649, 'num_leaves': 36, 'max_depth': 8, 'subsample': 0.6625916610133735, 'colsample_bytree': 0.864803089169032, 'min_data_in_leaf': 192, 'reg_alpha': 0.12522814303053625, 'reg_lambda': 5.994036749692399e-05}. Best is trial 0 with value: 12996.574064743065.\n",
      "[I 2024-11-06 20:56:18,530] Trial 10 finished with value: 10883.41954139869 and parameters: {'n_estimators': 951, 'learning_rate': 0.023367493808810827, 'num_leaves': 157, 'max_depth': 19, 'subsample': 0.7606700059313507, 'colsample_bytree': 0.8451235367845726, 'min_data_in_leaf': 5, 'reg_alpha': 0.0009705371168540475, 'reg_lambda': 0.0003667608064912254}. Best is trial 10 with value: 10883.41954139869.\n",
      "[I 2024-11-06 20:56:33,487] Trial 11 finished with value: 10905.113688777294 and parameters: {'n_estimators': 997, 'learning_rate': 0.02532108340976422, 'num_leaves': 145, 'max_depth': 20, 'subsample': 0.7804533509078434, 'colsample_bytree': 0.8513496163789993, 'min_data_in_leaf': 4, 'reg_alpha': 0.0003857694405425067, 'reg_lambda': 0.0005413387146719047}. Best is trial 10 with value: 10883.41954139869.\n",
      "[I 2024-11-06 20:56:51,174] Trial 12 finished with value: 11784.083220612276 and parameters: {'n_estimators': 971, 'learning_rate': 0.019575500799074524, 'num_leaves': 147, 'max_depth': 20, 'subsample': 0.7630125055985993, 'colsample_bytree': 0.8588729908849949, 'min_data_in_leaf': 64, 'reg_alpha': 0.00022421038024331597, 'reg_lambda': 0.0011219586787933678}. Best is trial 10 with value: 10883.41954139869.\n",
      "[I 2024-11-06 20:57:07,172] Trial 13 finished with value: 11164.981054547618 and parameters: {'n_estimators': 997, 'learning_rate': 0.020046179107204486, 'num_leaves': 162, 'max_depth': 20, 'subsample': 0.7878475603784051, 'colsample_bytree': 0.8585787245031458, 'min_data_in_leaf': 57, 'reg_alpha': 0.000573767767665648, 'reg_lambda': 1.3659363488645942e-05}. Best is trial 10 with value: 10883.41954139869.\n",
      "[I 2024-11-06 20:57:21,620] Trial 14 finished with value: 10598.565710551282 and parameters: {'n_estimators': 843, 'learning_rate': 0.03415962026347908, 'num_leaves': 186, 'max_depth': 16, 'subsample': 0.9977408115016615, 'colsample_bytree': 0.9501945220447685, 'min_data_in_leaf': 12, 'reg_alpha': 0.001580412558295919, 'reg_lambda': 0.0032862235703113624}. Best is trial 14 with value: 10598.565710551282.\n",
      "[I 2024-11-06 20:57:43,232] Trial 15 finished with value: 14409.953629830314 and parameters: {'n_estimators': 846, 'learning_rate': 0.009497901487853528, 'num_leaves': 200, 'max_depth': 16, 'subsample': 0.9758970590679756, 'colsample_bytree': 0.9913430783889023, 'min_data_in_leaf': 91, 'reg_alpha': 0.0038333277200349966, 'reg_lambda': 0.003439113856242893}. Best is trial 14 with value: 10598.565710551282.\n",
      "[I 2024-11-06 20:57:54,532] Trial 16 finished with value: 11627.9656987822 and parameters: {'n_estimators': 826, 'learning_rate': 0.03809284274090978, 'num_leaves': 96, 'max_depth': 17, 'subsample': 0.8607349956827239, 'colsample_bytree': 0.9298249375977756, 'min_data_in_leaf': 180, 'reg_alpha': 1.439343623998578e-05, 'reg_lambda': 1.2747755202583602e-08}. Best is trial 14 with value: 10598.565710551282.\n",
      "[I 2024-11-06 20:58:12,497] Trial 17 finished with value: 14905.043900251703 and parameters: {'n_estimators': 865, 'learning_rate': 0.009581544655016535, 'num_leaves': 218, 'max_depth': 15, 'subsample': 0.7172744518636273, 'colsample_bytree': 0.7847849004475568, 'min_data_in_leaf': 39, 'reg_alpha': 0.0012712604724850398, 'reg_lambda': 0.8179631349411198}. Best is trial 14 with value: 10598.565710551282.\n",
      "[I 2024-11-06 20:58:17,317] Trial 18 finished with value: 16753.27266211676 and parameters: {'n_estimators': 276, 'learning_rate': 0.039060295435834044, 'num_leaves': 95, 'max_depth': 18, 'subsample': 0.9547281365288425, 'colsample_bytree': 0.9216961205137372, 'min_data_in_leaf': 74, 'reg_alpha': 4.8533413107341945e-05, 'reg_lambda': 0.011112945894084673}. Best is trial 14 with value: 10598.565710551282.\n",
      "[I 2024-11-06 20:58:40,643] Trial 19 finished with value: 10155.600949285548 and parameters: {'n_estimators': 886, 'learning_rate': 0.055711970808604544, 'num_leaves': 441, 'max_depth': 14, 'subsample': 0.8391815226694496, 'colsample_bytree': 0.7866804535238765, 'min_data_in_leaf': 31, 'reg_alpha': 0.005492567442539989, 'reg_lambda': 1.2620961933636518e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 20:58:56,113] Trial 20 finished with value: 10160.465414892591 and parameters: {'n_estimators': 790, 'learning_rate': 0.09629850538730012, 'num_leaves': 499, 'max_depth': 14, 'subsample': 0.8314063332863684, 'colsample_bytree': 0.7663977387461562, 'min_data_in_leaf': 157, 'reg_alpha': 1.2387044364130546e-08, 'reg_lambda': 8.125571491656555e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 20:59:09,402] Trial 21 finished with value: 10216.202628691995 and parameters: {'n_estimators': 796, 'learning_rate': 0.09002387580177851, 'num_leaves': 461, 'max_depth': 14, 'subsample': 0.8378250814044333, 'colsample_bytree': 0.7655861314080078, 'min_data_in_leaf': 156, 'reg_alpha': 1.3767884945287517e-08, 'reg_lambda': 8.710367764781329e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 20:59:18,592] Trial 22 finished with value: 10383.834791800364 and parameters: {'n_estimators': 762, 'learning_rate': 0.08693801653136937, 'num_leaves': 500, 'max_depth': 10, 'subsample': 0.8291568366683594, 'colsample_bytree': 0.7576385607694824, 'min_data_in_leaf': 177, 'reg_alpha': 1.2691509858065726e-08, 'reg_lambda': 7.676375188123143e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 20:59:29,032] Trial 23 finished with value: 12537.882319822294 and parameters: {'n_estimators': 578, 'learning_rate': 0.059092001553299474, 'num_leaves': 439, 'max_depth': 14, 'subsample': 0.8271543911444089, 'colsample_bytree': 0.7034240386097456, 'min_data_in_leaf': 218, 'reg_alpha': 1.0855377534771625e-08, 'reg_lambda': 5.288724728108369e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 20:59:44,696] Trial 24 finished with value: 11150.87009089962 and parameters: {'n_estimators': 896, 'learning_rate': 0.09973026847681427, 'num_leaves': 421, 'max_depth': 11, 'subsample': 0.931100212155028, 'colsample_bytree': 0.7952571736263923, 'min_data_in_leaf': 148, 'reg_alpha': 1.3989913173347137e-07, 'reg_lambda': 5.545546453261822e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:00:00,078] Trial 25 finished with value: 12064.913291756795 and parameters: {'n_estimators': 770, 'learning_rate': 0.05651193081791867, 'num_leaves': 431, 'max_depth': 13, 'subsample': 0.7201219900800487, 'colsample_bytree': 0.643842661182726, 'min_data_in_leaf': 128, 'reg_alpha': 1.0560103869449096e-07, 'reg_lambda': 6.64634179761215e-08}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:00:10,312] Trial 26 finished with value: 12832.204495899301 and parameters: {'n_estimators': 915, 'learning_rate': 0.052867732809113326, 'num_leaves': 464, 'max_depth': 8, 'subsample': 0.8280654041106802, 'colsample_bytree': 0.7347106699292584, 'min_data_in_leaf': 163, 'reg_alpha': 8.368448328637751e-07, 'reg_lambda': 1.2560745459954922e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:00:23,892] Trial 27 finished with value: 11041.637952342464 and parameters: {'n_estimators': 798, 'learning_rate': 0.08840721907384255, 'num_leaves': 397, 'max_depth': 14, 'subsample': 0.8655135854696242, 'colsample_bytree': 0.8011317313078313, 'min_data_in_leaf': 226, 'reg_alpha': 1.3080756183547259e-05, 'reg_lambda': 1.4682992967285433e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:00:39,926] Trial 28 finished with value: 14969.553783884949 and parameters: {'n_estimators': 628, 'learning_rate': 0.013520165439266837, 'num_leaves': 465, 'max_depth': 15, 'subsample': 0.915884027996377, 'colsample_bytree': 0.7135225550307122, 'min_data_in_leaf': 199, 'reg_alpha': 3.761588919435557e-08, 'reg_lambda': 2.3283288866828006e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:00:53,452] Trial 29 finished with value: 12782.348704764556 and parameters: {'n_estimators': 706, 'learning_rate': 0.07023288357954248, 'num_leaves': 404, 'max_depth': 12, 'subsample': 0.8117236604463361, 'colsample_bytree': 0.619720671481651, 'min_data_in_leaf': 100, 'reg_alpha': 6.847662450885711e-07, 'reg_lambda': 3.7487999952106444e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:01:07,887] Trial 30 finished with value: 12496.227541410357 and parameters: {'n_estimators': 930, 'learning_rate': 0.03166910719825314, 'num_leaves': 384, 'max_depth': 10, 'subsample': 0.7238843423759939, 'colsample_bytree': 0.8194041845232801, 'min_data_in_leaf': 156, 'reg_alpha': 2.910175348288161e-07, 'reg_lambda': 2.9742041015448545e-07}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:01:17,827] Trial 31 finished with value: 11416.051696004273 and parameters: {'n_estimators': 763, 'learning_rate': 0.09579921080584958, 'num_leaves': 495, 'max_depth': 9, 'subsample': 0.844177358292261, 'colsample_bytree': 0.7748627502476889, 'min_data_in_leaf': 168, 'reg_alpha': 1.0100176804573491e-08, 'reg_lambda': 8.860675917163795e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:01:29,394] Trial 32 finished with value: 12060.933284386434 and parameters: {'n_estimators': 726, 'learning_rate': 0.07313834049323457, 'num_leaves': 463, 'max_depth': 13, 'subsample': 0.8002909474624988, 'colsample_bytree': 0.7611784754490304, 'min_data_in_leaf': 210, 'reg_alpha': 2.9581234171857556e-08, 'reg_lambda': 5.631941823272853e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:01:44,402] Trial 33 finished with value: 10732.517099205073 and parameters: {'n_estimators': 775, 'learning_rate': 0.05742399347515003, 'num_leaves': 497, 'max_depth': 11, 'subsample': 0.8510670515114516, 'colsample_bytree': 0.7190253565236316, 'min_data_in_leaf': 136, 'reg_alpha': 5.286297486535375e-06, 'reg_lambda': 0.00014728295800572842}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:00,176] Trial 34 finished with value: 11266.267804359073 and parameters: {'n_estimators': 899, 'learning_rate': 0.047875016235907425, 'num_leaves': 327, 'max_depth': 14, 'subsample': 0.8844302319577306, 'colsample_bytree': 0.8223655560178663, 'min_data_in_leaf': 248, 'reg_alpha': 2.357344171033579e-08, 'reg_lambda': 2.3693452417323417e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:11,826] Trial 35 finished with value: 11106.031500349143 and parameters: {'n_estimators': 797, 'learning_rate': 0.0732687084372022, 'num_leaves': 451, 'max_depth': 10, 'subsample': 0.6844088260498035, 'colsample_bytree': 0.7427065856021283, 'min_data_in_leaf': 184, 'reg_alpha': 3.0308218271651805e-07, 'reg_lambda': 3.0322296465778822e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:20,586] Trial 36 finished with value: 11568.879340067808 and parameters: {'n_estimators': 582, 'learning_rate': 0.0947517658860524, 'num_leaves': 476, 'max_depth': 12, 'subsample': 0.8143759428940601, 'colsample_bytree': 0.6829211308933169, 'min_data_in_leaf': 258, 'reg_alpha': 0.02407927137934235, 'reg_lambda': 1.261227411625771e-07}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:27,226] Trial 37 finished with value: 26846.12153522505 and parameters: {'n_estimators': 494, 'learning_rate': 0.027882267157633027, 'num_leaves': 500, 'max_depth': 7, 'subsample': 0.926100439577581, 'colsample_bytree': 0.6832681795727704, 'min_data_in_leaf': 35, 'reg_alpha': 6.485576214132154e-08, 'reg_lambda': 0.0001989267149987203}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:32,012] Trial 38 finished with value: 38172.09896559475 and parameters: {'n_estimators': 683, 'learning_rate': 0.07375730280076011, 'num_leaves': 293, 'max_depth': 3, 'subsample': 0.747864040393996, 'colsample_bytree': 0.763230884631249, 'min_data_in_leaf': 123, 'reg_alpha': 0.817273328543755, 'reg_lambda': 6.706680911592273e-07}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:02:54,592] Trial 39 finished with value: 15946.7496923222 and parameters: {'n_estimators': 742, 'learning_rate': 0.006574343659203269, 'num_leaves': 377, 'max_depth': 17, 'subsample': 0.8844020474596617, 'colsample_bytree': 0.8953092998258054, 'min_data_in_leaf': 144, 'reg_alpha': 0.05052090308796114, 'reg_lambda': 2.481015579906632e-06}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:03:05,756] Trial 40 finished with value: 44381.42283478888 and parameters: {'n_estimators': 523, 'learning_rate': 0.0023431365315276283, 'num_leaves': 415, 'max_depth': 15, 'subsample': 0.8359806257693881, 'colsample_bytree': 0.5778610056515865, 'min_data_in_leaf': 169, 'reg_alpha': 4.8617630631098834e-05, 'reg_lambda': 1.9624653910334962e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:03:23,517] Trial 41 finished with value: 10308.090230987666 and parameters: {'n_estimators': 864, 'learning_rate': 0.03515727571008989, 'num_leaves': 210, 'max_depth': 16, 'subsample': 0.999659503692174, 'colsample_bytree': 0.9026128327214511, 'min_data_in_leaf': 35, 'reg_alpha': 0.004038489857405995, 'reg_lambda': 0.001502098145268614}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:03:39,422] Trial 42 finished with value: 11480.276782148178 and parameters: {'n_estimators': 878, 'learning_rate': 0.04581242331432574, 'num_leaves': 224, 'max_depth': 13, 'subsample': 0.9587404750233652, 'colsample_bytree': 0.8197623389001705, 'min_data_in_leaf': 29, 'reg_alpha': 0.005413608745707791, 'reg_lambda': 0.00012336522815377407}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:03:55,613] Trial 43 finished with value: 11260.457599471747 and parameters: {'n_estimators': 833, 'learning_rate': 0.05862659780512909, 'num_leaves': 254, 'max_depth': 14, 'subsample': 0.6110396652493462, 'colsample_bytree': 0.8843970393129935, 'min_data_in_leaf': 111, 'reg_alpha': 0.004031773924390286, 'reg_lambda': 0.001725434405924847}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:04:13,372] Trial 44 finished with value: 52067.65621701923 and parameters: {'n_estimators': 624, 'learning_rate': 0.001090561914826461, 'num_leaves': 446, 'max_depth': 18, 'subsample': 0.9058492495139486, 'colsample_bytree': 0.734625277188062, 'min_data_in_leaf': 80, 'reg_alpha': 2.319247933111383e-08, 'reg_lambda': 7.150470613409945e-05}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:04:33,762] Trial 45 finished with value: 10171.966059238224 and parameters: {'n_estimators': 948, 'learning_rate': 0.07952665901990794, 'num_leaves': 340, 'max_depth': 15, 'subsample': 0.7808393690669156, 'colsample_bytree': 0.9638038308274863, 'min_data_in_leaf': 22, 'reg_alpha': 0.00792802575366055, 'reg_lambda': 0.00030499824850933416}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:04:57,373] Trial 46 finished with value: 10795.576544952946 and parameters: {'n_estimators': 946, 'learning_rate': 0.045028544609318544, 'num_leaves': 338, 'max_depth': 16, 'subsample': 0.7732076245669395, 'colsample_bytree': 0.9704908216187291, 'min_data_in_leaf': 25, 'reg_alpha': 0.05884324503944192, 'reg_lambda': 0.00032795484970098176}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:05:06,628] Trial 47 finished with value: 12980.270232043757 and parameters: {'n_estimators': 335, 'learning_rate': 0.03173423231129348, 'num_leaves': 297, 'max_depth': 15, 'subsample': 0.5403317102892633, 'colsample_bytree': 0.8938422798743824, 'min_data_in_leaf': 47, 'reg_alpha': 0.019375684835600412, 'reg_lambda': 0.0009285817757313216}. Best is trial 19 with value: 10155.600949285548.\n",
      "[I 2024-11-06 21:05:26,892] Trial 48 finished with value: 8649.625191260928 and parameters: {'n_estimators': 969, 'learning_rate': 0.06922991270832674, 'num_leaves': 318, 'max_depth': 18, 'subsample': 0.7467813979547294, 'colsample_bytree': 0.9571263765454211, 'min_data_in_leaf': 17, 'reg_alpha': 0.00892745657075051, 'reg_lambda': 0.01654906069601954}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:05:48,603] Trial 49 finished with value: 10298.527628454838 and parameters: {'n_estimators': 967, 'learning_rate': 0.06258415772859861, 'num_leaves': 277, 'max_depth': 18, 'subsample': 0.7933743032221452, 'colsample_bytree': 0.9507438067856805, 'min_data_in_leaf': 1, 'reg_alpha': 0.2665882703503631, 'reg_lambda': 0.009394635825292767}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:06:10,222] Trial 50 finished with value: 9271.699916659842 and parameters: {'n_estimators': 978, 'learning_rate': 0.07910860952383258, 'num_leaves': 361, 'max_depth': 19, 'subsample': 0.7477802473830539, 'colsample_bytree': 0.9654565223315629, 'min_data_in_leaf': 17, 'reg_alpha': 0.00821491345974664, 'reg_lambda': 0.6846442809102341}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:06:28,162] Trial 51 finished with value: 9031.441966450988 and parameters: {'n_estimators': 991, 'learning_rate': 0.08005845213010424, 'num_leaves': 316, 'max_depth': 19, 'subsample': 0.7337713767552384, 'colsample_bytree': 0.9678180159206338, 'min_data_in_leaf': 49, 'reg_alpha': 0.010168445701805173, 'reg_lambda': 0.24878508949027123}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:06:47,903] Trial 52 finished with value: 10734.964100995274 and parameters: {'n_estimators': 985, 'learning_rate': 0.080415505964522, 'num_leaves': 366, 'max_depth': 19, 'subsample': 0.6868917933681495, 'colsample_bytree': 0.9980022199427547, 'min_data_in_leaf': 20, 'reg_alpha': 0.011885785798164229, 'reg_lambda': 0.3500240430475574}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:07:05,942] Trial 53 finished with value: 8702.200720582212 and parameters: {'n_estimators': 939, 'learning_rate': 0.06791773081947816, 'num_leaves': 322, 'max_depth': 19, 'subsample': 0.746510851011568, 'colsample_bytree': 0.9674256331243393, 'min_data_in_leaf': 49, 'reg_alpha': 0.007553503175979748, 'reg_lambda': 0.1143738124728012}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:07:28,642] Trial 54 finished with value: 9588.54588589136 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06561623815967293, 'num_leaves': 317, 'max_depth': 19, 'subsample': 0.7436741904249252, 'colsample_bytree': 0.9264141217461664, 'min_data_in_leaf': 43, 'reg_alpha': 0.0019980340681525553, 'reg_lambda': 0.14557504529254134}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:07:52,122] Trial 55 finished with value: 10253.763213706445 and parameters: {'n_estimators': 999, 'learning_rate': 0.047906994482315376, 'num_leaves': 319, 'max_depth': 19, 'subsample': 0.7419165560298491, 'colsample_bytree': 0.9281890653831892, 'min_data_in_leaf': 55, 'reg_alpha': 0.0020778418974201456, 'reg_lambda': 0.14469526057288276}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:08:13,670] Trial 56 finished with value: 10235.436632740253 and parameters: {'n_estimators': 916, 'learning_rate': 0.06367849498746733, 'num_leaves': 356, 'max_depth': 20, 'subsample': 0.6795827189801318, 'colsample_bytree': 0.9766620142026698, 'min_data_in_leaf': 69, 'reg_alpha': 0.00021666860374629321, 'reg_lambda': 0.7480409964132287}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:08:47,372] Trial 57 finished with value: 11259.597041718042 and parameters: {'n_estimators': 958, 'learning_rate': 0.01722191438012344, 'num_leaves': 239, 'max_depth': 19, 'subsample': 0.7035846206019793, 'colsample_bytree': 0.9473814201578804, 'min_data_in_leaf': 47, 'reg_alpha': 0.0006846123532527258, 'reg_lambda': 0.05020376502500043}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:08:52,352] Trial 58 finished with value: 13746.153864697548 and parameters: {'n_estimators': 155, 'learning_rate': 0.04335953289298109, 'num_leaves': 311, 'max_depth': 17, 'subsample': 0.6504967799425629, 'colsample_bytree': 0.9087522634474525, 'min_data_in_leaf': 83, 'reg_alpha': 0.03084410622902962, 'reg_lambda': 0.18086671906284152}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:09:11,352] Trial 59 finished with value: 9783.297763453445 and parameters: {'n_estimators': 931, 'learning_rate': 0.03685691288051943, 'num_leaves': 281, 'max_depth': 18, 'subsample': 0.736940197888835, 'colsample_bytree': 0.8767631182992086, 'min_data_in_leaf': 10, 'reg_alpha': 0.10381708610351886, 'reg_lambda': 0.020798039253467362}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:09:34,864] Trial 60 finished with value: 9728.135056268797 and parameters: {'n_estimators': 930, 'learning_rate': 0.02608130250361365, 'num_leaves': 283, 'max_depth': 18, 'subsample': 0.7319616978736764, 'colsample_bytree': 0.8743817529879506, 'min_data_in_leaf': 14, 'reg_alpha': 0.12118065045542126, 'reg_lambda': 0.02004438530632168}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:09:55,772] Trial 61 finished with value: 10399.267750045416 and parameters: {'n_estimators': 931, 'learning_rate': 0.025175435070674698, 'num_leaves': 279, 'max_depth': 18, 'subsample': 0.7382792499695376, 'colsample_bytree': 0.8743002770771079, 'min_data_in_leaf': 15, 'reg_alpha': 0.11645872559917636, 'reg_lambda': 0.020395350621939087}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:10:21,035] Trial 62 finished with value: 11026.863051859831 and parameters: {'n_estimators': 975, 'learning_rate': 0.01169095617172593, 'num_leaves': 292, 'max_depth': 20, 'subsample': 0.7653700629011696, 'colsample_bytree': 0.9424274686682662, 'min_data_in_leaf': 7, 'reg_alpha': 0.16361609551006834, 'reg_lambda': 0.08170524507419764}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:10:42,873] Trial 63 finished with value: 9940.362948068443 and parameters: {'n_estimators': 917, 'learning_rate': 0.039855462100149314, 'num_leaves': 264, 'max_depth': 18, 'subsample': 0.7006580779507356, 'colsample_bytree': 0.9198504238945822, 'min_data_in_leaf': 46, 'reg_alpha': 0.34961348324415464, 'reg_lambda': 0.3731112759622344}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:11:07,117] Trial 64 finished with value: 11341.675376090083 and parameters: {'n_estimators': 1000, 'learning_rate': 0.020627618908966784, 'num_leaves': 322, 'max_depth': 19, 'subsample': 0.7309692358267075, 'colsample_bytree': 0.9605489416164351, 'min_data_in_leaf': 61, 'reg_alpha': 0.010913726211730083, 'reg_lambda': 0.019477309369071254}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:11:27,024] Trial 65 finished with value: 11363.963715741873 and parameters: {'n_estimators': 858, 'learning_rate': 0.05164314303657595, 'num_leaves': 347, 'max_depth': 17, 'subsample': 0.7584902718814351, 'colsample_bytree': 0.9886298593779329, 'min_data_in_leaf': 13, 'reg_alpha': 0.002357777902508011, 'reg_lambda': 0.005220329264229232}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:11:45,072] Trial 66 finished with value: 10251.959910586358 and parameters: {'n_estimators': 889, 'learning_rate': 0.0646115278381228, 'num_leaves': 243, 'max_depth': 19, 'subsample': 0.7082686441763337, 'colsample_bytree': 0.9362934471176348, 'min_data_in_leaf': 39, 'reg_alpha': 0.043633349737926215, 'reg_lambda': 0.06449668955925716}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:12:04,252] Trial 67 finished with value: 9987.769264846822 and parameters: {'n_estimators': 961, 'learning_rate': 0.08070265929453416, 'num_leaves': 306, 'max_depth': 20, 'subsample': 0.6270193250837354, 'colsample_bytree': 0.8461397246913456, 'min_data_in_leaf': 51, 'reg_alpha': 0.11459289947851223, 'reg_lambda': 0.4082661517157872}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:12:25,454] Trial 68 finished with value: 10038.30978596484 and parameters: {'n_estimators': 935, 'learning_rate': 0.036383115157494594, 'num_leaves': 365, 'max_depth': 18, 'subsample': 0.7542008793176852, 'colsample_bytree': 0.9156019408853336, 'min_data_in_leaf': 2, 'reg_alpha': 0.0002451444072593124, 'reg_lambda': 0.10161574433448885}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:12:45,446] Trial 69 finished with value: 10498.021408936014 and parameters: {'n_estimators': 832, 'learning_rate': 0.027960205719291573, 'num_leaves': 282, 'max_depth': 20, 'subsample': 0.659743126541578, 'colsample_bytree': 0.9777236868118664, 'min_data_in_leaf': 19, 'reg_alpha': 0.07695203919130424, 'reg_lambda': 0.2209887615406523}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:13:01,949] Trial 70 finished with value: 10117.861378591919 and parameters: {'n_estimators': 895, 'learning_rate': 0.053350807833212735, 'num_leaves': 265, 'max_depth': 17, 'subsample': 0.7221729665380371, 'colsample_bytree': 0.8685599227753791, 'min_data_in_leaf': 64, 'reg_alpha': 0.02819777397564241, 'reg_lambda': 0.030752037504566086}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:13:22,897] Trial 71 finished with value: 10571.11833147041 and parameters: {'n_estimators': 918, 'learning_rate': 0.04113991536670522, 'num_leaves': 329, 'max_depth': 18, 'subsample': 0.7006263627824525, 'colsample_bytree': 0.9235223815546965, 'min_data_in_leaf': 44, 'reg_alpha': 0.32994681990439506, 'reg_lambda': 0.43719844298411176}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:13:44,282] Trial 72 finished with value: 9500.242469436473 and parameters: {'n_estimators': 973, 'learning_rate': 0.0682973440803498, 'num_leaves': 260, 'max_depth': 19, 'subsample': 0.6752636844110528, 'colsample_bytree': 0.9494654769300905, 'min_data_in_leaf': 92, 'reg_alpha': 0.3126457546209708, 'reg_lambda': 0.6822792907924372}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:14:01,596] Trial 73 finished with value: 10558.674608771582 and parameters: {'n_estimators': 971, 'learning_rate': 0.0688825548694208, 'num_leaves': 237, 'max_depth': 19, 'subsample': 0.6754855403159428, 'colsample_bytree': 0.9589750597264465, 'min_data_in_leaf': 95, 'reg_alpha': 0.8393681605648375, 'reg_lambda': 0.828739715381214}. Best is trial 48 with value: 8649.625191260928.\n",
      "[I 2024-11-06 21:14:22,192] Trial 74 finished with value: 9486.43032670046 and parameters: {'n_estimators': 978, 'learning_rate': 0.08602548700139037, 'num_leaves': 304, 'max_depth': 19, 'subsample': 0.7359718098040062, 'colsample_bytree': 0.9376119219862982, 'min_data_in_leaf': 28, 'reg_alpha': 0.008065069114789667, 'reg_lambda': 0.009333157536520857}. Best is trial 48 with value: 8649.625191260928.\n"
     ]
    }
   ],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_estimators': 969, 'learning_rate': 0.06922991270832674, 'num_leaves': 318, 'max_depth': 18, 'subsample': 0.7467813979547294, 'colsample_bytree': 0.9571263765454211, 'min_data_in_leaf': 17, 'reg_alpha': 0.00892745657075051, 'reg_lambda': 0.01654906069601954}\n",
      "\n",
      "Melhor MAE: 8649.6252\n"
     ]
    }
   ],
   "source": [
    "mae_lightgbm = study.best_value\n",
    "params_lightgbm = study.best_params\n",
    "\n",
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Tunagem do modelo XGBoost com Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Função objetivo para otimizar os hiperparâmetros do modelo XGBRegressor usando o Optuna.\n",
    "\n",
    "    :param trial: optuna.Trial\n",
    "        Objeto que sugere valores para os hiperparâmetros do modelo durante o processo de otimização.\n",
    "\n",
    "    :return: float\n",
    "        O valor do MAE calculado no conjunto de teste para o modelo treinado.\n",
    "    '''\n",
    "    model = XGBRegressor(\n",
    "        # Número de árvores (boosting rounds)\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \n",
    "        # Taxa de aprendizado\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        \n",
    "        # Número máximo de folhas por árvore\n",
    "        max_leaves=trial.suggest_int('max_leaves', 5, 500),\n",
    "        \n",
    "        # Limita a profundidade máxima de cada árvore\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 16),\n",
    "        \n",
    "        # Proporção de amostras usadas para treinar cada árvore (controle de overfitting)\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1),\n",
    "        \n",
    "        # Proporção de colunas (features) usadas para construir cada árvore\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        \n",
    "        # Proporção de colunas usadas por cada nó para divisão (split)\n",
    "        colsample_bylevel=trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        \n",
    "        # Regularização L1 (Lasso) - penalidade no valor absoluto dos coeficientes\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Regularização L2 (Ridge) - penalidade no valor quadrático dos coeficientes\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1, log=True),\n",
    "        \n",
    "        # Peso mínimo necessário para formar uma folha\n",
    "        min_child_weight=trial.suggest_int('min_child_weight', 1, 300),\n",
    "        \n",
    "        # Semente aleatória para garantir reprodutibilidade dos resultados\n",
    "        random_state=42,\n",
    "        \n",
    "        # Silenciar a saída de logs durante o treinamento\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Cria um pipeline que combina o pré-processamento e o modelo\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Treina o modelo usando o pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "   \n",
    "    # Faz previsões no conjunto de teste e calcula as métricas\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 21:14:22,222] A new study created in memory with name: no-name-7aea09c6-76cb-4840-83e9-d5dc712375f0\n",
      "[I 2024-11-06 21:14:36,062] Trial 0 finished with value: 14889.249219546517 and parameters: {'n_estimators': 437, 'learning_rate': 0.07969454818643935, 'max_leaves': 368, 'max_depth': 11, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'colsample_bylevel': 0.5290418060840998, 'reg_alpha': 0.08499808989182997, 'reg_lambda': 0.0006440507553993703, 'min_child_weight': 213}. Best is trial 0 with value: 14889.249219546517.\n",
      "[I 2024-11-06 21:14:38,608] Trial 1 finished with value: 43404.12835798154 and parameters: {'n_estimators': 118, 'learning_rate': 0.08706020878304858, 'max_leaves': 417, 'max_depth': 5, 'subsample': 0.5909124836035503, 'colsample_bytree': 0.5917022549267169, 'colsample_bylevel': 0.6521211214797689, 'reg_alpha': 0.00015777981883364995, 'reg_lambda': 2.85469785779718e-05, 'min_child_weight': 88}. Best is trial 0 with value: 14889.249219546517.\n",
      "[I 2024-11-06 21:14:50,797] Trial 2 finished with value: 53427.06057088999 and parameters: {'n_estimators': 651, 'learning_rate': 0.0019010245319870357, 'max_leaves': 149, 'max_depth': 8, 'subsample': 0.728034992108518, 'colsample_bytree': 0.8925879806965068, 'colsample_bylevel': 0.5998368910791798, 'reg_alpha': 0.00012997969313168238, 'reg_lambda': 0.0005486767416600901, 'min_child_weight': 14}. Best is trial 0 with value: 14889.249219546517.\n",
      "[I 2024-11-06 21:14:59,792] Trial 3 finished with value: 55435.06389874602 and parameters: {'n_estimators': 647, 'learning_rate': 0.002193048555664369, 'max_leaves': 37, 'max_depth': 16, 'subsample': 0.9828160165372797, 'colsample_bytree': 0.9041986740582306, 'colsample_bylevel': 0.6523068845866853, 'reg_alpha': 6.044730070370796e-08, 'reg_lambda': 0.0029775853025212607, 'min_child_weight': 133}. Best is trial 0 with value: 14889.249219546517.\n",
      "[I 2024-11-06 21:15:02,872] Trial 4 finished with value: 53703.668608339816 and parameters: {'n_estimators': 209, 'learning_rate': 0.009780337016659405, 'max_leaves': 22, 'max_depth': 15, 'subsample': 0.6293899908000085, 'colsample_bytree': 0.831261142176991, 'colsample_bylevel': 0.6558555380447055, 'reg_alpha': 0.00014472520367197597, 'reg_lambda': 0.00023641892308789696, 'min_child_weight': 56}. Best is trial 0 with value: 14889.249219546517.\n",
      "[I 2024-11-06 21:15:26,352] Trial 5 finished with value: 10406.60411657053 and parameters: {'n_estimators': 973, 'learning_rate': 0.035503048581283086, 'max_leaves': 470, 'max_depth': 15, 'subsample': 0.7989499894055425, 'colsample_bytree': 0.9609371175115584, 'colsample_bylevel': 0.5442462510259598, 'reg_alpha': 3.697114486625506e-07, 'reg_lambda': 2.300479202014574e-08, 'min_child_weight': 98}. Best is trial 5 with value: 10406.60411657053.\n",
      "[I 2024-11-06 21:15:34,974] Trial 6 finished with value: 53798.19561797067 and parameters: {'n_estimators': 450, 'learning_rate': 0.003488976654890368, 'max_leaves': 416, 'max_depth': 7, 'subsample': 0.6404672548436904, 'colsample_bytree': 0.7713480415791243, 'colsample_bylevel': 0.5704621124873813, 'reg_alpha': 0.026156272064707428, 'reg_lambda': 3.9482545946332394e-08, 'min_child_weight': 297}. Best is trial 5 with value: 10406.60411657053.\n",
      "[I 2024-11-06 21:15:43,412] Trial 7 finished with value: 55777.61862715626 and parameters: {'n_estimators': 795, 'learning_rate': 0.002497073714505273, 'max_leaves': 7, 'max_depth': 14, 'subsample': 0.8534286719238086, 'colsample_bytree': 0.8645035840204937, 'colsample_bylevel': 0.8856351733429728, 'reg_alpha': 3.911625006683821e-08, 'reg_lambda': 7.374385355858303e-06, 'min_child_weight': 35}. Best is trial 5 with value: 10406.60411657053.\n",
      "[I 2024-11-06 21:15:51,257] Trial 8 finished with value: 47405.405626842025 and parameters: {'n_estimators': 877, 'learning_rate': 0.01764396768338155, 'max_leaves': 169, 'max_depth': 3, 'subsample': 0.6554911608578311, 'colsample_bytree': 0.6625916610133735, 'colsample_bylevel': 0.864803089169032, 'reg_alpha': 0.0012602588933700108, 'reg_lambda': 0.12522814303053625, 'min_child_weight': 142}. Best is trial 5 with value: 10406.60411657053.\n",
      "[I 2024-11-06 21:15:56,712] Trial 9 finished with value: 26947.628743437694 and parameters: {'n_estimators': 207, 'learning_rate': 0.026698666742744605, 'max_leaves': 382, 'max_depth': 10, 'subsample': 0.8854835899772805, 'colsample_bytree': 0.7468977981821954, 'colsample_bylevel': 0.7613664146909971, 'reg_alpha': 2.632256136809142e-05, 'reg_lambda': 1.5971768764426203e-08, 'min_child_weight': 33}. Best is trial 5 with value: 10406.60411657053.\n",
      "[I 2024-11-06 21:16:16,147] Trial 10 finished with value: 10226.96256992134 and parameters: {'n_estimators': 982, 'learning_rate': 0.03363458701677618, 'max_leaves': 485, 'max_depth': 12, 'subsample': 0.8100862264777774, 'colsample_bytree': 0.953832397641259, 'colsample_bylevel': 0.9798853729727102, 'reg_alpha': 1.9082669651408535e-06, 'reg_lambda': 5.009091666478291e-07, 'min_child_weight': 211}. Best is trial 10 with value: 10226.96256992134.\n",
      "[I 2024-11-06 21:16:37,592] Trial 11 finished with value: 10365.404856818219 and parameters: {'n_estimators': 997, 'learning_rate': 0.03559891344492107, 'max_leaves': 487, 'max_depth': 12, 'subsample': 0.8013995149182327, 'colsample_bytree': 0.9798558923631855, 'colsample_bylevel': 0.9954751604555587, 'reg_alpha': 1.00647419837769e-06, 'reg_lambda': 6.087336969851147e-07, 'min_child_weight': 213}. Best is trial 10 with value: 10226.96256992134.\n",
      "[I 2024-11-06 21:16:58,222] Trial 12 finished with value: 17274.18871798722 and parameters: {'n_estimators': 974, 'learning_rate': 0.008093981347756055, 'max_leaves': 499, 'max_depth': 12, 'subsample': 0.7395145881407779, 'colsample_bytree': 0.9971368525989509, 'colsample_bylevel': 0.9960184854215255, 'reg_alpha': 5.525789109310386e-06, 'reg_lambda': 1.0204999463123356e-06, 'min_child_weight': 225}. Best is trial 10 with value: 10226.96256992134.\n",
      "[I 2024-11-06 21:17:14,747] Trial 13 finished with value: 9831.376352285659 and parameters: {'n_estimators': 796, 'learning_rate': 0.04545501103119832, 'max_leaves': 298, 'max_depth': 13, 'subsample': 0.9219900508555976, 'colsample_bytree': 0.9994089215293822, 'colsample_bylevel': 0.993483630254652, 'reg_alpha': 1.1970517622846019e-06, 'reg_lambda': 3.034435531561686e-07, 'min_child_weight': 211}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:17:33,502] Trial 14 finished with value: 9959.778679710702 and parameters: {'n_estimators': 782, 'learning_rate': 0.05823223268688876, 'max_leaves': 295, 'max_depth': 13, 'subsample': 0.9556343044494433, 'colsample_bytree': 0.9286955650046744, 'colsample_bylevel': 0.8999487987995394, 'reg_alpha': 1.1103478183922612e-08, 'reg_lambda': 5.536758912961742e-07, 'min_child_weight': 264}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:17:49,687] Trial 15 finished with value: 10933.382394923707 and parameters: {'n_estimators': 758, 'learning_rate': 0.061446315671703944, 'max_leaves': 307, 'max_depth': 13, 'subsample': 0.9893102190391285, 'colsample_bytree': 0.7945563618320328, 'colsample_bylevel': 0.8862263283638486, 'reg_alpha': 1.0479357286771922e-08, 'reg_lambda': 4.609991093573291e-06, 'min_child_weight': 284}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:18:03,242] Trial 16 finished with value: 31422.020007477928 and parameters: {'n_estimators': 640, 'learning_rate': 0.01428740131011014, 'max_leaves': 261, 'max_depth': 8, 'subsample': 0.9249596402301398, 'colsample_bytree': 0.511847705752916, 'colsample_bylevel': 0.8069073929798726, 'reg_alpha': 1.4799700217973108e-07, 'reg_lambda': 1.3147806228924578e-07, 'min_child_weight': 254}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:18:19,792] Trial 17 finished with value: 10657.365763508633 and parameters: {'n_estimators': 812, 'learning_rate': 0.05521811888575418, 'max_leaves': 216, 'max_depth': 10, 'subsample': 0.9277798291357418, 'colsample_bytree': 0.91294863768974, 'colsample_bylevel': 0.9297093056521442, 'reg_alpha': 6.5353251266099355e-06, 'reg_lambda': 3.329724641271483e-05, 'min_child_weight': 176}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:18:36,148] Trial 18 finished with value: 31849.82494318336 and parameters: {'n_estimators': 532, 'learning_rate': 0.005173530364852636, 'max_leaves': 306, 'max_depth': 14, 'subsample': 0.5216004247704906, 'colsample_bytree': 0.7051102112946549, 'colsample_bylevel': 0.8154217807497963, 'reg_alpha': 1.2817949339244573e-08, 'reg_lambda': 0.5435210303519561, 'min_child_weight': 258}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:18:50,376] Trial 19 finished with value: 57839.308942165124 and parameters: {'n_estimators': 703, 'learning_rate': 0.0012454948213587087, 'max_leaves': 108, 'max_depth': 16, 'subsample': 0.9287293960952137, 'colsample_bytree': 0.8419020211434829, 'colsample_bylevel': 0.933040279602396, 'reg_alpha': 0.7087689671300903, 'reg_lambda': 1.5007175299858103e-07, 'min_child_weight': 164}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:19:09,117] Trial 20 finished with value: 10715.969499408246 and parameters: {'n_estimators': 884, 'learning_rate': 0.023501983986520474, 'max_leaves': 312, 'max_depth': 13, 'subsample': 0.8698581465887242, 'colsample_bytree': 0.9311497873809772, 'colsample_bylevel': 0.937980456434366, 'reg_alpha': 6.190866420001607e-07, 'reg_lambda': 0.007554821969388887, 'min_child_weight': 256}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:19:25,715] Trial 21 finished with value: 10198.937155815725 and parameters: {'n_estimators': 891, 'learning_rate': 0.044838577232059466, 'max_leaves': 246, 'max_depth': 12, 'subsample': 0.8227306699779074, 'colsample_bytree': 0.9503911801461994, 'colsample_bylevel': 0.9644601225697329, 'reg_alpha': 1.7882379446632224e-06, 'reg_lambda': 1.3506177250806736e-06, 'min_child_weight': 189}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:19:44,152] Trial 22 finished with value: 9949.14143722721 and parameters: {'n_estimators': 896, 'learning_rate': 0.05409652258843022, 'max_leaves': 243, 'max_depth': 11, 'subsample': 0.9637958059966714, 'colsample_bytree': 0.9464468390466794, 'colsample_bylevel': 0.9400381866177842, 'reg_alpha': 2.0506411460083785e-05, 'reg_lambda': 3.4692163246116265e-06, 'min_child_weight': 187}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:19:57,062] Trial 23 finished with value: 10304.118661077495 and parameters: {'n_estimators': 767, 'learning_rate': 0.0909625157365111, 'max_leaves': 208, 'max_depth': 10, 'subsample': 0.9598016552038016, 'colsample_bytree': 0.9998187709957277, 'colsample_bylevel': 0.8451222040988929, 'reg_alpha': 2.258028638681744e-05, 'reg_lambda': 6.459947102325028e-06, 'min_child_weight': 248}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:20:10,317] Trial 24 finished with value: 11075.63101278308 and parameters: {'n_estimators': 847, 'learning_rate': 0.06114023800910934, 'max_leaves': 275, 'max_depth': 9, 'subsample': 0.9044624856219707, 'colsample_bytree': 0.8768647300389331, 'colsample_bylevel': 0.9120269829100229, 'reg_alpha': 0.0013839001888369395, 'reg_lambda': 1.3089013124239658e-07, 'min_child_weight': 186}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:20:24,612] Trial 25 finished with value: 15130.584092050996 and parameters: {'n_estimators': 561, 'learning_rate': 0.017054950341726584, 'max_leaves': 342, 'max_depth': 14, 'subsample': 0.9419562296926047, 'colsample_bytree': 0.8188186222068878, 'colsample_bylevel': 0.7500949942496842, 'reg_alpha': 1.7550734580534137e-07, 'reg_lambda': 4.0148737177637234e-05, 'min_child_weight': 227}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:20:41,980] Trial 26 finished with value: 10951.647943492442 and parameters: {'n_estimators': 694, 'learning_rate': 0.045470722396438214, 'max_leaves': 218, 'max_depth': 11, 'subsample': 0.998536331355677, 'colsample_bytree': 0.9392033942108471, 'colsample_bylevel': 0.9523417488788313, 'reg_alpha': 0.0005587494293436513, 'reg_lambda': 2.1355506096290882e-06, 'min_child_weight': 278}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:20:59,738] Trial 27 finished with value: 10024.376539810677 and parameters: {'n_estimators': 924, 'learning_rate': 0.06713104976428298, 'max_leaves': 171, 'max_depth': 13, 'subsample': 0.8488548003530244, 'colsample_bytree': 0.8712599407611379, 'colsample_bylevel': 0.8240130240094011, 'reg_alpha': 2.0452487703066673e-05, 'reg_lambda': 3.027488289692632e-07, 'min_child_weight': 124}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:21:11,962] Trial 28 finished with value: 20135.306570999932 and parameters: {'n_estimators': 732, 'learning_rate': 0.02319245223974157, 'max_leaves': 93, 'max_depth': 11, 'subsample': 0.9597977223447893, 'colsample_bytree': 0.923178227764065, 'colsample_bylevel': 0.8984110691990971, 'reg_alpha': 5.092535944476547e-06, 'reg_lambda': 3.7673539969541585e-08, 'min_child_weight': 158}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:21:21,037] Trial 29 finished with value: 11335.144551106043 and parameters: {'n_estimators': 547, 'learning_rate': 0.0888347610915501, 'max_leaves': 364, 'max_depth': 9, 'subsample': 0.8968882648638894, 'colsample_bytree': 0.9732533070235716, 'colsample_bylevel': 0.7181713300191271, 'reg_alpha': 0.006731588241237991, 'reg_lambda': 2.0000074686356697e-05, 'min_child_weight': 206}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:21:33,162] Trial 30 finished with value: 24773.755564714276 and parameters: {'n_estimators': 825, 'learning_rate': 0.04430143821604339, 'max_leaves': 285, 'max_depth': 6, 'subsample': 0.6875761410842035, 'colsample_bytree': 0.6465923608200839, 'colsample_bylevel': 0.7889592850978223, 'reg_alpha': 2.192891328139504e-07, 'reg_lambda': 0.00010247813803342223, 'min_child_weight': 236}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:21:51,047] Trial 31 finished with value: 11491.672242152983 and parameters: {'n_estimators': 920, 'learning_rate': 0.06258701390886477, 'max_leaves': 175, 'max_depth': 13, 'subsample': 0.8438634400598801, 'colsample_bytree': 0.8627143280450729, 'colsample_bylevel': 0.8406385759107673, 'reg_alpha': 2.5485000279473297e-05, 'reg_lambda': 2.478054182626037e-07, 'min_child_weight': 120}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:22:08,868] Trial 32 finished with value: 9908.84463984032 and parameters: {'n_estimators': 932, 'learning_rate': 0.07299564603825286, 'max_leaves': 240, 'max_depth': 13, 'subsample': 0.7678480266086195, 'colsample_bytree': 0.8887716530756352, 'colsample_bylevel': 0.8608144684091897, 'reg_alpha': 3.7925783034959166e-05, 'reg_lambda': 2.542119734057279e-06, 'min_child_weight': 114}. Best is trial 13 with value: 9831.376352285659.\n",
      "[I 2024-11-06 21:22:24,902] Trial 33 finished with value: 9813.036865564747 and parameters: {'n_estimators': 927, 'learning_rate': 0.08050094050380782, 'max_leaves': 239, 'max_depth': 11, 'subsample': 0.9578756083989484, 'colsample_bytree': 0.9091914796050693, 'colsample_bylevel': 0.9641616900760803, 'reg_alpha': 0.00043668253871622314, 'reg_lambda': 2.8547351533253114e-06, 'min_child_weight': 90}. Best is trial 33 with value: 9813.036865564747.\n",
      "[I 2024-11-06 21:22:44,402] Trial 34 finished with value: 9651.967572768453 and parameters: {'n_estimators': 915, 'learning_rate': 0.09639636363067126, 'max_leaves': 222, 'max_depth': 11, 'subsample': 0.7635314545353749, 'colsample_bytree': 0.9008820527712378, 'colsample_bylevel': 0.9575454269230523, 'reg_alpha': 0.00042477240751569346, 'reg_lambda': 2.5115672111733546e-06, 'min_child_weight': 85}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:23:03,657] Trial 35 finished with value: 9715.158963068166 and parameters: {'n_estimators': 935, 'learning_rate': 0.08829651330619084, 'max_leaves': 142, 'max_depth': 15, 'subsample': 0.760354608589476, 'colsample_bytree': 0.9047308501134365, 'colsample_bylevel': 0.9697063216024229, 'reg_alpha': 0.0003945407772645669, 'reg_lambda': 1.1566484074073177e-05, 'min_child_weight': 85}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:23:20,295] Trial 36 finished with value: 9954.040096290326 and parameters: {'n_estimators': 847, 'learning_rate': 0.09648001696926503, 'max_leaves': 125, 'max_depth': 15, 'subsample': 0.7064924079819765, 'colsample_bytree': 0.806308615219407, 'colsample_bylevel': 0.9699155812138669, 'reg_alpha': 0.0003552561451019706, 'reg_lambda': 1.3272990874791824e-05, 'min_child_weight': 78}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:23:35,831] Trial 37 finished with value: 13697.102432587819 and parameters: {'n_estimators': 943, 'learning_rate': 0.09965293023414552, 'max_leaves': 56, 'max_depth': 15, 'subsample': 0.7746403324043701, 'colsample_bytree': 0.8434718425145459, 'colsample_bylevel': 0.5007250058963767, 'reg_alpha': 0.00305223405257105, 'reg_lambda': 0.00010792483839691205, 'min_child_weight': 73}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:23:44,172] Trial 38 finished with value: 11856.398629303398 and parameters: {'n_estimators': 332, 'learning_rate': 0.07612637582328029, 'max_leaves': 136, 'max_depth': 16, 'subsample': 0.583310096611403, 'colsample_bytree': 0.9019020060510743, 'colsample_bylevel': 0.9697785926432546, 'reg_alpha': 0.018219082667210323, 'reg_lambda': 0.0004679964750307912, 'min_child_weight': 100}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:23:58,352] Trial 39 finished with value: 19338.452153570262 and parameters: {'n_estimators': 859, 'learning_rate': 0.034001290050534615, 'max_leaves': 72, 'max_depth': 8, 'subsample': 0.6764735843987589, 'colsample_bytree': 0.7812239493269991, 'colsample_bylevel': 0.9986595579038978, 'reg_alpha': 9.555936517904458e-05, 'reg_lambda': 0.00257431012950665, 'min_child_weight': 3}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:24:11,223] Trial 40 finished with value: 13106.34810234869 and parameters: {'n_estimators': 645, 'learning_rate': 0.04227373339902905, 'max_leaves': 193, 'max_depth': 14, 'subsample': 0.7172427538567578, 'colsample_bytree': 0.7493016501874794, 'colsample_bylevel': 0.6725770410673296, 'reg_alpha': 0.0003560792313001882, 'reg_lambda': 1.090480313807611e-05, 'min_child_weight': 49}. Best is trial 34 with value: 9651.967572768453.\n",
      "[I 2024-11-06 21:24:34,988] Trial 41 finished with value: 9537.3479055311 and parameters: {'n_estimators': 942, 'learning_rate': 0.07679504125969339, 'max_leaves': 238, 'max_depth': 12, 'subsample': 0.7789760295104393, 'colsample_bytree': 0.8954383651250244, 'colsample_bylevel': 0.872668649935964, 'reg_alpha': 0.00013486833451392785, 'reg_lambda': 2.3226075362804787e-06, 'min_child_weight': 103}. Best is trial 41 with value: 9537.3479055311.\n",
      "[I 2024-11-06 21:24:54,137] Trial 42 finished with value: 9454.978630275988 and parameters: {'n_estimators': 953, 'learning_rate': 0.0748528018683091, 'max_leaves': 348, 'max_depth': 11, 'subsample': 0.7744439933860179, 'colsample_bytree': 0.9038918497047795, 'colsample_bylevel': 0.9094679078410599, 'reg_alpha': 0.00017133873665291422, 'reg_lambda': 7.73655911184156e-08, 'min_child_weight': 93}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:25:09,826] Trial 43 finished with value: 10486.198190035762 and parameters: {'n_estimators': 968, 'learning_rate': 0.07910613067078923, 'max_leaves': 344, 'max_depth': 10, 'subsample': 0.7626074212879821, 'colsample_bytree': 0.8953652658185405, 'colsample_bylevel': 0.9138744394803561, 'reg_alpha': 8.36501520851885e-05, 'reg_lambda': 5.494756894346538e-08, 'min_child_weight': 96}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:25:39,402] Trial 44 finished with value: 9575.189163333032 and parameters: {'n_estimators': 996, 'learning_rate': 0.07566200779372936, 'max_leaves': 432, 'max_depth': 11, 'subsample': 0.7890383748727311, 'colsample_bytree': 0.857634896268261, 'colsample_bylevel': 0.8754048876772867, 'reg_alpha': 0.0010119872843107267, 'reg_lambda': 2.964075536625816e-05, 'min_child_weight': 72}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:26:07,712] Trial 45 finished with value: 10623.141795272611 and parameters: {'n_estimators': 978, 'learning_rate': 0.027308620916772445, 'max_leaves': 406, 'max_depth': 12, 'subsample': 0.7833333320699856, 'colsample_bytree': 0.8493437192814632, 'colsample_bylevel': 0.8690811415134365, 'reg_alpha': 0.0016999663740021465, 'reg_lambda': 5.650489528511957e-05, 'min_child_weight': 64}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:26:25,542] Trial 46 finished with value: 10083.204390004352 and parameters: {'n_estimators': 954, 'learning_rate': 0.09931363118875214, 'max_leaves': 456, 'max_depth': 9, 'subsample': 0.7286056094679663, 'colsample_bytree': 0.8229521028671107, 'colsample_bylevel': 0.7849827581630003, 'reg_alpha': 0.005016729310623179, 'reg_lambda': 0.0002366325294154088, 'min_child_weight': 45}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:26:36,476] Trial 47 finished with value: 44061.98410382132 and parameters: {'n_estimators': 392, 'learning_rate': 0.007293123534399826, 'max_leaves': 457, 'max_depth': 7, 'subsample': 0.8260754931311608, 'colsample_bytree': 0.8811234413239387, 'colsample_bylevel': 0.8788824376516242, 'reg_alpha': 0.0001711229207992724, 'reg_lambda': 1.1912092635325772e-06, 'min_child_weight': 23}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:27:07,266] Trial 48 finished with value: 9739.725572777681 and parameters: {'n_estimators': 897, 'learning_rate': 0.07246107659868746, 'max_leaves': 435, 'max_depth': 12, 'subsample': 0.7488768659908118, 'colsample_bytree': 0.9669449268144448, 'colsample_bylevel': 0.9159038531178098, 'reg_alpha': 0.0007953773111918109, 'reg_lambda': 0.0012761074374494814, 'min_child_weight': 108}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:27:09,788] Trial 49 finished with value: 48343.5580603656 and parameters: {'n_estimators': 103, 'learning_rate': 0.05194737312442248, 'max_leaves': 384, 'max_depth': 4, 'subsample': 0.804639420543277, 'colsample_bytree': 0.7695806666315451, 'colsample_bylevel': 0.7195807293705433, 'reg_alpha': 0.037045567051928456, 'reg_lambda': 1.7235519172765024e-05, 'min_child_weight': 140}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:27:38,772] Trial 50 finished with value: 12878.903102662769 and parameters: {'n_estimators': 999, 'learning_rate': 0.028141849874087667, 'max_leaves': 155, 'max_depth': 11, 'subsample': 0.7877896718842582, 'colsample_bytree': 0.8572535793808902, 'colsample_bylevel': 0.6111241866611743, 'reg_alpha': 0.0001745428975810888, 'reg_lambda': 1.1642356868138484e-08, 'min_child_weight': 74}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:27:59,702] Trial 51 finished with value: 9755.14023021626 and parameters: {'n_estimators': 902, 'learning_rate': 0.07030879638494315, 'max_leaves': 431, 'max_depth': 12, 'subsample': 0.7407664589839213, 'colsample_bytree': 0.9682984184265284, 'colsample_bylevel': 0.9174337560759527, 'reg_alpha': 0.0007039990159781442, 'reg_lambda': 0.013769230250088969, 'min_child_weight': 104}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:28:20,043] Trial 52 finished with value: 9619.588220663718 and parameters: {'n_estimators': 857, 'learning_rate': 0.0803651198141215, 'max_leaves': 434, 'max_depth': 10, 'subsample': 0.7453112803954923, 'colsample_bytree': 0.9176565043652363, 'colsample_bylevel': 0.8985447405037926, 'reg_alpha': 5.960715437498129e-05, 'reg_lambda': 0.0005586080098354833, 'min_child_weight': 83}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:28:38,186] Trial 53 finished with value: 10217.078343812136 and parameters: {'n_estimators': 825, 'learning_rate': 0.08156964227530022, 'max_leaves': 408, 'max_depth': 10, 'subsample': 0.7051941595064517, 'colsample_bytree': 0.9217268207785715, 'colsample_bylevel': 0.8905995358419334, 'reg_alpha': 7.164787901660851e-05, 'reg_lambda': 0.00014454765720746027, 'min_child_weight': 84}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:28:58,972] Trial 54 finished with value: 11506.66779219274 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03868139269718458, 'max_leaves': 330, 'max_depth': 9, 'subsample': 0.6099058444725642, 'colsample_bytree': 0.9008232465273569, 'colsample_bylevel': 0.9432750263759198, 'reg_alpha': 0.00022461804792583861, 'reg_lambda': 0.0002975449857273411, 'min_child_weight': 132}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:29:16,743] Trial 55 finished with value: 9559.197076730496 and parameters: {'n_estimators': 952, 'learning_rate': 0.05268929774743526, 'max_leaves': 382, 'max_depth': 11, 'subsample': 0.7555195944069082, 'colsample_bytree': 0.9382038230829437, 'colsample_bylevel': 0.8461830510387436, 'reg_alpha': 4.5849766390074125e-05, 'reg_lambda': 4.7943674974006895e-05, 'min_child_weight': 62}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:29:35,278] Trial 56 finished with value: 9603.336481856748 and parameters: {'n_estimators': 856, 'learning_rate': 0.053763458803230704, 'max_leaves': 371, 'max_depth': 11, 'subsample': 0.825840264044264, 'colsample_bytree': 0.9361561197279606, 'colsample_bylevel': 0.8415840757878885, 'reg_alpha': 4.5459657588559085e-05, 'reg_lambda': 6.454274546605914e-05, 'min_child_weight': 61}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:29:57,274] Trial 57 finished with value: 9725.14395543198 and parameters: {'n_estimators': 957, 'learning_rate': 0.05260238886296591, 'max_leaves': 386, 'max_depth': 10, 'subsample': 0.8255537800591635, 'colsample_bytree': 0.9450879475259485, 'colsample_bylevel': 0.8380035503842375, 'reg_alpha': 4.6008720392258126e-05, 'reg_lambda': 5.939098585646762e-05, 'min_child_weight': 65}. Best is trial 42 with value: 9454.978630275988.\n",
      "[I 2024-11-06 21:30:18,255] Trial 58 finished with value: 9129.087902531533 and parameters: {'n_estimators': 862, 'learning_rate': 0.05008838340439533, 'max_leaves': 364, 'max_depth': 11, 'subsample': 0.8709428371338962, 'colsample_bytree': 0.9274652094406343, 'colsample_bylevel': 0.8560743131266231, 'reg_alpha': 1.0945200425394747e-05, 'reg_lambda': 0.0010163138603090642, 'min_child_weight': 36}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:30:41,217] Trial 59 finished with value: 9804.521979231919 and parameters: {'n_estimators': 873, 'learning_rate': 0.03313726328637587, 'max_leaves': 361, 'max_depth': 11, 'subsample': 0.8707506107455435, 'colsample_bytree': 0.9894423295763888, 'colsample_bylevel': 0.8592518124889225, 'reg_alpha': 1.2124343211457033e-05, 'reg_lambda': 0.016042260430858886, 'min_child_weight': 34}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:31:00,682] Trial 60 finished with value: 30725.057782184605 and parameters: {'n_estimators': 740, 'learning_rate': 0.0035119323587584107, 'max_leaves': 323, 'max_depth': 12, 'subsample': 0.8677104428576248, 'colsample_bytree': 0.9541244125826874, 'colsample_bylevel': 0.7923472960483302, 'reg_alpha': 7.190566035482333e-06, 'reg_lambda': 0.0018792324559436086, 'min_child_weight': 55}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:31:20,212] Trial 61 finished with value: 9530.659438471965 and parameters: {'n_estimators': 841, 'learning_rate': 0.05047278593188005, 'max_leaves': 393, 'max_depth': 10, 'subsample': 0.7930986321711873, 'colsample_bytree': 0.9224441445268567, 'colsample_bylevel': 0.8540485433087658, 'reg_alpha': 3.44310520496554e-06, 'reg_lambda': 0.000817358821210913, 'min_child_weight': 23}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:31:42,162] Trial 62 finished with value: 9183.61804620057 and parameters: {'n_estimators': 800, 'learning_rate': 0.051307665471985724, 'max_leaves': 400, 'max_depth': 11, 'subsample': 0.8124946140210165, 'colsample_bytree': 0.9364646094979523, 'colsample_bylevel': 0.8235060349568986, 'reg_alpha': 3.2293971114549496e-06, 'reg_lambda': 0.005678451200518258, 'min_child_weight': 16}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:32:01,265] Trial 63 finished with value: 9215.428813697832 and parameters: {'n_estimators': 797, 'learning_rate': 0.04903682019526239, 'max_leaves': 397, 'max_depth': 12, 'subsample': 0.7932892274715964, 'colsample_bytree': 0.8787860069710064, 'colsample_bylevel': 0.8262414615254641, 'reg_alpha': 3.630586268039309e-06, 'reg_lambda': 0.005200359183598959, 'min_child_weight': 19}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:32:22,316] Trial 64 finished with value: 11622.857394333625 and parameters: {'n_estimators': 791, 'learning_rate': 0.020385683794663857, 'max_leaves': 402, 'max_depth': 12, 'subsample': 0.8103461733192008, 'colsample_bytree': 0.9811455362552752, 'colsample_bylevel': 0.8137015248590196, 'reg_alpha': 3.03343410135992e-06, 'reg_lambda': 0.0054310021166275825, 'min_child_weight': 18}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:32:39,232] Trial 65 finished with value: 12654.096444449086 and parameters: {'n_estimators': 608, 'learning_rate': 0.04803524244387626, 'max_leaves': 339, 'max_depth': 10, 'subsample': 0.8438952944631186, 'colsample_bytree': 0.7171614023314319, 'colsample_bylevel': 0.7663861416333917, 'reg_alpha': 2.673935175003895e-06, 'reg_lambda': 0.032164452196223096, 'min_child_weight': 1}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:32:57,239] Trial 66 finished with value: 15555.711003843893 and parameters: {'n_estimators': 820, 'learning_rate': 0.030651249148477427, 'max_leaves': 353, 'max_depth': 9, 'subsample': 0.814512729380374, 'colsample_bytree': 0.5701925095622711, 'colsample_bylevel': 0.8266251168076199, 'reg_alpha': 9.010031181759276e-07, 'reg_lambda': 0.0010854052007607594, 'min_child_weight': 42}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:33:14,857] Trial 67 finished with value: 9626.430408420048 and parameters: {'n_estimators': 767, 'learning_rate': 0.03855943308834346, 'max_leaves': 392, 'max_depth': 12, 'subsample': 0.7837985137523522, 'colsample_bytree': 0.8778473471034088, 'colsample_bylevel': 0.8539926163798973, 'reg_alpha': 8.213007478076512e-06, 'reg_lambda': 0.005503502896031412, 'min_child_weight': 23}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:33:34,537] Trial 68 finished with value: 17948.28238993232 and parameters: {'n_estimators': 702, 'learning_rate': 0.013574957008351502, 'max_leaves': 369, 'max_depth': 10, 'subsample': 0.7951333325896794, 'colsample_bytree': 0.9258323614640741, 'colsample_bylevel': 0.8059244220848127, 'reg_alpha': 3.8641895968801694e-07, 'reg_lambda': 0.06079107297151188, 'min_child_weight': 9}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:33:56,352] Trial 69 finished with value: 9348.569508186674 and parameters: {'n_estimators': 679, 'learning_rate': 0.0602681944414407, 'max_leaves': 475, 'max_depth': 11, 'subsample': 0.8347289359836418, 'colsample_bytree': 0.9566691171147862, 'colsample_bylevel': 0.831961360826048, 'reg_alpha': 3.6414383007932116e-06, 'reg_lambda': 0.0009486024569729674, 'min_child_weight': 29}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:34:16,306] Trial 70 finished with value: 9129.247247512245 and parameters: {'n_estimators': 684, 'learning_rate': 0.0627485528426375, 'max_leaves': 478, 'max_depth': 13, 'subsample': 0.8651742987767397, 'colsample_bytree': 0.9546697507592299, 'colsample_bylevel': 0.7658195223504423, 'reg_alpha': 1.4360241145167273e-06, 'reg_lambda': 0.003834803415795412, 'min_child_weight': 29}. Best is trial 58 with value: 9129.087902531533.\n",
      "[I 2024-11-06 21:34:32,882] Trial 71 finished with value: 9059.618384475692 and parameters: {'n_estimators': 603, 'learning_rate': 0.06335744677868296, 'max_leaves': 499, 'max_depth': 13, 'subsample': 0.8861806646880922, 'colsample_bytree': 0.9597964153943412, 'colsample_bylevel': 0.773190073814407, 'reg_alpha': 3.4773924327771223e-06, 'reg_lambda': 0.0010666702776200164, 'min_child_weight': 27}. Best is trial 71 with value: 9059.618384475692.\n",
      "[I 2024-11-06 21:34:53,517] Trial 72 finished with value: 9389.90231417071 and parameters: {'n_estimators': 671, 'learning_rate': 0.058761375687937024, 'max_leaves': 500, 'max_depth': 14, 'subsample': 0.9085131313579137, 'colsample_bytree': 0.9596168944463235, 'colsample_bylevel': 0.7654768032376954, 'reg_alpha': 3.621355602782085e-06, 'reg_lambda': 0.0008970092716939281, 'min_child_weight': 24}. Best is trial 71 with value: 9059.618384475692.\n",
      "[I 2024-11-06 21:35:11,337] Trial 73 finished with value: 9127.101506857969 and parameters: {'n_estimators': 606, 'learning_rate': 0.061690545080977585, 'max_leaves': 494, 'max_depth': 14, 'subsample': 0.9054352044653602, 'colsample_bytree': 0.9571287391239515, 'colsample_bylevel': 0.7301013413575226, 'reg_alpha': 1.5292913130628965e-06, 'reg_lambda': 0.004241783384901759, 'min_child_weight': 31}. Best is trial 71 with value: 9059.618384475692.\n",
      "[I 2024-11-06 21:35:29,312] Trial 74 finished with value: 9472.37701982265 and parameters: {'n_estimators': 601, 'learning_rate': 0.06214529687190237, 'max_leaves': 491, 'max_depth': 14, 'subsample': 0.9068315909660549, 'colsample_bytree': 0.9780812694567768, 'colsample_bylevel': 0.7259136221366146, 'reg_alpha': 1.8024463698613726e-06, 'reg_lambda': 0.0025099492943974986, 'min_child_weight': 35}. Best is trial 71 with value: 9059.618384475692.\n"
     ]
    }
   ],
   "source": [
    "# Cria o estudo Optuna com o sampler TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_estimators': 603, 'learning_rate': 0.06335744677868296, 'max_leaves': 499, 'max_depth': 13, 'subsample': 0.8861806646880922, 'colsample_bytree': 0.9597964153943412, 'colsample_bylevel': 0.773190073814407, 'reg_alpha': 3.4773924327771223e-06, 'reg_lambda': 0.0010666702776200164, 'min_child_weight': 27}\n",
      "\n",
      "Melhor MAE: 9059.6184\n"
     ]
    }
   ],
   "source": [
    "mae_xgboost = study.best_value\n",
    "params_xgboost = study.best_params\n",
    "\n",
    "print(f'Melhores hiperparâmetros: {study.best_params}')\n",
    "print(f'\\nMelhor MAE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvando os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. LightGBM: salvando e testando o desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(best_model, file_name, model_name):\n",
    "    '''\n",
    "    Treina um modelo com os melhores hiperparâmetros, salva o pipeline treinado \n",
    "    em um arquivo e avalia o desempenho no conjunto de teste.\n",
    "\n",
    "    :param best_model: Estimator object\n",
    "        O modelo otimizado com os melhores hiperparâmetros a ser treinado.\n",
    "    :param file_name: str\n",
    "        Nome do arquivo para salvar o pipeline treinado (formato .pkl).\n",
    "    :param model_name: str\n",
    "        Nome do modelo para identificação nos resultados.\n",
    "\n",
    "    :return: list\n",
    "        Lista contendo o nome do modelo, o RMSE e o MAE calculados no conjunto \n",
    "        de teste, para avaliação do desempenho.\n",
    "    '''\n",
    "    results = []\n",
    "    \n",
    "    # Recriando o pipeline com os melhores hiperpârametros\n",
    "    pipeline_best_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                          ('model', best_model)])\n",
    "    \n",
    "    # Treinando o pipeline final no conjunto de treinamento\n",
    "    pipeline_best_model.fit(X_train, y_train)\n",
    "    \n",
    "    try:\n",
    "        # Salvando o pipeline em um arquivo .pkl\n",
    "        joblib.dump(pipeline_best_model, f'modelos/{file_name}.pkl')\n",
    "        print(f'Arquivo {file_name}.pkl gerado com sucesso!')\n",
    "    except Exception as e:\n",
    "        print(f'Erro ao salvar o pipeline: {e}')\n",
    "        \n",
    "    # Previsões e cálculo das métricas no conjunto de treino\n",
    "    train_predictions = pipeline_best_model.predict(X_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "    train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "    \n",
    "    # Previsões e cálculo das métricas no conjunto de teste\n",
    "    test_predictions = pipeline_best_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    \n",
    "    # Adiciona previsões em teste a lista\n",
    "    results.append((\n",
    "        model_name, train_rmse, test_rmse, train_mae, test_mae\n",
    "    ))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo pipeline_best_model_lightgbm.pkl gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros otimizados para o LightGBM\n",
    "best_params = params_lightgbm\n",
    "\n",
    "# Cria o modelo com os melhores hiperparâmetros\n",
    "best_model = lgb.LGBMRegressor(**best_params, verbose=-1)\n",
    "\n",
    "# Treina o modelo e salva o pipeline treinado em um arquivo .pkl\n",
    "results_lightgbm = train_and_save_model(best_model, 'pipeline_best_model_lightgbm', 'LightGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. XGBoost: salvando e testando o desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo pipeline_best_model_xgboost.pkl gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros otimizados para o XGBoost\n",
    "best_params = params_xgboost\n",
    "\n",
    "# Cria o modelo com os melhores hiperparâmetros\n",
    "best_model = XGBRegressor(**best_params, verbosity=0)\n",
    "\n",
    "# Treina o modelo e salva o pipeline treinado em um arquivo .pkl\n",
    "results_xgboost = train_and_save_model(best_model, 'pipeline_best_model_xgboost', 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Comparativo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE em treino</th>\n",
       "      <th>RMSE em teste</th>\n",
       "      <th>MAE em treino</th>\n",
       "      <th>MAE em teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1948.520721</td>\n",
       "      <td>18731.616588</td>\n",
       "      <td>1328.918736</td>\n",
       "      <td>10323.606148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3240.838954</td>\n",
       "      <td>15263.694667</td>\n",
       "      <td>2153.939358</td>\n",
       "      <td>9517.590189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  RMSE em treino  RMSE em teste  MAE em treino  MAE em teste\n",
       "0  LightGBM     1948.520721   18731.616588    1328.918736  10323.606148\n",
       "1   XGBoost     3240.838954   15263.694667    2153.939358   9517.590189"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo as colunas para o DataFrame\n",
    "columns = ['Modelo', 'RMSE em treino', 'RMSE em teste', 'MAE em treino', 'MAE em teste']\n",
    "\n",
    "# Criando DataFrames com os resultados dos modelos LightGBM e XGBoost\n",
    "df_results_lightgbm = pd.DataFrame(results_lightgbm, columns=columns)\n",
    "df_results_xgboost = pd.DataFrame(results_xgboost, columns=columns)\n",
    "\n",
    "# Concatenando os resultados dos dois modelos em um único DataFrame\n",
    "df_results = pd.concat([df_results_lightgbm, df_results_xgboost], ignore_index=True)\n",
    "\n",
    "# Exibindo o DataFrame final com os resultados\n",
    "df_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
